{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Learn UNIX & Networking Learn Linux in a simple and fun way. Chapter 1: Command Line Chapter 2: Filesystem Chapter 3: Processes Chapter 4: Access Permissions Chapter 5: User Management Chapter 6: Devices Chapter 7: Text Manipulation Chapter 8: Linux Boot Process Chapter 9: Kernel Chapter 10: Process Utilisation Chapter 11: DNS Chapter 12: Network Fundamentals Chapter 13: Routing Chapter 14: Subnetting Chapter 15: Network Troubleshooting Chapter 16: Network Sharing Chapter 17: Advanced Debugging & Troubleshooting Creator of UNIX Learn: Mohamed Abukar LinkedIn , GitHub If you have any feedback or suggestions, please feel free to reach out to me on LinkedIn. Book link (TBC)","title":"Home"},{"location":"#learn-unix-networking","text":"Learn Linux in a simple and fun way.","title":"Learn UNIX &amp; Networking"},{"location":"#chapter-1-command-line","text":"","title":"Chapter 1: Command Line"},{"location":"#chapter-2-filesystem","text":"","title":"Chapter 2: Filesystem"},{"location":"#chapter-3-processes","text":"","title":"Chapter 3: Processes"},{"location":"#chapter-4-access-permissions","text":"","title":"Chapter 4: Access Permissions"},{"location":"#chapter-5-user-management","text":"","title":"Chapter 5: User Management"},{"location":"#chapter-6-devices","text":"","title":"Chapter 6: Devices"},{"location":"#chapter-7-text-manipulation","text":"","title":"Chapter 7: Text Manipulation"},{"location":"#chapter-8-linux-boot-process","text":"","title":"Chapter 8: Linux Boot Process"},{"location":"#chapter-9-kernel","text":"","title":"Chapter 9: Kernel"},{"location":"#chapter-10-process-utilisation","text":"","title":"Chapter 10: Process Utilisation"},{"location":"#chapter-11-dns","text":"","title":"Chapter 11: DNS"},{"location":"#chapter-12-network-fundamentals","text":"","title":"Chapter 12: Network Fundamentals"},{"location":"#chapter-13-routing","text":"","title":"Chapter 13: Routing"},{"location":"#chapter-14-subnetting","text":"","title":"Chapter 14: Subnetting"},{"location":"#chapter-15-network-troubleshooting","text":"","title":"Chapter 15: Network Troubleshooting"},{"location":"#chapter-16-network-sharing","text":"","title":"Chapter 16: Network Sharing"},{"location":"#chapter-17-advanced-debugging-troubleshooting","text":"","title":"Chapter 17: Advanced Debugging &amp; Troubleshooting"},{"location":"#creator-of-unix-learn","text":"Mohamed Abukar LinkedIn , GitHub If you have any feedback or suggestions, please feel free to reach out to me on LinkedIn.","title":"Creator of UNIX Learn:"},{"location":"#book-link-tbc","text":"","title":"Book link (TBC)"},{"location":"CODE_OF_CONDUCT/","text":"Code of Conduct template here","title":"Code of Conduct"},{"location":"CODE_OF_CONDUCT/#code-of-conduct-template-here","text":"","title":"Code of Conduct template here"},{"location":"CONTRIBUTING/","text":"Contributing Guidelines Ensure that you adhere to the following guidelines: Should be about principles and concepts that can be applied in any company or individual project. Do not focus on particular tools or tech stack(which usually change over time). Adhere to the Code of Conduct Should be relevant to the roles and responsibilities of Linux. Should be locally tested (see steps for testing) and well formatted. Building and testing locally Run the following commands to build and view the site locally before opening a PR. python3 -m venv .venv source .venv/bin/activate pip3 install -r requirements.txt mkdocs build mkdocs serve","title":"Contribute"},{"location":"CONTRIBUTING/#contributing-guidelines","text":"Ensure that you adhere to the following guidelines: Should be about principles and concepts that can be applied in any company or individual project. Do not focus on particular tools or tech stack(which usually change over time). Adhere to the Code of Conduct Should be relevant to the roles and responsibilities of Linux. Should be locally tested (see steps for testing) and well formatted.","title":"Contributing Guidelines"},{"location":"CONTRIBUTING/#building-and-testing-locally","text":"Run the following commands to build and view the site locally before opening a PR. python3 -m venv .venv source .venv/bin/activate pip3 install -r requirements.txt mkdocs build mkdocs serve","title":"Building and testing locally"},{"location":"access/file-permissions/","text":"File Permissions As we learned previously, files have different permissions or file modes. Let's look at an example: $ ls -l Desktop/ drwxr-xr-x 2 mo staff 4096 Dec 1 11:45 . There are four parts to a file's permissions. The first part is the filetype, which is denoted by the first character in the permissions, in our case since we are looking at a directory it shows d for the filetype. Most commonly you will see a - for a regular file. The next three parts of the file mode are the actual permissions. The permissions are grouped into 3 bits each. The first 3 bits are user permissions, then group permissions and then other permissions. I've added the pipe to make it easier to differentiate. d | rwx | r-x | r-x Each character represent a different permission: r: readable w: writable x: executable (basically an executable program) -: empty So in the above example, we see that the user mo has read, write and execute permissions on the file. The group staff has read and execute permissions. And finally, the other users (everyone else) has read and execute permissions. Exercise Use the ls -l command on multiple files and recite their permissions, user and group. Quiz Questions Click the right arrow to view the answers What permission bit is used for executable? x","title":"File Permissions"},{"location":"access/file-permissions/#file-permissions","text":"As we learned previously, files have different permissions or file modes. Let's look at an example: $ ls -l Desktop/ drwxr-xr-x 2 mo staff 4096 Dec 1 11:45 . There are four parts to a file's permissions. The first part is the filetype, which is denoted by the first character in the permissions, in our case since we are looking at a directory it shows d for the filetype. Most commonly you will see a - for a regular file. The next three parts of the file mode are the actual permissions. The permissions are grouped into 3 bits each. The first 3 bits are user permissions, then group permissions and then other permissions. I've added the pipe to make it easier to differentiate. d | rwx | r-x | r-x Each character represent a different permission: r: readable w: writable x: executable (basically an executable program) -: empty So in the above example, we see that the user mo has read, write and execute permissions on the file. The group staff has read and execute permissions. And finally, the other users (everyone else) has read and execute permissions.","title":"File Permissions"},{"location":"access/file-permissions/#exercise","text":"Use the ls -l command on multiple files and recite their permissions, user and group.","title":"Exercise"},{"location":"access/file-permissions/#quiz-questions","text":"Click the right arrow to view the answers What permission bit is used for executable? x","title":"Quiz Questions"},{"location":"access/modifying-permissions/","text":"Modifying Permissions Changing permissions can easily be done with the chmod command. First, pick which permission set you want to change, user, group or other. You can add or remove permissions with a + or - , let's look at some examples. Adding permission bit on a file $ chmod u+x myfile The above command reads like this: change permission on myfile by adding executable permission bit on the user set. So now the user has executable permission on this file! Removing permission bit on a file $ chmod u-x myfile Adding multiple permission bits on a file $ chmod ug+w There is another way to change permissions using numerical format. This method allows you to change permissions all at once. Instead of using r, w, or x to represent permissions, you'll use a numerical representation for a single permission set. So no need to specify the group with g or the user with u. The numerical representations are seen below: 4: read permission 2: write permission 1: execute permission Let's look at an example: $ chmod 755 myfile Can you guess what permissions we are giving this file? Let's break this down, so now 755 covers the permissions for all sets. The first number (7) represents user permissions, the second number (5) represents group permissions and the last 5 represents other permissions. Wait a minute, 7 and 5 weren't listed above, where are we getting these numbers? Remember we are combining all the permissions into one number now, so you'll have to get some math involved. 7 = 4 + 2 + 1, so 7 is the user permissions and it has read, write and execute permissions 5 = 4 + 1, the group has read and execute permissions 5 = 4 +1, and all other users have read and execute permissions One thing to note: it's not a great idea to be changing permissions nilly willy, you could potentially expose a sensitive file for everyone to modify, however many times you legitimately want to change permissions, just take precaution when using the chmod command. Exercise Change some basic text file permissions and see the bits changing as you do an ls -l. Quiz Questions Click the right arrow to view the answers What number represents the read permission when using numerical format? 4","title":"Modifying Permissions"},{"location":"access/modifying-permissions/#modifying-permissions","text":"Changing permissions can easily be done with the chmod command. First, pick which permission set you want to change, user, group or other. You can add or remove permissions with a + or - , let's look at some examples. Adding permission bit on a file $ chmod u+x myfile The above command reads like this: change permission on myfile by adding executable permission bit on the user set. So now the user has executable permission on this file! Removing permission bit on a file $ chmod u-x myfile Adding multiple permission bits on a file $ chmod ug+w There is another way to change permissions using numerical format. This method allows you to change permissions all at once. Instead of using r, w, or x to represent permissions, you'll use a numerical representation for a single permission set. So no need to specify the group with g or the user with u. The numerical representations are seen below: 4: read permission 2: write permission 1: execute permission Let's look at an example: $ chmod 755 myfile Can you guess what permissions we are giving this file? Let's break this down, so now 755 covers the permissions for all sets. The first number (7) represents user permissions, the second number (5) represents group permissions and the last 5 represents other permissions. Wait a minute, 7 and 5 weren't listed above, where are we getting these numbers? Remember we are combining all the permissions into one number now, so you'll have to get some math involved. 7 = 4 + 2 + 1, so 7 is the user permissions and it has read, write and execute permissions 5 = 4 + 1, the group has read and execute permissions 5 = 4 +1, and all other users have read and execute permissions One thing to note: it's not a great idea to be changing permissions nilly willy, you could potentially expose a sensitive file for everyone to modify, however many times you legitimately want to change permissions, just take precaution when using the chmod command.","title":"Modifying Permissions"},{"location":"access/modifying-permissions/#exercise","text":"Change some basic text file permissions and see the bits changing as you do an ls -l.","title":"Exercise"},{"location":"access/modifying-permissions/#quiz-questions","text":"Click the right arrow to view the answers What number represents the read permission when using numerical format? 4","title":"Quiz Questions"},{"location":"access/ownership-permissions/","text":"Ownership Permissions In addition to modifying permissions on files, you can also modify the group and user ownership of the file as well. Modify user ownership $ sudo chown staff myfile This command will set the owner of myfile to staff. Modify group ownership $ sudo chgrp whales myfile This command will set the group of myfile to whales. Modify both user and group ownership at the same time If you add a colon and groupname after the user you can set both the user and group at the same time. $ sudo chown staff:whales myfile Exercise Modify the group and user of some test files. Afterwards take a look at the permissions with ls -l. Quiz Questions Click the right arrow to view the answers What command do you use to change user ownership? chown","title":"Ownership Permissions"},{"location":"access/ownership-permissions/#ownership-permissions","text":"In addition to modifying permissions on files, you can also modify the group and user ownership of the file as well. Modify user ownership $ sudo chown staff myfile This command will set the owner of myfile to staff. Modify group ownership $ sudo chgrp whales myfile This command will set the group of myfile to whales. Modify both user and group ownership at the same time If you add a colon and groupname after the user you can set both the user and group at the same time. $ sudo chown staff:whales myfile","title":"Ownership Permissions"},{"location":"access/ownership-permissions/#exercise","text":"Modify the group and user of some test files. Afterwards take a look at the permissions with ls -l.","title":"Exercise"},{"location":"access/ownership-permissions/#quiz-questions","text":"Click the right arrow to view the answers What command do you use to change user ownership? chown","title":"Quiz Questions"},{"location":"access/process-permissions/","text":"Process Permissions Let's segway into process permissions for a bit, remember how I told you that when you run the passwd command with the SUID permission bit enabled you will run the program as root? That is true, however does that mean since you are temporarily root you can modify other user's passwords? Nope fortunately not! This is because of the many UIDs that Linux implements. There are three UIDS associated with every process: When you launch a process, it runs with the same permissions as the user or group that ran it, this is known as an effective user ID . This UID is used to grant access rights to a process. So naturally if Bob ran the touch command, the process would run as him and any files he created would be under his ownership. There is another UID, called the real user ID this is the ID of the user that launched the process. These are used to track down who the user who launched the process is. One last UID is the saved user ID , this allows a process to switch between the effective UID and real UID, vice versa. This is useful because we don't want our process to run with elevated privileges all the time, it's just good practice to use special privileges at specific times. Now let's piece these all together by looking at the passwd command once more. When running the passwd command, your effective UID is your user ID, let's say its 500 for now. Oh but wait, remember the passwd command has the SUID permission enabled. So when you run it, your effective UID is now 0 (0 is the UID of root). Now this program can access files as root. Let's say you get a little taste of power and you want to modify Sally's password, Sally has a UID of 600. Well you'll be out of luck, fortunately the process also has your real UID in this case 500. It knows that your UID is 500 and therefore you can't modify the password of UID of 600. (This of course is always bypassed if you are a superuser on a machine and can control and change everything). Since you ran passwd, it will start the process off using your real UID, and it will save the UID of the owner of the file (effective UID), so you can switch between the two. No need to modify all files with root access if it's not required. Most of the time the real UID and the effective UID are the same, but in such cases as the passwd command they will change. Exercise We haven't discussed processes yet, we can still take a look at this change happening in real time: Open one terminal window, and run the command: watch -n 1 \"ps aux | grep passwd\" . This will watch for the passwd process. Open a second terminal window and run: passwd Look at the first terminal window, you'll see a process come up for passwd. The first column in the process table is the effective user ID, lo and behold it's the root user! Quiz Questions Click the right arrow to view the answers What UID decides what access to grant? effective","title":"Process Permissions"},{"location":"access/process-permissions/#process-permissions","text":"Let's segway into process permissions for a bit, remember how I told you that when you run the passwd command with the SUID permission bit enabled you will run the program as root? That is true, however does that mean since you are temporarily root you can modify other user's passwords? Nope fortunately not! This is because of the many UIDs that Linux implements. There are three UIDS associated with every process: When you launch a process, it runs with the same permissions as the user or group that ran it, this is known as an effective user ID . This UID is used to grant access rights to a process. So naturally if Bob ran the touch command, the process would run as him and any files he created would be under his ownership. There is another UID, called the real user ID this is the ID of the user that launched the process. These are used to track down who the user who launched the process is. One last UID is the saved user ID , this allows a process to switch between the effective UID and real UID, vice versa. This is useful because we don't want our process to run with elevated privileges all the time, it's just good practice to use special privileges at specific times. Now let's piece these all together by looking at the passwd command once more. When running the passwd command, your effective UID is your user ID, let's say its 500 for now. Oh but wait, remember the passwd command has the SUID permission enabled. So when you run it, your effective UID is now 0 (0 is the UID of root). Now this program can access files as root. Let's say you get a little taste of power and you want to modify Sally's password, Sally has a UID of 600. Well you'll be out of luck, fortunately the process also has your real UID in this case 500. It knows that your UID is 500 and therefore you can't modify the password of UID of 600. (This of course is always bypassed if you are a superuser on a machine and can control and change everything). Since you ran passwd, it will start the process off using your real UID, and it will save the UID of the owner of the file (effective UID), so you can switch between the two. No need to modify all files with root access if it's not required. Most of the time the real UID and the effective UID are the same, but in such cases as the passwd command they will change.","title":"Process Permissions"},{"location":"access/process-permissions/#exercise","text":"We haven't discussed processes yet, we can still take a look at this change happening in real time: Open one terminal window, and run the command: watch -n 1 \"ps aux | grep passwd\" . This will watch for the passwd process. Open a second terminal window and run: passwd Look at the first terminal window, you'll see a process come up for passwd. The first column in the process table is the effective user ID, lo and behold it's the root user!","title":"Exercise"},{"location":"access/process-permissions/#quiz-questions","text":"Click the right arrow to view the answers What UID decides what access to grant? effective","title":"Quiz Questions"},{"location":"access/setgid-set-group-id/","text":"Setgid Similar to the set user ID permission bit, there is a set group ID (SGID) permission bit. This bit allows a program to run as if it was a member of that group. Let's look at one example: $ ls -l /usr/bin/wall -rwxr-sr-x 1 root tty 19024 Dec 14 11:45 /usr/bin/wall We can see now that the permission bit is in the group permission set. Modifying SGID $ sudo chmod g+s myfile $ sudo chmod 2555 myfile The numerical representation for SGID is 2. Quiz Questions Click the right arrow to view the answers What number represents the SGID? 2","title":"Setgid"},{"location":"access/setgid-set-group-id/#setgid","text":"Similar to the set user ID permission bit, there is a set group ID (SGID) permission bit. This bit allows a program to run as if it was a member of that group. Let's look at one example: $ ls -l /usr/bin/wall -rwxr-sr-x 1 root tty 19024 Dec 14 11:45 /usr/bin/wall We can see now that the permission bit is in the group permission set. Modifying SGID $ sudo chmod g+s myfile $ sudo chmod 2555 myfile The numerical representation for SGID is 2.","title":"Setgid"},{"location":"access/setgid-set-group-id/#quiz-questions","text":"Click the right arrow to view the answers What number represents the SGID? 2","title":"Quiz Questions"},{"location":"access/setuid-set-user-id/","text":"Setuid There are many cases in which normal users need elevated access to do stuff. The system administrator can't always be there to enter in a root password every time a user needed access to a protected file, so there are special file permission bits to allow this behavior. The Set User ID (SUID) allows a user to run a program as the owner of the program file rather than as themselves. Let's look at an example: Let's say I want to change my password, simple right? I just use the passwd command: $ passwd What is the password command doing? It's modifying a couple of files, but most importantly it's modifying the /etc/shadow file. Let's look at that file for a second: $ ls -l /etc/shadow -rw-r----- 1 root shadow 1134 Dec 1 11:45 /etc/shadow Oh wait a minute here, this file is owned by root? How is it possible that we are able to modify a file owned by root? Let's look at another permission set, this time of the command we ran: $ ls -l /usr/bin/passwd -rwsr-xr-x 1 root root 47032 Dec 1 11:45 /usr/bin/passwd You'll notice a new permission bit here s . This permission bit is the SUID, when a file has this permission set, it allows the users who launched the program to get the file owner's permission as well as execution permission, in this case root. So essentially while a user is running the password command, they are running as root. That's why we are able to access a protected file like /etc/shadow when we run the passwd command. Now if you removed that bit, you would see that you will not be able to modify /etc/shadow and therefore change your password. Modifying SUID Just like regular permissions there are two ways to modify SUID permissions. Symbolic way: $ sudo chmod u+s myfile Numerical way: sudo chmod 4755 myfile As you can see the SUID is denoted by a 4 and pre-pended to the permission set. You may see the SUID denoted as a capital S this means that it still does the same thing, but it does not have execute permissions. Exercise Look at the permission for /etc/passwd in detail, do you notice anything else? Files with SUID enabled are also easily distinguishable. Quiz Questions Click the right arrow to view the answers What number represents the SUID? 4","title":"Setuid"},{"location":"access/setuid-set-user-id/#setuid","text":"There are many cases in which normal users need elevated access to do stuff. The system administrator can't always be there to enter in a root password every time a user needed access to a protected file, so there are special file permission bits to allow this behavior. The Set User ID (SUID) allows a user to run a program as the owner of the program file rather than as themselves. Let's look at an example: Let's say I want to change my password, simple right? I just use the passwd command: $ passwd What is the password command doing? It's modifying a couple of files, but most importantly it's modifying the /etc/shadow file. Let's look at that file for a second: $ ls -l /etc/shadow -rw-r----- 1 root shadow 1134 Dec 1 11:45 /etc/shadow Oh wait a minute here, this file is owned by root? How is it possible that we are able to modify a file owned by root? Let's look at another permission set, this time of the command we ran: $ ls -l /usr/bin/passwd -rwsr-xr-x 1 root root 47032 Dec 1 11:45 /usr/bin/passwd You'll notice a new permission bit here s . This permission bit is the SUID, when a file has this permission set, it allows the users who launched the program to get the file owner's permission as well as execution permission, in this case root. So essentially while a user is running the password command, they are running as root. That's why we are able to access a protected file like /etc/shadow when we run the passwd command. Now if you removed that bit, you would see that you will not be able to modify /etc/shadow and therefore change your password. Modifying SUID Just like regular permissions there are two ways to modify SUID permissions. Symbolic way: $ sudo chmod u+s myfile Numerical way: sudo chmod 4755 myfile As you can see the SUID is denoted by a 4 and pre-pended to the permission set. You may see the SUID denoted as a capital S this means that it still does the same thing, but it does not have execute permissions.","title":"Setuid"},{"location":"access/setuid-set-user-id/#exercise","text":"Look at the permission for /etc/passwd in detail, do you notice anything else? Files with SUID enabled are also easily distinguishable.","title":"Exercise"},{"location":"access/setuid-set-user-id/#quiz-questions","text":"Click the right arrow to view the answers What number represents the SUID? 4","title":"Quiz Questions"},{"location":"access/sticky-bit/","text":"The Sticky Bit One last special permission bit I want to talk about is the sticky bit. This permission bit, \"sticks a file/directory\" this means that only the owner or the root user can delete or modify the file. This is very useful for shared directories. Take a look at the example below: $ ls -ld /tmp drwxrwxrwxt 6 root root 4096 Dec 15 11:45 /tmp You'll see a special permission bit at the end here t , this means everyone can add files, write files, modify files in the /tmp directory, but only root can delete the /tmp directory. Modify sticky bit $ sudo chmod +t mydir $ sudo chmod 1755 mydir The numerical representation for the sticky bit is 1 Exercise What other files and directories do you think have a sticky bit enabled? Quiz Questions Click the right arrow to view the answers What symbol represents the sticky bit? t","title":"The Sticky Bit"},{"location":"access/sticky-bit/#the-sticky-bit","text":"One last special permission bit I want to talk about is the sticky bit. This permission bit, \"sticks a file/directory\" this means that only the owner or the root user can delete or modify the file. This is very useful for shared directories. Take a look at the example below: $ ls -ld /tmp drwxrwxrwxt 6 root root 4096 Dec 15 11:45 /tmp You'll see a special permission bit at the end here t , this means everyone can add files, write files, modify files in the /tmp directory, but only root can delete the /tmp directory. Modify sticky bit $ sudo chmod +t mydir $ sudo chmod 1755 mydir The numerical representation for the sticky bit is 1","title":"The Sticky Bit"},{"location":"access/sticky-bit/#exercise","text":"What other files and directories do you think have a sticky bit enabled?","title":"Exercise"},{"location":"access/sticky-bit/#quiz-questions","text":"Click the right arrow to view the answers What symbol represents the sticky bit? t","title":"Quiz Questions"},{"location":"access/umask/","text":"Umask Every file that gets created comes with a default set of permissions. If you ever wanted to change that default set of permissions, you can do so with the umask command. This command takes the 3 bit permission set we see in numerical permissions. Instead of adding these permissions though, umask takes away these permissions. $ umask 021 In the above example, we are stating that we want the default permissions of new files to allow users access to everything, but for groups we want to take away their write permission and for others we want to take away their executable permission. The default umask on most distributions is 022, meaning all user access, but no write access for group and other users. When you run the umask command it will give that default set of permissions on any new file you make. However, if you want it to persist you'll have to modify your startup file (.profile), but we'll discuss that in a later lesson. Exercise Create a new file, then note it's permissions. Modify the umask and then create another new file. Check the permissions once more on the new file, what do you expect to see? ## Quiz Questions Click the right arrow to view the answers What command is used to change default file permissions? unmask","title":"Umask"},{"location":"access/umask/#umask","text":"Every file that gets created comes with a default set of permissions. If you ever wanted to change that default set of permissions, you can do so with the umask command. This command takes the 3 bit permission set we see in numerical permissions. Instead of adding these permissions though, umask takes away these permissions. $ umask 021 In the above example, we are stating that we want the default permissions of new files to allow users access to everything, but for groups we want to take away their write permission and for others we want to take away their executable permission. The default umask on most distributions is 022, meaning all user access, but no write access for group and other users. When you run the umask command it will give that default set of permissions on any new file you make. However, if you want it to persist you'll have to modify your startup file (.profile), but we'll discuss that in a later lesson.","title":"Umask"},{"location":"access/umask/#exercise","text":"Create a new file, then note it's permissions. Modify the umask and then create another new file. Check the permissions once more on the new file, what do you expect to see? ## Quiz Questions Click the right arrow to view the answers What command is used to change default file permissions? unmask","title":"Exercise"},{"location":"advanced-debugging/dns-deep-dive/","text":"DNS Deep Dive You're trying to access www.google.com from your computer, but it's the first time you're visiting the site, and there's no relevant entry in your local DNS cache or hosts file. Describe the sequence of steps taken by the DNS resolver to find the authoritative IP address for www.google.com. Solution: (BASIC) 1. **Query to Resolver:** The query for www.google.com is sent to the DNS resolver, typically running on a home router or within an ISP. 2. **Root Zone Query:** The resolver, finding no cached entry, queries the root zone servers for .com TLD information. 3. **.com TLD Nameservers:** The root zone directs the resolver to the .com TLD nameservers, managed by Verisign. 4. **Query to .com TLD Nameservers:** The resolver queries one of the .com TLD nameservers for information about google.com. 5. **google.com Nameservers:** The .com TLD nameserver provides the DNS resolver with the nameservers for google.com (e.g., `ns-81.awsdns-10.com`, `ns-659.awsdns-18.net`). 6. **Authoritative Response:** The resolver then queries these nameservers for www.google.com, receiving an authoritative response with the IP address(es). 7. **Caching the Response:** The resolver caches this response for future queries. 8. **Final Step:** The resolver returns the IP address to the local machine, allowing the computer to access www.google.com. This sequence is known as \"walking the DNS tree,\" and it demonstrates how DNS queries progressively narrow down to the specific zone holding the required records. Solution: (DEEP DIVE) - So in simple, we have a client and it wants to access [google.com](http://google.com). and we need the IP address or addresses which we can connect to in order to access google. Somewhere in the world there is a DNS zone for google.com which has these and contains the records, which links [www.google.com](http://www.google.com) to 1 or more IPs .How do we find this zone - That\u2019s what DNS does. It\u2019s the job of DNS which allows you to locate the specific DNS zone and get a query response from the authoritative zone which hosts the DNS records you need - DNS is huge global distributed database containing lots of DNS records and the function of DNS is to allow you to locate the specific zone which can give you an authoritative answer. - **Example of a query within DNS:** >> like the Google.com question - Imagine we are querying www.google.com. First thing to check is the local DNS cache and hostsfile on the local machine. The hosts file is a static mapping of names to IPs and overrides DNS. Assuming the local client isn\u2019t aware of the DNS name, then next step: - A resolver comes in here. A resolver is a type of DNS server often running on a home router or within an ISP and it will do the query on our behalf. So we send the query to the DNS resolve and it will query for you. The resolver also has a local cache which is used to speed up DNS queries. So if someone has queried [google.com](http://google.com) before, it might be able to return a non-authoritative answer aka local cached response. Assume now there is no cached entry for google.com, then the resolve queries the root zone via one of the root servers. Every DNS server will have these IPs hardcoded and this list is maintained by the OS vendor. The DNS root won\u2019t be able to answer us coz it isn\u2019t aware of google.com but it can help us get closer - The root zone contains the records of a .com specifically nameserver records which point at the nameservers for the .com TLD and it returns .com NS - So now the DNS resolver can now query one of the .com TLD NS for [www.google.com](http://www.google.com). Assuming that the google.com domain has been registered, the .com zone will contain entries for google.com. Then the details of google.com NS are returned to the DNS resolver. The resolver can now move on: - The DNS resolve now queries the [google.com](http://google.com) NS for [www.google.com](http://www.google.com) and because these NS are authoritative for this domains as they host the zone and zonefile for this domain and they\u2019re pointed at by the .com TLD zone, they can return an authoritative response back to the resolver. - Now the DNS resolver caches the result in order to improve performance - Now the DNS resolver caches the result in order to improve performance for future queries. - And this DNS resolver returns the result to our local machine. This is how every DNS query works. - Note: No one single Nameserver has all the answers, not even the root NS. But, every query gives you the next step and takes you closer to your query. - The root gives you the .com NS, the .com NS gives you the [google](http://google.com)x.com NS, and the google.com NS can give you an authoritative answer - This DNS process is also known as \u201cWalking the (\u201dDNS\u201d) tree\u201d - This process is on a high level. - **A bit deeper** - Start with root zone when the DNS resolver is querying the root zone. The root zone doesn\u2019t have the info needed but it does know which NS handles .com NS so it can provide this. These NS are run by Verisign which manages the .com TLD. These NS host the .com zone file. - We can now query the .com zone. We can\u2019t get answer directly from here but it does know which NS are authoritative for [google.com](http://google.com). These are the network addresses of the servers which host the google.com zone and this is authoritative. This gives us what we need (they look like `[ns-81.awsdns-10.com](http://ns-81.awsdns-10.com)` , `[ns-659.awsdns-18.net](http://ns-659.awsdns-18.net)` etc - The above are not IPs, they are another DNS name. This is a CNAME record. To get the IP address for this, you follow the same process again.","title":"DNS deep dive"},{"location":"advanced-debugging/dns-deep-dive/#dns-deep-dive","text":"You're trying to access www.google.com from your computer, but it's the first time you're visiting the site, and there's no relevant entry in your local DNS cache or hosts file. Describe the sequence of steps taken by the DNS resolver to find the authoritative IP address for www.google.com. Solution: (BASIC) 1. **Query to Resolver:** The query for www.google.com is sent to the DNS resolver, typically running on a home router or within an ISP. 2. **Root Zone Query:** The resolver, finding no cached entry, queries the root zone servers for .com TLD information. 3. **.com TLD Nameservers:** The root zone directs the resolver to the .com TLD nameservers, managed by Verisign. 4. **Query to .com TLD Nameservers:** The resolver queries one of the .com TLD nameservers for information about google.com. 5. **google.com Nameservers:** The .com TLD nameserver provides the DNS resolver with the nameservers for google.com (e.g., `ns-81.awsdns-10.com`, `ns-659.awsdns-18.net`). 6. **Authoritative Response:** The resolver then queries these nameservers for www.google.com, receiving an authoritative response with the IP address(es). 7. **Caching the Response:** The resolver caches this response for future queries. 8. **Final Step:** The resolver returns the IP address to the local machine, allowing the computer to access www.google.com. This sequence is known as \"walking the DNS tree,\" and it demonstrates how DNS queries progressively narrow down to the specific zone holding the required records. Solution: (DEEP DIVE) - So in simple, we have a client and it wants to access [google.com](http://google.com). and we need the IP address or addresses which we can connect to in order to access google. Somewhere in the world there is a DNS zone for google.com which has these and contains the records, which links [www.google.com](http://www.google.com) to 1 or more IPs .How do we find this zone - That\u2019s what DNS does. It\u2019s the job of DNS which allows you to locate the specific DNS zone and get a query response from the authoritative zone which hosts the DNS records you need - DNS is huge global distributed database containing lots of DNS records and the function of DNS is to allow you to locate the specific zone which can give you an authoritative answer. - **Example of a query within DNS:** >> like the Google.com question - Imagine we are querying www.google.com. First thing to check is the local DNS cache and hostsfile on the local machine. The hosts file is a static mapping of names to IPs and overrides DNS. Assuming the local client isn\u2019t aware of the DNS name, then next step: - A resolver comes in here. A resolver is a type of DNS server often running on a home router or within an ISP and it will do the query on our behalf. So we send the query to the DNS resolve and it will query for you. The resolver also has a local cache which is used to speed up DNS queries. So if someone has queried [google.com](http://google.com) before, it might be able to return a non-authoritative answer aka local cached response. Assume now there is no cached entry for google.com, then the resolve queries the root zone via one of the root servers. Every DNS server will have these IPs hardcoded and this list is maintained by the OS vendor. The DNS root won\u2019t be able to answer us coz it isn\u2019t aware of google.com but it can help us get closer - The root zone contains the records of a .com specifically nameserver records which point at the nameservers for the .com TLD and it returns .com NS - So now the DNS resolver can now query one of the .com TLD NS for [www.google.com](http://www.google.com). Assuming that the google.com domain has been registered, the .com zone will contain entries for google.com. Then the details of google.com NS are returned to the DNS resolver. The resolver can now move on: - The DNS resolve now queries the [google.com](http://google.com) NS for [www.google.com](http://www.google.com) and because these NS are authoritative for this domains as they host the zone and zonefile for this domain and they\u2019re pointed at by the .com TLD zone, they can return an authoritative response back to the resolver. - Now the DNS resolver caches the result in order to improve performance - Now the DNS resolver caches the result in order to improve performance for future queries. - And this DNS resolver returns the result to our local machine. This is how every DNS query works. - Note: No one single Nameserver has all the answers, not even the root NS. But, every query gives you the next step and takes you closer to your query. - The root gives you the .com NS, the .com NS gives you the [google](http://google.com)x.com NS, and the google.com NS can give you an authoritative answer - This DNS process is also known as \u201cWalking the (\u201dDNS\u201d) tree\u201d - This process is on a high level. - **A bit deeper** - Start with root zone when the DNS resolver is querying the root zone. The root zone doesn\u2019t have the info needed but it does know which NS handles .com NS so it can provide this. These NS are run by Verisign which manages the .com TLD. These NS host the .com zone file. - We can now query the .com zone. We can\u2019t get answer directly from here but it does know which NS are authoritative for [google.com](http://google.com). These are the network addresses of the servers which host the google.com zone and this is authoritative. This gives us what we need (they look like `[ns-81.awsdns-10.com](http://ns-81.awsdns-10.com)` , `[ns-659.awsdns-18.net](http://ns-659.awsdns-18.net)` etc - The above are not IPs, they are another DNS name. This is a CNAME record. To get the IP address for this, you follow the same process again.","title":"DNS Deep Dive"},{"location":"advanced-debugging/log-not-working/","text":"Logging doesn't work as expected Scenario Imagine you are working as a DevOps Engineer in a company that heavily relies on real-time data processing and logging. One day, you're notified that a critical process on one of your servers has stopped logging data. This process is essential for tracking user activities and system health. Initial observations do not show any immediate system failures, but the absence of new log entries is concerning. You need to quickly diagnose and resolve this issue to ensure continuous monitoring and data integrity. Question As a DevOps Engineer, you are faced with a challenge where a critical process on your system has suddenly stopped logging data. You suspect several potential issues but need a structured approach to identify and fix the problem. What do you do and where do you start? Example solution Click the right arrow to view the answers Solution 1. check process config files in /proc 2. **Check disk space**: Verify available disk space and ensure it is not full. Free up space if necessary. `Du -h, Df -h , ls -arl` 3. **Review file permissions**: Check if the process has proper write permissions to the log directory. User perms? Ownership of directory has changed. `Chmod`, `Chown`. `Chgrp` 4. **Investigate log rotation**: Ensure log rotation is properly configured to prevent log files from filling up the disk. **/etc/logrotate.d/** 5. **Monitor disk I/O**: Monitor disk I/O performance to identify any issues affecting logging. **iostat, iotop** 6. **Implement centralized logging**: Adopt a centralized logging solution to streamline log management and analysis. CloudWatch Logs or Elasticsearch 7. **Enable process-level logging**: Configure the process to perform its own logging, using frameworks or libraries. mplement a logging framework (e.g., Logrus, Zap 8. **Implement fault tolerance**: Design the system with redundancy to ensure logging continuity in case of process failures. Implement redundancy by deploying multiple instances of the process, using load balancers or orchestrators, and considering backup log streams or alternate logging mechanisms","title":"Log not working"},{"location":"advanced-debugging/log-not-working/#logging-doesnt-work-as-expected","text":"","title":"Logging doesn't work as expected"},{"location":"advanced-debugging/log-not-working/#scenario","text":"Imagine you are working as a DevOps Engineer in a company that heavily relies on real-time data processing and logging. One day, you're notified that a critical process on one of your servers has stopped logging data. This process is essential for tracking user activities and system health. Initial observations do not show any immediate system failures, but the absence of new log entries is concerning. You need to quickly diagnose and resolve this issue to ensure continuous monitoring and data integrity.","title":"Scenario"},{"location":"advanced-debugging/log-not-working/#question","text":"As a DevOps Engineer, you are faced with a challenge where a critical process on your system has suddenly stopped logging data. You suspect several potential issues but need a structured approach to identify and fix the problem. What do you do and where do you start?","title":"Question"},{"location":"advanced-debugging/log-not-working/#example-solution","text":"Click the right arrow to view the answers Solution 1. check process config files in /proc 2. **Check disk space**: Verify available disk space and ensure it is not full. Free up space if necessary. `Du -h, Df -h , ls -arl` 3. **Review file permissions**: Check if the process has proper write permissions to the log directory. User perms? Ownership of directory has changed. `Chmod`, `Chown`. `Chgrp` 4. **Investigate log rotation**: Ensure log rotation is properly configured to prevent log files from filling up the disk. **/etc/logrotate.d/** 5. **Monitor disk I/O**: Monitor disk I/O performance to identify any issues affecting logging. **iostat, iotop** 6. **Implement centralized logging**: Adopt a centralized logging solution to streamline log management and analysis. CloudWatch Logs or Elasticsearch 7. **Enable process-level logging**: Configure the process to perform its own logging, using frameworks or libraries. mplement a logging framework (e.g., Logrus, Zap 8. **Implement fault tolerance**: Design the system with redundancy to ensure logging continuity in case of process failures. Implement redundancy by deploying multiple instances of the process, using load balancers or orchestrators, and considering backup log streams or alternate logging mechanisms","title":"Example solution"},{"location":"advanced-debugging/ssh-not-working/","text":"SSH not working Scenario You are a DevOps Engineer working on a remote server infrastructure. Recently, you've encountered an issue where you cannot establish an SSH connection to one of your critical servers. This server hosts several key applications and its inaccessibility is causing operational delays. You suspect a few potential issues but need to systematically troubleshoot to identify the root cause. Question As a DevOps Engineer, you are tasked with resolving an SSH connectivity issue to a critical server. Your initial attempts to connect via SSH have failed, and you need to diagnose and fix the problem to regain access. What do you do and where do you start? Example Solution Click the right arrow to view the answers Solution 1) **Check the network connection**: Make sure that the server is connected to the network and that it has an active internet connection. 2) **Check the SSH service**: Make sure that the SSH service is running on the server. You can check the status of the SSH service using the following command: **systemctl status ssh** 3. Check the firewall: Make sure that the firewall on the server is not blocking incoming SSH connections. You can check the firewall rules using the following command: **iptables -L** 4. **Check the IP address**: Make sure that you are using the correct IP address or hostname to connect to the server. You can check the server's IP address using the ifconfig command. 5) **Check the SSH configuration**: Make sure that the SSH configuration on the server is set up correctly. You can check the SSH configuration file (usually located at /etc/ssh/sshd_config) for any issues. 6) **Check the log files**: The log files (usually located in the /var/log directory) can often provide valuable information about why an SSH connection is not working. Look for any error messages related to SSH in the log files. 7) **Disk was full so user could not use it** 8) **ran out of inodes (cant allocation anymore due to disk full)**","title":"SSH not working"},{"location":"advanced-debugging/ssh-not-working/#ssh-not-working","text":"","title":"SSH not working"},{"location":"advanced-debugging/ssh-not-working/#scenario","text":"You are a DevOps Engineer working on a remote server infrastructure. Recently, you've encountered an issue where you cannot establish an SSH connection to one of your critical servers. This server hosts several key applications and its inaccessibility is causing operational delays. You suspect a few potential issues but need to systematically troubleshoot to identify the root cause.","title":"Scenario"},{"location":"advanced-debugging/ssh-not-working/#question","text":"As a DevOps Engineer, you are tasked with resolving an SSH connectivity issue to a critical server. Your initial attempts to connect via SSH have failed, and you need to diagnose and fix the problem to regain access. What do you do and where do you start?","title":"Question"},{"location":"advanced-debugging/ssh-not-working/#example-solution","text":"Click the right arrow to view the answers Solution 1) **Check the network connection**: Make sure that the server is connected to the network and that it has an active internet connection. 2) **Check the SSH service**: Make sure that the SSH service is running on the server. You can check the status of the SSH service using the following command: **systemctl status ssh** 3. Check the firewall: Make sure that the firewall on the server is not blocking incoming SSH connections. You can check the firewall rules using the following command: **iptables -L** 4. **Check the IP address**: Make sure that you are using the correct IP address or hostname to connect to the server. You can check the server's IP address using the ifconfig command. 5) **Check the SSH configuration**: Make sure that the SSH configuration on the server is set up correctly. You can check the SSH configuration file (usually located at /etc/ssh/sshd_config) for any issues. 6) **Check the log files**: The log files (usually located in the /var/log directory) can often provide valuable information about why an SSH connection is not working. Look for any error messages related to SSH in the log files. 7) **Disk was full so user could not use it** 8) **ran out of inodes (cant allocation anymore due to disk full)**","title":"Example Solution"},{"location":"advanced-debugging/www/","text":"Famous WWW question Question You are tasked with explaining how a client computer communicates with a web server, specifically accessing \"google.com\".Consider the entire journey of a request from a client to the server step by step. Solution ### **DNS Resolution Expanded:** - **Initial Client Query**: The process begins with the client (your computer) checking its local DNS cache to see if it already knows the IP address for \"google.com\". If not, the DNS query process starts. - **/etc/resolv.conf and Local DNS Resolver**: The query is directed to the DNS server specified in the client's **`/etc/resolv.conf`** file, typically the local router or a DNS server provided by the ISP (e.g., Comcast). - **Recursive and Non-Recursive Queries**: The ISP's DNS resolver performs a recursive query, contacting root servers, then TLD servers for \".com\", and finally the authoritative name servers for \"google.com\". These authoritative servers are specified by Google when registering the domain. - **Zone Files and Record Types**: The authoritative servers check their zone files for a forward lookup (hostname to IP address) and respond with the appropriate A or AAAA record. - **Caching and TTL**: Each DNS server along the path may cache the response based on the TTL to expedite future queries. ### **2. Network Communication with TCP and BGP:** - **Routing Table and Default Gateway**: The client's routing table is consulted. If there's no direct route to the destination network, the packet is sent to the default gateway. - **ARP and MAC Address Resolution**: For local network communication, ARP (Address Resolution Protocol) is used to find the MAC address of the next hop, typically the router. - **BGP and Internet Routing**: As the packet moves beyond the local network, BGP at the ISP's Internet gateway determines the best path across various Autonomous Systems to reach the destination IP. - **TCP 3-Way Handshake**: Once the correct route is established, a TCP 3-way handshake (SYN, SYN-ACK, ACK) is executed to establish a reliable connection with the server. ### **3. HTTPS, SSL, and Load Balancers:** - **TLS/SSL Handshake**: For secure HTTP (HTTPS), a TLS/SSL handshake occurs, involving encryption algorithm negotiation, key exchange, and certificate verification. - **Load Balancing**: If the server, such as \"google.com\", is behind a load balancer, the load balancer distributes incoming requests to prevent bottlenecks. It may operate in either in-line mode (handling both incoming and outgoing connections) or DSR (Direct Server Return) mode, where responses bypass the load balancer. - **Server Processing and HTTP**: The web server (e.g., Apache running in pre-fork or worker mode) processes the HTTP request. Pre-fork uses separate processes for each request, while worker mode uses threads. ### **4. HTTP Request and Response:** - **Client HTTP Request**: The browser sends an HTTP GET request for \"google.com\". - **Server Response**: The server processes the request and sends back an HTTP response with the webpage content. ### **5. Rendering and Further Requests:** - **Web Content Rendering**: The browser renders the webpage from the HTML, CSS, and JavaScript content. - **Additional Resource Requests**: For additional resources (images, scripts, etc.), the browser makes further HTTP(S) requests. ### **6. Persistent Connections and HTTP/2:** - **TCP Keep-Alive**: TCP connections might be kept open for a short period for efficiency. - **HTTP/2 Features**: Parallel resource loading and multiplexing over the same connection are utilized for better performance. ### **7. Connection Closure:** - **TCP Teardown**: The connection is eventually closed through a TCP four-way handshake or by timeout. ### **8. Additional Networking Concepts:** - **TCP/UDP Differences**: TCP is used for reliable, connection-oriented transmissions, while UDP is used for simpler, connectionless communication. - **Other Routing Protocols**: Besides BGP, interior routing protocols like RIP and OSPF are used within Autonomous Systems for routing decisions. ### **9. Advanced DNS and HTTP Topics:** - **DNS SOA Records**: The Start of Authority (SOA) record in DNS holds important administrative information about a zone. - **Apache and SSL Configuration**: Setting up Apache for web hosting and configuring SSL for secure communication are advanced topics in HTTP and web server management.","title":"Famous WWW question"},{"location":"advanced-debugging/www/#famous-www-question","text":"","title":"Famous WWW question"},{"location":"advanced-debugging/www/#question","text":"You are tasked with explaining how a client computer communicates with a web server, specifically accessing \"google.com\".Consider the entire journey of a request from a client to the server step by step. Solution ### **DNS Resolution Expanded:** - **Initial Client Query**: The process begins with the client (your computer) checking its local DNS cache to see if it already knows the IP address for \"google.com\". If not, the DNS query process starts. - **/etc/resolv.conf and Local DNS Resolver**: The query is directed to the DNS server specified in the client's **`/etc/resolv.conf`** file, typically the local router or a DNS server provided by the ISP (e.g., Comcast). - **Recursive and Non-Recursive Queries**: The ISP's DNS resolver performs a recursive query, contacting root servers, then TLD servers for \".com\", and finally the authoritative name servers for \"google.com\". These authoritative servers are specified by Google when registering the domain. - **Zone Files and Record Types**: The authoritative servers check their zone files for a forward lookup (hostname to IP address) and respond with the appropriate A or AAAA record. - **Caching and TTL**: Each DNS server along the path may cache the response based on the TTL to expedite future queries. ### **2. Network Communication with TCP and BGP:** - **Routing Table and Default Gateway**: The client's routing table is consulted. If there's no direct route to the destination network, the packet is sent to the default gateway. - **ARP and MAC Address Resolution**: For local network communication, ARP (Address Resolution Protocol) is used to find the MAC address of the next hop, typically the router. - **BGP and Internet Routing**: As the packet moves beyond the local network, BGP at the ISP's Internet gateway determines the best path across various Autonomous Systems to reach the destination IP. - **TCP 3-Way Handshake**: Once the correct route is established, a TCP 3-way handshake (SYN, SYN-ACK, ACK) is executed to establish a reliable connection with the server. ### **3. HTTPS, SSL, and Load Balancers:** - **TLS/SSL Handshake**: For secure HTTP (HTTPS), a TLS/SSL handshake occurs, involving encryption algorithm negotiation, key exchange, and certificate verification. - **Load Balancing**: If the server, such as \"google.com\", is behind a load balancer, the load balancer distributes incoming requests to prevent bottlenecks. It may operate in either in-line mode (handling both incoming and outgoing connections) or DSR (Direct Server Return) mode, where responses bypass the load balancer. - **Server Processing and HTTP**: The web server (e.g., Apache running in pre-fork or worker mode) processes the HTTP request. Pre-fork uses separate processes for each request, while worker mode uses threads. ### **4. HTTP Request and Response:** - **Client HTTP Request**: The browser sends an HTTP GET request for \"google.com\". - **Server Response**: The server processes the request and sends back an HTTP response with the webpage content. ### **5. Rendering and Further Requests:** - **Web Content Rendering**: The browser renders the webpage from the HTML, CSS, and JavaScript content. - **Additional Resource Requests**: For additional resources (images, scripts, etc.), the browser makes further HTTP(S) requests. ### **6. Persistent Connections and HTTP/2:** - **TCP Keep-Alive**: TCP connections might be kept open for a short period for efficiency. - **HTTP/2 Features**: Parallel resource loading and multiplexing over the same connection are utilized for better performance. ### **7. Connection Closure:** - **TCP Teardown**: The connection is eventually closed through a TCP four-way handshake or by timeout. ### **8. Additional Networking Concepts:** - **TCP/UDP Differences**: TCP is used for reliable, connection-oriented transmissions, while UDP is used for simpler, connectionless communication. - **Other Routing Protocols**: Besides BGP, interior routing protocols like RIP and OSPF are used within Autonomous Systems for routing decisions. ### **9. Advanced DNS and HTTP Topics:** - **DNS SOA Records**: The Start of Authority (SOA) record in DNS holds important administrative information about a zone. - **Apache and SSL Configuration**: Setting up Apache for web hosting and configuring SSL for secure communication are advanced topics in HTTP and web server management.","title":"Question"},{"location":"booting/boot-process-bios/","text":"Boot Process: BIOS BIOS The first step in the Linux boot process is the BIOS which performs system integrity checks. The BIOS is a firmware that comes most common in IBM PC compatible computers, the dominant type of computers out there today. You've probably used the BIOS firmware to change the boot order of your harddisks, check system time, your machine's mac address, etc. The BIOS's main goal is to find the system bootloader. So once the BIOS boots up the hard drive, it searches for the boot block to figure out how to boot up the system. Depending on how you partition your disk, it will look to the master boot record (MBR) or GPT. The MBR is located in the first sector of the hard drive, the first 512 bytes. The MBR contains the code to load another program somewhere on the disk, this program in turn actually loads up our bootloader. Now if you partitioned your disk with GPT, the location of the bootloader changes a bit. UEFI There is another way to boot up your system instead of using BIOS and that is with UEFI (stands for \"Unified extensible firmware interface\"). UEFI was designed to be successor to BIOS, most hardware out there today comes with UEFI firmware built in. Macintosh machines have been using EFI booting for years now and Windows has mostly moved all of their stuff over to UEFI booting. The GPT format was intended for use with EFI. You don't necessarily need EFI if you are booting a GPT disk. The first sector of a GPT disk is reserved for a \"protective MBR\" to make it possible to boot a BIOS-based machine. UEFI stores all the information about startup in an .efi file. This file is stored on a special partition called EFI system partition on the hardware. Inside this partition it will contain the bootloader. UEFI comes with many improvements from the traditional BIOS firmware. However, since we are using Linux, the majority of us are using BIOS. So all of these lessons will be going along with that pretense. Exercise Go into your BIOS menu and see if you have UEFI booting enabled. Quiz Questions Click the right arrow to view the answers What does the BIOS load? bootloader","title":"(1) BIOS"},{"location":"booting/boot-process-bios/#boot-process-bios","text":"BIOS The first step in the Linux boot process is the BIOS which performs system integrity checks. The BIOS is a firmware that comes most common in IBM PC compatible computers, the dominant type of computers out there today. You've probably used the BIOS firmware to change the boot order of your harddisks, check system time, your machine's mac address, etc. The BIOS's main goal is to find the system bootloader. So once the BIOS boots up the hard drive, it searches for the boot block to figure out how to boot up the system. Depending on how you partition your disk, it will look to the master boot record (MBR) or GPT. The MBR is located in the first sector of the hard drive, the first 512 bytes. The MBR contains the code to load another program somewhere on the disk, this program in turn actually loads up our bootloader. Now if you partitioned your disk with GPT, the location of the bootloader changes a bit. UEFI There is another way to boot up your system instead of using BIOS and that is with UEFI (stands for \"Unified extensible firmware interface\"). UEFI was designed to be successor to BIOS, most hardware out there today comes with UEFI firmware built in. Macintosh machines have been using EFI booting for years now and Windows has mostly moved all of their stuff over to UEFI booting. The GPT format was intended for use with EFI. You don't necessarily need EFI if you are booting a GPT disk. The first sector of a GPT disk is reserved for a \"protective MBR\" to make it possible to boot a BIOS-based machine. UEFI stores all the information about startup in an .efi file. This file is stored on a special partition called EFI system partition on the hardware. Inside this partition it will contain the bootloader. UEFI comes with many improvements from the traditional BIOS firmware. However, since we are using Linux, the majority of us are using BIOS. So all of these lessons will be going along with that pretense.","title":"Boot Process: BIOS"},{"location":"booting/boot-process-bios/#exercise","text":"Go into your BIOS menu and see if you have UEFI booting enabled.","title":"Exercise"},{"location":"booting/boot-process-bios/#quiz-questions","text":"Click the right arrow to view the answers What does the BIOS load? bootloader","title":"Quiz Questions"},{"location":"booting/boot-process-bootloader/","text":"Boot Process: Bootloader The bootloader's main responsibilities are: Booting into an operating system, it can also be used to boot to non-Linux operating systems Select a kernel to use Specify kernel parameters The most common bootloader for Linux is GRUB, you are most likely using it on your system. There are many other bootloaders that you can use such as LILO, efilinux, coreboot, SYSLINUX and more. However, we will just be working with GRUB as our bootloader. So we know that the bootloader's main goal is to load up the kernel, but where does it find the kernel? To find it, we will need to look at our kernel parameters. The parameters can be found by going into the GRUB menu on startup using the 'e' key. If you don't have GRUB no worries, we'll go through the boot parameters that you will see: initrd - Specifies the location of initial RAM disk (we'll talk more about this in the next lesson). BOOT_IMAGE - This is where the kernel image is located root - The location of the root filesystem, the kernel searches inside this location to find init. It is often represented by it's UUID or the device name such as /dev/sda1. ro - This parameter is pretty standard, it mounts the fileystem as read-only mode. quiet - This is added so that you don't see display messages that are going on in the background during boot. splash - This lets the splash screen be shown. Exercise If you have GRUB as your bootloader, go into the GRUB menu with 'e' and take a look at the settings. Quiz Questions Click the right arrow to view the answers What kernel parameter makes it so you don't see bootup messages? quiet","title":"(2) Bootloader"},{"location":"booting/boot-process-bootloader/#boot-process-bootloader","text":"The bootloader's main responsibilities are: Booting into an operating system, it can also be used to boot to non-Linux operating systems Select a kernel to use Specify kernel parameters The most common bootloader for Linux is GRUB, you are most likely using it on your system. There are many other bootloaders that you can use such as LILO, efilinux, coreboot, SYSLINUX and more. However, we will just be working with GRUB as our bootloader. So we know that the bootloader's main goal is to load up the kernel, but where does it find the kernel? To find it, we will need to look at our kernel parameters. The parameters can be found by going into the GRUB menu on startup using the 'e' key. If you don't have GRUB no worries, we'll go through the boot parameters that you will see: initrd - Specifies the location of initial RAM disk (we'll talk more about this in the next lesson). BOOT_IMAGE - This is where the kernel image is located root - The location of the root filesystem, the kernel searches inside this location to find init. It is often represented by it's UUID or the device name such as /dev/sda1. ro - This parameter is pretty standard, it mounts the fileystem as read-only mode. quiet - This is added so that you don't see display messages that are going on in the background during boot. splash - This lets the splash screen be shown.","title":"Boot Process: Bootloader"},{"location":"booting/boot-process-bootloader/#exercise","text":"If you have GRUB as your bootloader, go into the GRUB menu with 'e' and take a look at the settings.","title":"Exercise"},{"location":"booting/boot-process-bootloader/#quiz-questions","text":"Click the right arrow to view the answers What kernel parameter makes it so you don't see bootup messages? quiet","title":"Quiz Questions"},{"location":"booting/boot-process-init/","text":"Boot Process: Init We've discussed init in previous lessons and know that it is the first process that gets started and it starts all the other essential services on our system. But how? There are actually three major implementations of init in Linux: System V init (sysv) This is the traditional init system. It sequentially starts and stops processes, based on startup scripts. The state of the machine is denoted by runlevels, each runlevel starts or stops a machine in a different way. Upstart This is the init you'll find on older Ubuntu installations. Upstart uses the idea of jobs and events and works by starting jobs that performs certain actions in response to events. Systemd This is the new standard for init, it is goal oriented. Basically you have a goal that you want to achieve and systemd tries to satisfy the goal's dependencies to complete the goal. We have an entire course on Init systems where we will dive into each of these systems in more detail. Quiz Questions Click the right arrow to view the answers What is the newest standard for init? systemd","title":"(4) Init"},{"location":"booting/boot-process-init/#boot-process-init","text":"We've discussed init in previous lessons and know that it is the first process that gets started and it starts all the other essential services on our system. But how? There are actually three major implementations of init in Linux: System V init (sysv) This is the traditional init system. It sequentially starts and stops processes, based on startup scripts. The state of the machine is denoted by runlevels, each runlevel starts or stops a machine in a different way. Upstart This is the init you'll find on older Ubuntu installations. Upstart uses the idea of jobs and events and works by starting jobs that performs certain actions in response to events. Systemd This is the new standard for init, it is goal oriented. Basically you have a goal that you want to achieve and systemd tries to satisfy the goal's dependencies to complete the goal. We have an entire course on Init systems where we will dive into each of these systems in more detail.","title":"Boot Process: Init"},{"location":"booting/boot-process-init/#quiz-questions","text":"Click the right arrow to view the answers What is the newest standard for init? systemd","title":"Quiz Questions"},{"location":"booting/boot-process-kernel/","text":"Boot Process: Kernel So now that our bootloader has passed on the necessary parameters, let's see how it get's started: Initrd vs Initramfs There is a bit of a chicken and egg problem when we talk about the kernel bootup. The kernel manages our systems hardware, however not all drivers are available to the kernel during bootup. So we depend on a temporary root filesystem that contains just the essential modules that the kernel needs to get to the rest of the hardware. In older versions of Linux, this job was given to the initrd (initial ram disk). The kernel would mount the initrd, get the necessary bootup drivers, then when it was done loading everything it needed, it would replace the initrd with the actual root filesystem. These days, we have something called the initramfs, this is a temporary root filesystem that is built into the kernel itself to load all the necessary drivers for the real root filesystem, so no more locating the initrd file. Mounting the root filesystem Now the kernel has all the modules it needs to create a root device and mount the root partition. Before you go any further though, the root partition is actually mounted in read-only mode first so that fsck can run safely and check for system integrity. Afterwards it remounts the root filesystem in read-write mode. Then the kernel locates the init program and executes it. Quiz Questions Click the right arrow to view the answers What is used in modern systems to load up a temporary root filesystem? initramfs","title":"(3) Kernel"},{"location":"booting/boot-process-kernel/#boot-process-kernel","text":"So now that our bootloader has passed on the necessary parameters, let's see how it get's started: Initrd vs Initramfs There is a bit of a chicken and egg problem when we talk about the kernel bootup. The kernel manages our systems hardware, however not all drivers are available to the kernel during bootup. So we depend on a temporary root filesystem that contains just the essential modules that the kernel needs to get to the rest of the hardware. In older versions of Linux, this job was given to the initrd (initial ram disk). The kernel would mount the initrd, get the necessary bootup drivers, then when it was done loading everything it needed, it would replace the initrd with the actual root filesystem. These days, we have something called the initramfs, this is a temporary root filesystem that is built into the kernel itself to load all the necessary drivers for the real root filesystem, so no more locating the initrd file. Mounting the root filesystem Now the kernel has all the modules it needs to create a root device and mount the root partition. Before you go any further though, the root partition is actually mounted in read-only mode first so that fsck can run safely and check for system integrity. Afterwards it remounts the root filesystem in read-write mode. Then the kernel locates the init program and executes it.","title":"Boot Process: Kernel"},{"location":"booting/boot-process-kernel/#quiz-questions","text":"Click the right arrow to view the answers What is used in modern systems to load up a temporary root filesystem? initramfs","title":"Quiz Questions"},{"location":"booting/boot-process-overview/","text":"Boot Process Overview Now that we've gotten a pretty good grasp at some of the important components of Linux, let's piece them altogether by learning about how the system boots. When you turn on your machine, it does some neat things like show you the logo screen, run through some different messages and then at the end you're prompted with a login window. Well there is actually a ton of stuff happening between when you push the power button to when you login and we'll discuss those in this course. The Linux boot process can be broken down in 4 simple stages: 1. BIOS The BIOS (stands for \"Basic Input/Output System\") initializes the hardware and makes sure with a Power-on self test (POST) that all the hardware is good to go. The main job of the BIOS is to load up the bootloader. 2. Bootloader The bootloader loads the kernel into memory and then starts the kernel with a set of kernel parameters. One of the most common bootloaders is GRUB, which is a universal Linux standard. 3. Kernel When the kernel is loaded, it immediately initializes devices and memory. The main job of the kernel is to load up the init process. 4. Init Remember the init process is the first process that gets started, init starts and stops essential service process on the system. There are three major implementations of init in Linux distributions. We will go over them briefly and then dive into them in another course. There it is, the (very) simple explanation of the Linux boot process. We will go into more detail about these stages in the next lessons. Exercise Reboot your system (Linux server) and see if you can spot each step as your machine boots up. Quiz Questions Click the right arrow to view the answers What is the last stage in the Linux boot process? init What are the stages in order? 1. BIOS 2. Bootloader 3. Kernel 4. Init","title":"Overview"},{"location":"booting/boot-process-overview/#boot-process-overview","text":"Now that we've gotten a pretty good grasp at some of the important components of Linux, let's piece them altogether by learning about how the system boots. When you turn on your machine, it does some neat things like show you the logo screen, run through some different messages and then at the end you're prompted with a login window. Well there is actually a ton of stuff happening between when you push the power button to when you login and we'll discuss those in this course. The Linux boot process can be broken down in 4 simple stages: 1. BIOS The BIOS (stands for \"Basic Input/Output System\") initializes the hardware and makes sure with a Power-on self test (POST) that all the hardware is good to go. The main job of the BIOS is to load up the bootloader. 2. Bootloader The bootloader loads the kernel into memory and then starts the kernel with a set of kernel parameters. One of the most common bootloaders is GRUB, which is a universal Linux standard. 3. Kernel When the kernel is loaded, it immediately initializes devices and memory. The main job of the kernel is to load up the init process. 4. Init Remember the init process is the first process that gets started, init starts and stops essential service process on the system. There are three major implementations of init in Linux distributions. We will go over them briefly and then dive into them in another course. There it is, the (very) simple explanation of the Linux boot process. We will go into more detail about these stages in the next lessons.","title":"Boot Process Overview"},{"location":"booting/boot-process-overview/#exercise","text":"Reboot your system (Linux server) and see if you can spot each step as your machine boots up.","title":"Exercise"},{"location":"booting/boot-process-overview/#quiz-questions","text":"Click the right arrow to view the answers What is the last stage in the Linux boot process? init What are the stages in order? 1. BIOS 2. Bootloader 3. Kernel 4. Init","title":"Quiz Questions"},{"location":"command-line/alias-command/","text":"Alias Sometimes typing commands can get really repetitive, or if you need to type a long command many times, it\u2019s best to have an alias you can use for that. To create an alias for a command you simply specify an alias name and set it to the command. $ alias foobar='ls -la' Now instead of typing ls -la, you can type foobar and it will execute that command, pretty neat stuff. Keep in mind that this command won't save your alias after reboot, so you'll need to add a permanent alias in: ~/.bashrc or similar files if you want to have it persist after reboot. You can remove aliases with the unalias command: $ unalias foobar Exercise Create a couple of aliases then remove them. Quiz Questions Click the right arrow to view the answers What command is used to make an alias? alias","title":"Alias"},{"location":"command-line/alias-command/#alias","text":"Sometimes typing commands can get really repetitive, or if you need to type a long command many times, it\u2019s best to have an alias you can use for that. To create an alias for a command you simply specify an alias name and set it to the command. $ alias foobar='ls -la' Now instead of typing ls -la, you can type foobar and it will execute that command, pretty neat stuff. Keep in mind that this command won't save your alias after reboot, so you'll need to add a permanent alias in: ~/.bashrc or similar files if you want to have it persist after reboot. You can remove aliases with the unalias command: $ unalias foobar","title":"Alias"},{"location":"command-line/alias-command/#exercise","text":"Create a couple of aliases then remove them.","title":"Exercise"},{"location":"command-line/alias-command/#quiz-questions","text":"Click the right arrow to view the answers What command is used to make an alias? alias","title":"Quiz Questions"},{"location":"command-line/cat-command/","text":"Cat We\u2019re almost done navigating files, but first let\u2019s learn how to read a file. A simple command to use is the cat command, short for concatenate, it not only displays file contents but it can combine multiple files and show you the output of them. $ cat foofile birdfile It\u2019s not great for viewing large files and it\u2019s only meant for short content. There are many other tools that we use to view larger text files that we\u2019ll discuss in the next lesson. Exercise Run cat on different files and directories. Then try to cat multiple files. Quiz Questions Click the right arrow to view the answers What's a good way to see the contents of a file? cat","title":"Cat"},{"location":"command-line/cat-command/#cat","text":"We\u2019re almost done navigating files, but first let\u2019s learn how to read a file. A simple command to use is the cat command, short for concatenate, it not only displays file contents but it can combine multiple files and show you the output of them. $ cat foofile birdfile It\u2019s not great for viewing large files and it\u2019s only meant for short content. There are many other tools that we use to view larger text files that we\u2019ll discuss in the next lesson.","title":"Cat"},{"location":"command-line/cat-command/#exercise","text":"Run cat on different files and directories. Then try to cat multiple files.","title":"Exercise"},{"location":"command-line/cat-command/#quiz-questions","text":"Click the right arrow to view the answers What's a good way to see the contents of a file? cat","title":"Quiz Questions"},{"location":"command-line/cd/","text":"cd (change directory) Now that you know where you are, let\u2019s see if we can move around the filesystem a bit. Remember we\u2019ll need to navigate our way using paths. There are two different ways to specify a path, with absolute and relative paths. Absolute path: This is the path from the root directory. The root is the head honcho. The root directory is commonly shown as a slash. Every time your path starts with / it means you are starting from the root directory. For example, /home/mo/Desktop. Relative path: This is the path from where you are currently in filesystem. If I was in location /home/mo/Documents and wanted to get to a directory inside Documents called taxes, I don\u2019t have to specify the whole path from root like /home/mo/Documents/taxes, I can just go to taxes/ instead. Now that you know how paths work, we just need something to help us change to the directory we want to. Luckily, we have cd or \u201cchange directory\u201d to do that. $ cd /home/mo/Pictures So now I've changed my directory location to /home/mo/Pictures. Now from this directory I have a folder inside called Hawaii, I can navigate to that folder with: $ cd Hawaii Notice how I just used the name of the folder? It\u2019s because I was already in /home/mo/Pictures. It can get pretty tiring navigating with absolute and relative paths all the time, luckily there are some shortcuts to help you out. . (current directory). This is the directory you are currently in. .. (previous directory). Takes you to the directory above your current. ~ (home directory). This directory defaults to your \u201chome directory\u201d. Such as /home/mo. - (previous directory). This will take you to the previous directory you were just at. $ cd . $ cd .. $ cd ~ $ cd - Give them a try! Exercise Run the cd command without any flags, where does it take you? Quiz Questions Click the right arrow to view the answers If you are in /home/mo/Documents and wanted to go to /home/mo, what\u2019s a good shortcut to use? cd ..","title":"Change Directory"},{"location":"command-line/cd/#cd-change-directory","text":"Now that you know where you are, let\u2019s see if we can move around the filesystem a bit. Remember we\u2019ll need to navigate our way using paths. There are two different ways to specify a path, with absolute and relative paths. Absolute path: This is the path from the root directory. The root is the head honcho. The root directory is commonly shown as a slash. Every time your path starts with / it means you are starting from the root directory. For example, /home/mo/Desktop. Relative path: This is the path from where you are currently in filesystem. If I was in location /home/mo/Documents and wanted to get to a directory inside Documents called taxes, I don\u2019t have to specify the whole path from root like /home/mo/Documents/taxes, I can just go to taxes/ instead. Now that you know how paths work, we just need something to help us change to the directory we want to. Luckily, we have cd or \u201cchange directory\u201d to do that. $ cd /home/mo/Pictures So now I've changed my directory location to /home/mo/Pictures. Now from this directory I have a folder inside called Hawaii, I can navigate to that folder with: $ cd Hawaii Notice how I just used the name of the folder? It\u2019s because I was already in /home/mo/Pictures. It can get pretty tiring navigating with absolute and relative paths all the time, luckily there are some shortcuts to help you out. . (current directory). This is the directory you are currently in. .. (previous directory). Takes you to the directory above your current. ~ (home directory). This directory defaults to your \u201chome directory\u201d. Such as /home/mo. - (previous directory). This will take you to the previous directory you were just at. $ cd . $ cd .. $ cd ~ $ cd - Give them a try!","title":"cd (change directory)"},{"location":"command-line/cd/#exercise","text":"Run the cd command without any flags, where does it take you?","title":"Exercise"},{"location":"command-line/cd/#quiz-questions","text":"Click the right arrow to view the answers If you are in /home/mo/Documents and wanted to go to /home/mo, what\u2019s a good shortcut to use? cd ..","title":"Quiz Questions"},{"location":"command-line/cp/","text":"cp (copy) Let\u2019s start making some copies of these files. Much like copy and pasting files in other operating systems, the shell gives us an even simpler way of doing that. $ cp mycoolfile /home/mo/Documents/cooldocs mycoolfile is the file you want to copy and /home/mo/Documents/cooldocs is where you are copying the file to. You can copy multiple files and directories as well as use wildcards. A wildcard is a character that can be substituted for a pattern based selection, giving you more flexibility with searches. You can use wildcards in every command for more flexibility. * the wildcard of wildcards, it's used to represent all single characters or any string. ? used to represent one character [] used to represent any character within the brackets $ cp *.jpg /home/mo/Pictures This will copy all files with the .jpg extension in your current directory to the Pictures directory. A useful command is to use the -r flag, this will recursively copy the files and directories within a directory. Try to do a cp on a directory that contains a couple of files to your Documents directory. Didn\u2019t work did it? Well that\u2019s because you\u2019ll need to copy over the files and directories inside as well with -r command. $ cp -r Pumpkin/ /home/mo/Documents One thing to note, if you copy a file over to a directory that has the same filename, the file will be overwritten with whatever you are copying over. This is no bueno if you have a file that you don\u2019t want to get accidentally overwritten. You can use the -i flag (interactive) to prompt you before overwriting a file. $ cp -i mycoolfile /home/mo/Pictures Exercise Copy over a couple of files, be careful not to overwrite anything important. Quiz Questions Click the right arrow to view the answers What flag do you need to specify to copy over a directory? -r","title":"Copy"},{"location":"command-line/cp/#cp-copy","text":"Let\u2019s start making some copies of these files. Much like copy and pasting files in other operating systems, the shell gives us an even simpler way of doing that. $ cp mycoolfile /home/mo/Documents/cooldocs mycoolfile is the file you want to copy and /home/mo/Documents/cooldocs is where you are copying the file to. You can copy multiple files and directories as well as use wildcards. A wildcard is a character that can be substituted for a pattern based selection, giving you more flexibility with searches. You can use wildcards in every command for more flexibility. * the wildcard of wildcards, it's used to represent all single characters or any string. ? used to represent one character [] used to represent any character within the brackets $ cp *.jpg /home/mo/Pictures This will copy all files with the .jpg extension in your current directory to the Pictures directory. A useful command is to use the -r flag, this will recursively copy the files and directories within a directory. Try to do a cp on a directory that contains a couple of files to your Documents directory. Didn\u2019t work did it? Well that\u2019s because you\u2019ll need to copy over the files and directories inside as well with -r command. $ cp -r Pumpkin/ /home/mo/Documents One thing to note, if you copy a file over to a directory that has the same filename, the file will be overwritten with whatever you are copying over. This is no bueno if you have a file that you don\u2019t want to get accidentally overwritten. You can use the -i flag (interactive) to prompt you before overwriting a file. $ cp -i mycoolfile /home/mo/Pictures","title":"cp (copy)"},{"location":"command-line/cp/#exercise","text":"Copy over a couple of files, be careful not to overwrite anything important.","title":"Exercise"},{"location":"command-line/cp/#quiz-questions","text":"Click the right arrow to view the answers What flag do you need to specify to copy over a directory? -r","title":"Quiz Questions"},{"location":"command-line/exit-command/","text":"exit Well, you sure did a good job getting through the basics. We\u2019ve only scratched the surface, now that you\u2019ve learned to crawl, in the next set of courses, I\u2019m gonna teach how to walk. For now, you can pat yourself on the back and take a break. To exit from the shell, you can use the exit command $ exit Or the logout command: $ logout Or if you are working out of a terminal GUI, you can just close the terminal, see you in the next course! Exercise Exit out of the shell and see what happens. Make sure you don't need to do anymore work in that shell. Quiz Questions Click the right arrow to view the answers How can you exit from the shell? exit","title":"Exit"},{"location":"command-line/exit-command/#exit","text":"Well, you sure did a good job getting through the basics. We\u2019ve only scratched the surface, now that you\u2019ve learned to crawl, in the next set of courses, I\u2019m gonna teach how to walk. For now, you can pat yourself on the back and take a break. To exit from the shell, you can use the exit command $ exit Or the logout command: $ logout Or if you are working out of a terminal GUI, you can just close the terminal, see you in the next course!","title":"exit"},{"location":"command-line/exit-command/#exercise","text":"Exit out of the shell and see what happens. Make sure you don't need to do anymore work in that shell.","title":"Exercise"},{"location":"command-line/exit-command/#quiz-questions","text":"Click the right arrow to view the answers How can you exit from the shell? exit","title":"Quiz Questions"},{"location":"command-line/file-command/","text":"file In the previous lesson we learned about touch, let\u2019s go back to that for a bit. Did you notice that the filename didn\u2019t conform to standard naming like you\u2019ve probably seen with other operating systems like Windows? Normally you would expect a file called banana.jpeg and expect a JPEG picture file. In Linux, filenames aren\u2019t required to represent the contents of the file. You can create a file called funny.gif that isn\u2019t actually a GIF. To find out what kind of file a file is, you can use the file command. It will show you a description of the file\u2019s contents. $ file banana.jpg Exercise Run the file command on a few different directories and files and note the output. Quiz Questions Click the right arrow to view the answers What command can you use to find the file type of a file? file","title":"file"},{"location":"command-line/file-command/#file","text":"In the previous lesson we learned about touch, let\u2019s go back to that for a bit. Did you notice that the filename didn\u2019t conform to standard naming like you\u2019ve probably seen with other operating systems like Windows? Normally you would expect a file called banana.jpeg and expect a JPEG picture file. In Linux, filenames aren\u2019t required to represent the contents of the file. You can create a file called funny.gif that isn\u2019t actually a GIF. To find out what kind of file a file is, you can use the file command. It will show you a description of the file\u2019s contents. $ file banana.jpg","title":"file"},{"location":"command-line/file-command/#exercise","text":"Run the file command on a few different directories and files and note the output.","title":"Exercise"},{"location":"command-line/file-command/#quiz-questions","text":"Click the right arrow to view the answers What command can you use to find the file type of a file? file","title":"Quiz Questions"},{"location":"command-line/find-command/","text":"find With all these files we have on the system it can get a little hectic trying to find a specific one. Well there\u2019s a command we can use for that, find! $ find /home -name puppies.jpg With find you\u2019ll have to specify the directory you\u2019ll be searching it, what you\u2019re searching for, in this case we are trying to find a file by the name of puppies.jpg. You can specify what type of file you are trying to find. $ find /home -type d -name MyFolder You can see that I set the type of file I\u2019m trying to find as (d) for directory and I\u2019m still searching by the name of MyFolder. One cool thing to note is that find doesn\u2019t stop at the directory you are searching, it will look inside any subdirectories that directory may have as well. Exercise Find a file from the root directory that has the word net in it. Quiz Questions Click the right arrow to view the answers What option should I specify for find if I want to search by name? -name","title":"Find"},{"location":"command-line/find-command/#find","text":"With all these files we have on the system it can get a little hectic trying to find a specific one. Well there\u2019s a command we can use for that, find! $ find /home -name puppies.jpg With find you\u2019ll have to specify the directory you\u2019ll be searching it, what you\u2019re searching for, in this case we are trying to find a file by the name of puppies.jpg. You can specify what type of file you are trying to find. $ find /home -type d -name MyFolder You can see that I set the type of file I\u2019m trying to find as (d) for directory and I\u2019m still searching by the name of MyFolder. One cool thing to note is that find doesn\u2019t stop at the directory you are searching, it will look inside any subdirectories that directory may have as well.","title":"find"},{"location":"command-line/find-command/#exercise","text":"Find a file from the root directory that has the word net in it.","title":"Exercise"},{"location":"command-line/find-command/#quiz-questions","text":"Click the right arrow to view the answers What option should I specify for find if I want to search by name? -name","title":"Quiz Questions"},{"location":"command-line/help-command/","text":"help Linux has some great built-in tools to help you how to use a command or check what flags are available for a command. One tool, help, is a built-in bash command that provides help for other bash commands (echo, logout, pwd, etc). $ help echo This will give you a description and the options you can use when you want to run echo. For other executable programs, it\u2019s convention to have an option called --help or something similar. $ echo --help Not all developers who ship out executables will conform to this standard, but it\u2019s probably your best shot to find some help on a program. Exercise Run help on the echo command, logout command and pwd command. Quiz Questions Click the right arrow to view the answers How do you get quick command line help for built-in bash commands? help","title":"Help"},{"location":"command-line/help-command/#help","text":"Linux has some great built-in tools to help you how to use a command or check what flags are available for a command. One tool, help, is a built-in bash command that provides help for other bash commands (echo, logout, pwd, etc). $ help echo This will give you a description and the options you can use when you want to run echo. For other executable programs, it\u2019s convention to have an option called --help or something similar. $ echo --help Not all developers who ship out executables will conform to this standard, but it\u2019s probably your best shot to find some help on a program.","title":"help"},{"location":"command-line/help-command/#exercise","text":"Run help on the echo command, logout command and pwd command.","title":"Exercise"},{"location":"command-line/help-command/#quiz-questions","text":"Click the right arrow to view the answers How do you get quick command line help for built-in bash commands? help","title":"Quiz Questions"},{"location":"command-line/history-command/","text":"history In your shell, there is a history of the commands that you previously entered, you can actually look through these commands. This is quite useful when you want to find and run a command you used previously without actually typing it again. $ history Want to run the same command you did before, just hit the up arrow. Want to run the previous command without typing it again? Use !!. If you typed cat file1 and want to run it again, you can actually just go !! and it will run the last command you ran. Another history shortcut is ctrl-R, this is the reverse search command, if you hit ctrl-R and you start typing parts of the command you want it will show you matches and you can just navigate through them by hitting the ctrl-R key again. Once you found the command you want to use again, just hit the Enter key. Our terminal is getting a little cluttered no? Let\u2019s do a little cleanup, use the clear command to clear up your display. $ clear There that looks better doesn\u2019t it? While we are talking about useful things, one of the most useful features in any command-line environment is tab completion. If you start typing the beginning of a command, file, directory, etc and hit the Tab key, it will autocomplete based on what it finds in the directory you are searching as long as you don\u2019t have any other files that start with those letters. For example if you were trying to run the command chrome, you can type chr and press Tab and it will autocomplete chrome. Exercise Navigate through your previous command history with the Up and Down keys. Play around with ctrl-R reverse search. Quiz Questions Click the right arrow to view the answers What is the command to clear the terminal? clear","title":"History"},{"location":"command-line/history-command/#history","text":"In your shell, there is a history of the commands that you previously entered, you can actually look through these commands. This is quite useful when you want to find and run a command you used previously without actually typing it again. $ history Want to run the same command you did before, just hit the up arrow. Want to run the previous command without typing it again? Use !!. If you typed cat file1 and want to run it again, you can actually just go !! and it will run the last command you ran. Another history shortcut is ctrl-R, this is the reverse search command, if you hit ctrl-R and you start typing parts of the command you want it will show you matches and you can just navigate through them by hitting the ctrl-R key again. Once you found the command you want to use again, just hit the Enter key. Our terminal is getting a little cluttered no? Let\u2019s do a little cleanup, use the clear command to clear up your display. $ clear There that looks better doesn\u2019t it? While we are talking about useful things, one of the most useful features in any command-line environment is tab completion. If you start typing the beginning of a command, file, directory, etc and hit the Tab key, it will autocomplete based on what it finds in the directory you are searching as long as you don\u2019t have any other files that start with those letters. For example if you were trying to run the command chrome, you can type chr and press Tab and it will autocomplete chrome.","title":"history"},{"location":"command-line/history-command/#exercise","text":"Navigate through your previous command history with the Up and Down keys. Play around with ctrl-R reverse search.","title":"Exercise"},{"location":"command-line/history-command/#quiz-questions","text":"Click the right arrow to view the answers What is the command to clear the terminal? clear","title":"Quiz Questions"},{"location":"command-line/less-command/","text":"less If you are viewing text files larger than a simple output, less is more. (There is actually a command called more that does something similar, so this is ironic.) The text is displayed in a paged manner, so you can navigate through a text file page by page. Go ahead and look at the contents of a file with less. Once you\u2019re in the less command, you can actually use other keyboard commands to navigate in the file. $ less /home/mo/Documents/text1 Use the following command to navigate through less: q - Used to quit out of less and go back to your shell. Page up, Page down, Up and Down - Navigate using the arrow keys and page keys. g - Moves to beginning of the text file. G - Moves to the end of the text file. /search - You can search for specific text inside the text document. Prefacing the words you want to search with / h - If you need a little help about how to use less while you\u2019re in less, use help. Exercise Run less on a file, then page up and around the file. Try searching for a specific word. Quickly navigate to the beginning or the end of the file. Quiz Questions Click the right arrow to view the answers How do you quit out of a less command? q","title":"Less"},{"location":"command-line/less-command/#less","text":"If you are viewing text files larger than a simple output, less is more. (There is actually a command called more that does something similar, so this is ironic.) The text is displayed in a paged manner, so you can navigate through a text file page by page. Go ahead and look at the contents of a file with less. Once you\u2019re in the less command, you can actually use other keyboard commands to navigate in the file. $ less /home/mo/Documents/text1 Use the following command to navigate through less: q - Used to quit out of less and go back to your shell. Page up, Page down, Up and Down - Navigate using the arrow keys and page keys. g - Moves to beginning of the text file. G - Moves to the end of the text file. /search - You can search for specific text inside the text document. Prefacing the words you want to search with / h - If you need a little help about how to use less while you\u2019re in less, use help.","title":"less"},{"location":"command-line/less-command/#exercise","text":"Run less on a file, then page up and around the file. Try searching for a specific word. Quickly navigate to the beginning or the end of the file.","title":"Exercise"},{"location":"command-line/less-command/#quiz-questions","text":"Click the right arrow to view the answers How do you quit out of a less command? q","title":"Quiz Questions"},{"location":"command-line/ls-command/","text":"ls (list directories) Now that we know how to move around the system, how do we figure out what is available to us? Right now it\u2019s like we are moving around in the dark. Well, we can use the wonderful ls command to list directory contents. The ls command will list directories and files in the current directory by default, however you can specify which path you want to list the directories of. $ ls $ ls /home/mo ls is a quite useful tool, it also shows you detailed information about the files and directories you are looking at. Also note that not all files in a directory will be visible. Filenames that start with . are hidden, you can view them however with the ls command and pass the -a flag to it (a for all). $ ls -a There is also one more useful ls flag, -l for long, this shows a detailed list of files in a long format. This will show you detailed information, starting from the left: file permissions, number of links, owner name, owner group, file size, timestamp of last modification, and file/directory name. $ ls -l mo:~$ ls -l total 19592 drwx------@ 8 mohameda staff 256 1 Jun 2023 Applications -rw-r--r-- 1 mohameda staff 1093 14 Sep 2022 Brewfile -rw-r--r--@ 1 mohameda staff 7015 6 Jul 16 :35 CHANGELOG.md drwx------@ 8 mohameda staff 256 28 Nov 00 :38 Desktop drwx------@ 60 mohameda staff 1920 27 Nov 18 :15 Documents drwx------@ 342 mohameda staff 10944 3 Dec 19 :45 Downloads -rw-r--r-- 1 mohameda staff 0 27 Nov 20 :19 JO.txt -rw-r--r-- 1 mohameda staff 0 27 Nov 20 :19 L.txt -rw-r--r-- 1 mohameda staff 1084 6 Oct 2021 LICENSE drwx------@ 94 mohameda staff 3008 28 Nov 00 :16 Library drwx------ 8 mohameda staff 256 28 Nov 00 :23 Movies drwx------+ 5 mohameda staff 160 28 Nov 00 :23 Music Commands have things called flags (or arguments or options, whatever you want to call it) to add more functionality. See how we added -a and -l, well you can add them both together with -la. The order of the flags determines which order it goes in, most of the time this doesn\u2019t really matter so you can also do ls -al and it would still work. $ ls -la Exercise Run ls with different flags and see the output you receive. Quiz Questions Click the right arrow to view the answers What command would you use to see hidden files? ls -a","title":"List"},{"location":"command-line/ls-command/#ls-list-directories","text":"Now that we know how to move around the system, how do we figure out what is available to us? Right now it\u2019s like we are moving around in the dark. Well, we can use the wonderful ls command to list directory contents. The ls command will list directories and files in the current directory by default, however you can specify which path you want to list the directories of. $ ls $ ls /home/mo ls is a quite useful tool, it also shows you detailed information about the files and directories you are looking at. Also note that not all files in a directory will be visible. Filenames that start with . are hidden, you can view them however with the ls command and pass the -a flag to it (a for all). $ ls -a There is also one more useful ls flag, -l for long, this shows a detailed list of files in a long format. This will show you detailed information, starting from the left: file permissions, number of links, owner name, owner group, file size, timestamp of last modification, and file/directory name. $ ls -l mo:~$ ls -l total 19592 drwx------@ 8 mohameda staff 256 1 Jun 2023 Applications -rw-r--r-- 1 mohameda staff 1093 14 Sep 2022 Brewfile -rw-r--r--@ 1 mohameda staff 7015 6 Jul 16 :35 CHANGELOG.md drwx------@ 8 mohameda staff 256 28 Nov 00 :38 Desktop drwx------@ 60 mohameda staff 1920 27 Nov 18 :15 Documents drwx------@ 342 mohameda staff 10944 3 Dec 19 :45 Downloads -rw-r--r-- 1 mohameda staff 0 27 Nov 20 :19 JO.txt -rw-r--r-- 1 mohameda staff 0 27 Nov 20 :19 L.txt -rw-r--r-- 1 mohameda staff 1084 6 Oct 2021 LICENSE drwx------@ 94 mohameda staff 3008 28 Nov 00 :16 Library drwx------ 8 mohameda staff 256 28 Nov 00 :23 Movies drwx------+ 5 mohameda staff 160 28 Nov 00 :23 Music Commands have things called flags (or arguments or options, whatever you want to call it) to add more functionality. See how we added -a and -l, well you can add them both together with -la. The order of the flags determines which order it goes in, most of the time this doesn\u2019t really matter so you can also do ls -al and it would still work. $ ls -la","title":"ls (list directories)"},{"location":"command-line/ls-command/#exercise","text":"Run ls with different flags and see the output you receive.","title":"Exercise"},{"location":"command-line/ls-command/#quiz-questions","text":"Click the right arrow to view the answers What command would you use to see hidden files? ls -a","title":"Quiz Questions"},{"location":"command-line/man-command/","text":"man Gee I wish some of these programs had a manual so we can see some more information about them. Well luckily they do! Aptly named man pages, you can see the manuals for a command with the man command. $ man ls Man pages are manuals that are by default built into most Linux operating systems. They provide documentation about commands and other aspects of the system. Try it out on a few commands to get more information about them. Exercise Run the man command on the ls command. Quiz Questions Click the right arrow to view the answers How do you see the manuals for a command? man","title":"Man"},{"location":"command-line/man-command/#man","text":"Gee I wish some of these programs had a manual so we can see some more information about them. Well luckily they do! Aptly named man pages, you can see the manuals for a command with the man command. $ man ls Man pages are manuals that are by default built into most Linux operating systems. They provide documentation about commands and other aspects of the system. Try it out on a few commands to get more information about them.","title":"man"},{"location":"command-line/man-command/#exercise","text":"Run the man command on the ls command.","title":"Exercise"},{"location":"command-line/man-command/#quiz-questions","text":"Click the right arrow to view the answers How do you see the manuals for a command? man","title":"Quiz Questions"},{"location":"command-line/mkdir-command/","text":"mkdir (make directory) We\u2019re gonna need some directories to store all these files we\u2019ve been working on. The mkdir command (Make Directory) is useful for that, it will create a directory if it doesn\u2019t already exist. You can even make multiple directories at the same time. $ mkdir books paintings You can also create subdirectories at the same time with the -p (parent flag). $ mkdir -p books/foobar/favorites Exercise Make a couple of directories and move some files into that directory. Quiz Questions Click the right arrow to view the answers What command is use to make a directory? mkdir","title":"Mkdir"},{"location":"command-line/mkdir-command/#mkdir-make-directory","text":"We\u2019re gonna need some directories to store all these files we\u2019ve been working on. The mkdir command (Make Directory) is useful for that, it will create a directory if it doesn\u2019t already exist. You can even make multiple directories at the same time. $ mkdir books paintings You can also create subdirectories at the same time with the -p (parent flag). $ mkdir -p books/foobar/favorites","title":"mkdir (make directory)"},{"location":"command-line/mkdir-command/#exercise","text":"Make a couple of directories and move some files into that directory.","title":"Exercise"},{"location":"command-line/mkdir-command/#quiz-questions","text":"Click the right arrow to view the answers What command is use to make a directory? mkdir","title":"Quiz Questions"},{"location":"command-line/mv-command/","text":"mv (move) Used for moving files and also renaming them. Quite similar to the cp command in terms of flags and functionality. You can rename files like this: $ mv oldfile newfile Or you can actually move a file to a different directory: $ mv file2 /home/mo/Documents And move more than one file: $ mv file_1 file_2 /somedirectory You can rename directories as well: $ mv directory1 directory2 Like cp, if you mv a file or directory it will overwrite anything in the same directory. So you can use the -i flag to prompt you before overwriting anything. mv -i directory1 directory2 Let\u2019s say you did want to mv a file to overwrite the previous one. You can also make a backup of that file and it will just rename the old version with a ~. $ mv -b directory1 directory2 Exercise Rename a file, then move that file to a different directory. Quiz Questions Click the right arrow to view the answers How do you rename a file called foo to bar? mv foo bar","title":"Move"},{"location":"command-line/mv-command/#mv-move","text":"Used for moving files and also renaming them. Quite similar to the cp command in terms of flags and functionality. You can rename files like this: $ mv oldfile newfile Or you can actually move a file to a different directory: $ mv file2 /home/mo/Documents And move more than one file: $ mv file_1 file_2 /somedirectory You can rename directories as well: $ mv directory1 directory2 Like cp, if you mv a file or directory it will overwrite anything in the same directory. So you can use the -i flag to prompt you before overwriting anything. mv -i directory1 directory2 Let\u2019s say you did want to mv a file to overwrite the previous one. You can also make a backup of that file and it will just rename the old version with a ~. $ mv -b directory1 directory2","title":"mv (move)"},{"location":"command-line/mv-command/#exercise","text":"Rename a file, then move that file to a different directory.","title":"Exercise"},{"location":"command-line/mv-command/#quiz-questions","text":"Click the right arrow to view the answers How do you rename a file called foo to bar? mv foo bar","title":"Quiz Questions"},{"location":"command-line/pwd/","text":"pwd (print working directory) Everything in Linux is a file, as you journey deeper into Linux you\u2019ll understand this, but for now just keep that in mind. Every file is organized in a hierarchical directory tree. The first directory in the filesystem is aptly named the root directory. The root directory has many folders and files which you can store more folders and files, etc. Here is an example of what the directory tree looks like: / |-- bin | |-- file1 | |-- file2 |-- etc | |-- file3 | `-- directory1 | |-- file4 | `-- file5 |-- home |-- var The location of these files and directories are referred to as paths. If you had a folder named home with a folder inside of it named mo and another folder in that folder called Movies, that path would look like this: /home/mo/Movies, pretty simple huh? Navigation of the filesystem, much like real life is helpful if you know where you are and where you are going. To see where you are, you can use the pwd command, this command means \u201cprint working directory\u201d and it just shows you which directory you are in, note the path stems from the root directory. $ pwd Where are you? Where am I? Give it a try. Quiz Questions Click the right arrow to view the answers How do I find what directory you are currently in? pwd","title":"Pwd"},{"location":"command-line/pwd/#pwd-print-working-directory","text":"Everything in Linux is a file, as you journey deeper into Linux you\u2019ll understand this, but for now just keep that in mind. Every file is organized in a hierarchical directory tree. The first directory in the filesystem is aptly named the root directory. The root directory has many folders and files which you can store more folders and files, etc. Here is an example of what the directory tree looks like: / |-- bin | |-- file1 | |-- file2 |-- etc | |-- file3 | `-- directory1 | |-- file4 | `-- file5 |-- home |-- var The location of these files and directories are referred to as paths. If you had a folder named home with a folder inside of it named mo and another folder in that folder called Movies, that path would look like this: /home/mo/Movies, pretty simple huh? Navigation of the filesystem, much like real life is helpful if you know where you are and where you are going. To see where you are, you can use the pwd command, this command means \u201cprint working directory\u201d and it just shows you which directory you are in, note the path stems from the root directory. $ pwd Where are you? Where am I? Give it a try.","title":"pwd (print working directory)"},{"location":"command-line/pwd/#quiz-questions","text":"Click the right arrow to view the answers How do I find what directory you are currently in? pwd","title":"Quiz Questions"},{"location":"command-line/rm/","text":"rm (remove) Now I think we have too many files, let\u2019s remove some files. To remove files you can use the rm command. The rm (remove) command is used to delete files and directories. $ rm file1 Take caution when using rm, there is no magical trash can that you can fish out removed files. Once they are gone, they are gone for good, so be careful. Fortunately there are some safety measures put into place, so the average joe can\u2019t just remove a bunch of important files. Write-protected files will prompt you for confirmation before deleting them. If a directory is write-protected it will also not be easily removed. Now if you don\u2019t care about any of that, you can absolutely remove a bunch of files. $ rm -f file1 -f or force option tells rm to remove all files, whether they are write protected or not, without prompting the user (as long as you have the appropriate permissions). $ rm -i file Adding the -i flag like many of the other commands, will give you a prompt on whether you want to actually remove the files or directories. $ rm -r directory You can\u2019t just rm a directory by default, you\u2019ll need to add the -r flag (recursive) to remove all the files and any subdirectories it may have. You can remove a directory with the rmdir command. $ rmdir directory Exercise Create a file called -file (don't forget the dash!). Remove that file. Quiz Questions Click the right arrow to view the answers How do you remove a file called myfile? rm myfile","title":"Remove"},{"location":"command-line/rm/#rm-remove","text":"Now I think we have too many files, let\u2019s remove some files. To remove files you can use the rm command. The rm (remove) command is used to delete files and directories. $ rm file1 Take caution when using rm, there is no magical trash can that you can fish out removed files. Once they are gone, they are gone for good, so be careful. Fortunately there are some safety measures put into place, so the average joe can\u2019t just remove a bunch of important files. Write-protected files will prompt you for confirmation before deleting them. If a directory is write-protected it will also not be easily removed. Now if you don\u2019t care about any of that, you can absolutely remove a bunch of files. $ rm -f file1 -f or force option tells rm to remove all files, whether they are write protected or not, without prompting the user (as long as you have the appropriate permissions). $ rm -i file Adding the -i flag like many of the other commands, will give you a prompt on whether you want to actually remove the files or directories. $ rm -r directory You can\u2019t just rm a directory by default, you\u2019ll need to add the -r flag (recursive) to remove all the files and any subdirectories it may have. You can remove a directory with the rmdir command. $ rmdir directory","title":"rm (remove)"},{"location":"command-line/rm/#exercise","text":"Create a file called -file (don't forget the dash!). Remove that file.","title":"Exercise"},{"location":"command-line/rm/#quiz-questions","text":"Click the right arrow to view the answers How do you remove a file called myfile? rm myfile","title":"Quiz Questions"},{"location":"command-line/the-shell/","text":"Shell The world is your oyster, or really the shell is your oyster. What is the shell? The shell is basically a program that takes your commands from the keyboard and sends them to the operating system to perform. If you\u2019ve ever used a GUI, you\u2019ve probably seen programs such as \u201cTerminal\u201d or \u201cConsole\u201d these are just programs that launch a shell for you. Throughout this entire course we will be learning about the wonders of the shell. In this course we will use the shell program bash (Bourne Again shell), almost all Linux distributions will default to the bash shell. There are other shells available such as ksh, zsh, tsch, but we won\u2019t get into any of those. Let\u2019s jump right in! Depending on the distribution your shell prompt might change, but for the most part it should adhere to the following format: username@hostname:current_directory mo@icebox:/home/mo $ Notice the $ at the end of the prompt? Different shells will have different prompts, in our case the $ is for a normal user using Bash, Bourne or Korn shell, you don't add the prompt symbol when you type the command, just know that it's there. Let\u2019s start with a simple command, echo. The echo command just prints out the text arguments to the display. $ echo Hello World Exercise Try some other Linux commands and see what they output: $ date $ whoami Quiz Questions Click the right arrow to view the answers What should be outputted to the display when you type echo FooBar? FooBar","title":"Shell"},{"location":"command-line/the-shell/#shell","text":"The world is your oyster, or really the shell is your oyster. What is the shell? The shell is basically a program that takes your commands from the keyboard and sends them to the operating system to perform. If you\u2019ve ever used a GUI, you\u2019ve probably seen programs such as \u201cTerminal\u201d or \u201cConsole\u201d these are just programs that launch a shell for you. Throughout this entire course we will be learning about the wonders of the shell. In this course we will use the shell program bash (Bourne Again shell), almost all Linux distributions will default to the bash shell. There are other shells available such as ksh, zsh, tsch, but we won\u2019t get into any of those. Let\u2019s jump right in! Depending on the distribution your shell prompt might change, but for the most part it should adhere to the following format: username@hostname:current_directory mo@icebox:/home/mo $ Notice the $ at the end of the prompt? Different shells will have different prompts, in our case the $ is for a normal user using Bash, Bourne or Korn shell, you don't add the prompt symbol when you type the command, just know that it's there. Let\u2019s start with a simple command, echo. The echo command just prints out the text arguments to the display. $ echo Hello World","title":"Shell"},{"location":"command-line/the-shell/#exercise","text":"Try some other Linux commands and see what they output: $ date $ whoami","title":"Exercise"},{"location":"command-line/the-shell/#quiz-questions","text":"Click the right arrow to view the answers What should be outputted to the display when you type echo FooBar? FooBar","title":"Quiz Questions"},{"location":"command-line/touch-command/","text":"touch Let\u2019s learn how to make some files. A very simple way is to use the touch command. Touch allows you to the create new empty files. $ touch mysuperduperfile And boom, new file! Touch is also used to change timestamps on existing files and directories. Give it a try, do an ls -l on a file and note the timestamp, then touch that file and it will update the timestamp. There are many other ways to create files that involve other things like redirection and text editors, but we\u2019ll get to that in the Text Manipulation course. Exercise Create a new file Note the timestamp Touch the file and check the timestamp once again Quiz Questions Click the right arrow to view the answers How do you create a file called myfile? touch myfile","title":"Touch"},{"location":"command-line/touch-command/#touch","text":"Let\u2019s learn how to make some files. A very simple way is to use the touch command. Touch allows you to the create new empty files. $ touch mysuperduperfile And boom, new file! Touch is also used to change timestamps on existing files and directories. Give it a try, do an ls -l on a file and note the timestamp, then touch that file and it will update the timestamp. There are many other ways to create files that involve other things like redirection and text editors, but we\u2019ll get to that in the Text Manipulation course.","title":"touch"},{"location":"command-line/touch-command/#exercise","text":"Create a new file Note the timestamp Touch the file and check the timestamp once again","title":"Exercise"},{"location":"command-line/touch-command/#quiz-questions","text":"Click the right arrow to view the answers How do you create a file called myfile? touch myfile","title":"Quiz Questions"},{"location":"command-line/whatis-command/","text":"whatis Whew, we\u2019ve learned quite a bit of commands so far, if you are ever feeling doubtful about what a command does, you can use the whatis command. The whatis command provides a brief description of command line programs. $ whatis cat The description gets sourced from the manual page of each command. If you ran whatis cat, you\u2019d see there is a small blurb with a short description. Exercise Run the whatis command on the less command. Quiz Questions Click the right arrow to view the answers What command can you use to see a small description of a command? whatis","title":"What is"},{"location":"command-line/whatis-command/#whatis","text":"Whew, we\u2019ve learned quite a bit of commands so far, if you are ever feeling doubtful about what a command does, you can use the whatis command. The whatis command provides a brief description of command line programs. $ whatis cat The description gets sourced from the manual page of each command. If you ran whatis cat, you\u2019d see there is a small blurb with a short description.","title":"whatis"},{"location":"command-line/whatis-command/#exercise","text":"Run the whatis command on the less command.","title":"Exercise"},{"location":"command-line/whatis-command/#quiz-questions","text":"Click the right arrow to view the answers What command can you use to see a small description of a command? whatis","title":"Quiz Questions"},{"location":"devices/dd-command/","text":"dd The dd tool is super useful for converting and copying data. It reads input from a file or data stream and writes it to a file or data stream. Consider the following command: $ dd if=/home/mo/backup.img of=/dev/sdb bs=1024 This command is copying the contents of backup.img to /dev/sdb. It will copy the data in blocks of 1024 bytes until there is no more data to be copied. if=file - Input file, read from a file instead of standard input of=file - Output file, write to a file instead of standard output bs=bytes - Block size, it reads and writes this many bytes of data at a time. You can use different size metrics by denoting the size with a k for kilobyte, m for megabyte, etc, so 1024 bytes is 1k count=number - Number of blocks to copy. You will see some dd commands that use the count option, usually with dd if you want to copy a file that is 1 megabyte, you'll usually want to see that file as 1 megabyte when it's done being copied. Let's say you run the following command: $ dd if=/home/mo/backup.img of=/dev/sdb bs=1M count=2 Our backup.img file is 10M, however, we are saying in this command to copy over 1M 2 times, so only 2M is being copied, leaving our copied data incomplete. Count can come in handy in many situations, but if you are just copying over data, you can pretty much omit count and even bs for that matter. If you really want to optimize your data transfers, then you'll want to start using those options. dd is extremely powerful, you can use it to make backups of anything, including whole disk drives, restoring disks images, and more. Be careful, that powerful tool can come at a price if you aren't sure what you are doing. Exercise Use the dd command to make a backup of your drive and set the output to a .img file. Quiz Questions Click the right arrow to view the answers What is the dd option for block size? bs","title":"DD command"},{"location":"devices/dd-command/#dd","text":"The dd tool is super useful for converting and copying data. It reads input from a file or data stream and writes it to a file or data stream. Consider the following command: $ dd if=/home/mo/backup.img of=/dev/sdb bs=1024 This command is copying the contents of backup.img to /dev/sdb. It will copy the data in blocks of 1024 bytes until there is no more data to be copied. if=file - Input file, read from a file instead of standard input of=file - Output file, write to a file instead of standard output bs=bytes - Block size, it reads and writes this many bytes of data at a time. You can use different size metrics by denoting the size with a k for kilobyte, m for megabyte, etc, so 1024 bytes is 1k count=number - Number of blocks to copy. You will see some dd commands that use the count option, usually with dd if you want to copy a file that is 1 megabyte, you'll usually want to see that file as 1 megabyte when it's done being copied. Let's say you run the following command: $ dd if=/home/mo/backup.img of=/dev/sdb bs=1M count=2 Our backup.img file is 10M, however, we are saying in this command to copy over 1M 2 times, so only 2M is being copied, leaving our copied data incomplete. Count can come in handy in many situations, but if you are just copying over data, you can pretty much omit count and even bs for that matter. If you really want to optimize your data transfers, then you'll want to start using those options. dd is extremely powerful, you can use it to make backups of anything, including whole disk drives, restoring disks images, and more. Be careful, that powerful tool can come at a price if you aren't sure what you are doing.","title":"dd"},{"location":"devices/dd-command/#exercise","text":"Use the dd command to make a backup of your drive and set the output to a .img file.","title":"Exercise"},{"location":"devices/dd-command/#quiz-questions","text":"Click the right arrow to view the answers What is the dd option for block size? bs","title":"Quiz Questions"},{"location":"devices/dev-directory/","text":"/dev directory When you connect a device to your machine, it generally needs a device driver to function properly. You can interact with device drivers through device files or device nodes, these are special files that look like regular files. Since these device files are just like regular files, you can use programs such as ls, cat, etc to interact with them. These device files are generally stored in the /dev directory. Go ahead and ls the /dev directory on your system, you'll see a large amount of devices files that are on your system. $ ls /dev Some of these devices you've already used and interacted with such as /dev/null. Remember when we send output to /dev/null, the kernel knows that this device takes all of our input and just discards it, so nothing gets returned. In the old days, if you wanted to add a device to your system, you'd add the device file in /dev and then probably forget about it. Well repeat that a couple of times and you can see where there was a problem. The /dev directory would get cluttered with static device files of devices that you've long since upgraded, stopped using, etc. Devices are also assigned device files in the order that the kernel finds them. So if everytime you rebooted your system, the devices could have different device files depending on when they were discovered. Thankfully we no longer use that method, now we have something that we use to dynamically add and remove devices that are currently being used on the system and we'll be discussing this in the coming lessons. Exercise Check out the contents of the /dev directory, do you recognize any familiar devices? Quiz Questions Click the right arrow to view the answers Where are device files stored on the system? /dev","title":"Dev directory"},{"location":"devices/dev-directory/#dev-directory","text":"When you connect a device to your machine, it generally needs a device driver to function properly. You can interact with device drivers through device files or device nodes, these are special files that look like regular files. Since these device files are just like regular files, you can use programs such as ls, cat, etc to interact with them. These device files are generally stored in the /dev directory. Go ahead and ls the /dev directory on your system, you'll see a large amount of devices files that are on your system. $ ls /dev Some of these devices you've already used and interacted with such as /dev/null. Remember when we send output to /dev/null, the kernel knows that this device takes all of our input and just discards it, so nothing gets returned. In the old days, if you wanted to add a device to your system, you'd add the device file in /dev and then probably forget about it. Well repeat that a couple of times and you can see where there was a problem. The /dev directory would get cluttered with static device files of devices that you've long since upgraded, stopped using, etc. Devices are also assigned device files in the order that the kernel finds them. So if everytime you rebooted your system, the devices could have different device files depending on when they were discovered. Thankfully we no longer use that method, now we have something that we use to dynamically add and remove devices that are currently being used on the system and we'll be discussing this in the coming lessons.","title":"/dev directory"},{"location":"devices/dev-directory/#exercise","text":"Check out the contents of the /dev directory, do you recognize any familiar devices?","title":"Exercise"},{"location":"devices/dev-directory/#quiz-questions","text":"Click the right arrow to view the answers Where are device files stored on the system? /dev","title":"Quiz Questions"},{"location":"devices/device-names/","text":"Device Names Here are the most common device names that you will encounter: SCSI Devices If you have any sort of mass storage on your machine, chances are it is using the SCSI (pronounced \"scuzzy\") protocol. SCSI stands for Small Computer System Interface, it is a protocol used for allow communication between disks, printers, scanners and other peripherals to your system. You may have heard of SCSI devices which aren't actually in use in modern systems, however our Linux systems correspond SCSI disks with hard disk drives in /dev. They are represented by a prefix of sd (SCSI disk): Common SCSI device files: /dev/sda - First hard disk /dev/sdb - Second hard disk /dev/sda3 - Third partition on the first hard disk Pseudo Devices As we discussed earlier, pseudo devices aren't really physically connected to your system, most common pseudo devices are character devices: /dev/zero - accepts and discards all input, produces a continuous stream of NULL (zero value) bytes /dev/null - accepts and discards all input, produces no output /dev/random - produces random numbers PATA Devices Sometimes in older systems you may see hard drives being referred to with an hd prefix: /dev/hda - First hard disk /dev/hdd2 - Second partition on 4th hard disk Exercise Write to the pseudo devices and see what happens, be careful not to write your disks to those devices! Quiz Questions Click the right arrow to view the answers What would commonly be the device name for the first partition on the second SCSI disk? sdb1","title":"Device Names"},{"location":"devices/device-names/#device-names","text":"Here are the most common device names that you will encounter: SCSI Devices If you have any sort of mass storage on your machine, chances are it is using the SCSI (pronounced \"scuzzy\") protocol. SCSI stands for Small Computer System Interface, it is a protocol used for allow communication between disks, printers, scanners and other peripherals to your system. You may have heard of SCSI devices which aren't actually in use in modern systems, however our Linux systems correspond SCSI disks with hard disk drives in /dev. They are represented by a prefix of sd (SCSI disk): Common SCSI device files: /dev/sda - First hard disk /dev/sdb - Second hard disk /dev/sda3 - Third partition on the first hard disk Pseudo Devices As we discussed earlier, pseudo devices aren't really physically connected to your system, most common pseudo devices are character devices: /dev/zero - accepts and discards all input, produces a continuous stream of NULL (zero value) bytes /dev/null - accepts and discards all input, produces no output /dev/random - produces random numbers PATA Devices Sometimes in older systems you may see hard drives being referred to with an hd prefix: /dev/hda - First hard disk /dev/hdd2 - Second partition on 4th hard disk","title":"Device Names"},{"location":"devices/device-names/#exercise","text":"Write to the pseudo devices and see what happens, be careful not to write your disks to those devices!","title":"Exercise"},{"location":"devices/device-names/#quiz-questions","text":"Click the right arrow to view the answers What would commonly be the device name for the first partition on the second SCSI disk? sdb1","title":"Quiz Questions"},{"location":"devices/device-types/","text":"Device types Before we chat about how devices are managed, let's actually take a look at some devices. $ ls -l /dev brw-rw---- 1 root disk 8, 0 Dec 4 15:11 sda crw-rw-rw- 1 root root 1, 3 Dec 4 15:11 null srw-rw-rw- 1 root root 0 Dec 4 15:11 log prw-r--r-- 1 root root 0 Dec 4 1:11 fdata The columns are as follows from left to right: Permissions Owner Group Major Device Number Minor Device Number Timestamp Device Name Remember in the ls command you can see the type of file with the first bit on each line. Device files are denoted as the following: c - character b - block p - pipe s - socket Character Device These devices transfer data, but one a character at a time. You'll see a lot of pseudo devices (/dev/null) as character devices, these devices aren't really physically connected to the machine, but they allow the operating system greater functionality. Block Device These devices transfer data, but in large fixed-sized blocks. You'll most commonly see devices that utilize data blocks as block devices, such as harddrives, filesystems, etc. Pipe Device Named pipes allow two or more processes to communicate with each other, these are similar to character devices, but instead of having output sent to a device, it's sent to another process. Socket Device Socket devices facilitate communication between processes, similar to pipe devices but they can communicate with many processes at once. Device Characterization Devices are characterized using two numbers, major device number and minor device number . You can see these numbers in the above ls example, they are separated by a comma. For example, let's say a device had the device numbers: 8, 0 : The major device number represents the device driver that is used, in this case 8, which is often the major number for sd block devices. The minor number tells the kernel which unique device it is in this driver class, in this case 0 is used to represent the first device (a). Exercise Look at your /dev directory and find out what types of devices you can see. Quiz Questions Click the right arrow to view the answers What is the symbol for character devices in the ls -l command? c","title":"Device Types"},{"location":"devices/device-types/#device-types","text":"Before we chat about how devices are managed, let's actually take a look at some devices. $ ls -l /dev brw-rw---- 1 root disk 8, 0 Dec 4 15:11 sda crw-rw-rw- 1 root root 1, 3 Dec 4 15:11 null srw-rw-rw- 1 root root 0 Dec 4 15:11 log prw-r--r-- 1 root root 0 Dec 4 1:11 fdata The columns are as follows from left to right: Permissions Owner Group Major Device Number Minor Device Number Timestamp Device Name Remember in the ls command you can see the type of file with the first bit on each line. Device files are denoted as the following: c - character b - block p - pipe s - socket Character Device These devices transfer data, but one a character at a time. You'll see a lot of pseudo devices (/dev/null) as character devices, these devices aren't really physically connected to the machine, but they allow the operating system greater functionality. Block Device These devices transfer data, but in large fixed-sized blocks. You'll most commonly see devices that utilize data blocks as block devices, such as harddrives, filesystems, etc. Pipe Device Named pipes allow two or more processes to communicate with each other, these are similar to character devices, but instead of having output sent to a device, it's sent to another process. Socket Device Socket devices facilitate communication between processes, similar to pipe devices but they can communicate with many processes at once. Device Characterization Devices are characterized using two numbers, major device number and minor device number . You can see these numbers in the above ls example, they are separated by a comma. For example, let's say a device had the device numbers: 8, 0 : The major device number represents the device driver that is used, in this case 8, which is often the major number for sd block devices. The minor number tells the kernel which unique device it is in this driver class, in this case 0 is used to represent the first device (a).","title":"Device types"},{"location":"devices/device-types/#exercise","text":"Look at your /dev directory and find out what types of devices you can see.","title":"Exercise"},{"location":"devices/device-types/#quiz-questions","text":"Click the right arrow to view the answers What is the symbol for character devices in the ls -l command? c","title":"Quiz Questions"},{"location":"devices/listing-devices/","text":"Listing devices - lsusb, lspci, lssci Just like we would use the ls command to list files and directories, we can use similar tools that list information about devices. Listing USB Devices $ lsusb Listing PCI Devices $ lspci Listing SCSI Devices $ lsscsi Exercise Try out each of these commands and see the output you receive. Quiz Questions Click the right arrow to view the answers What command can be used to view usb devices? lsusb","title":"Listing Devices"},{"location":"devices/listing-devices/#listing-devices-lsusb-lspci-lssci","text":"Just like we would use the ls command to list files and directories, we can use similar tools that list information about devices. Listing USB Devices $ lsusb Listing PCI Devices $ lspci Listing SCSI Devices $ lsscsi","title":"Listing devices - lsusb, lspci, lssci"},{"location":"devices/listing-devices/#exercise","text":"Try out each of these commands and see the output you receive.","title":"Exercise"},{"location":"devices/listing-devices/#quiz-questions","text":"Click the right arrow to view the answers What command can be used to view usb devices? lsusb","title":"Quiz Questions"},{"location":"devices/sysfs/","text":"sysfs Sysfs was created long ago to better manage devices on our system that the /dev directory failed to do. Sysfs is a virtual filesystem, most often mounted to the /sys directory. It gives us more detailed information than what we would be able to see in the /dev directory. Both directories /sys and /dev seem to be very similar and they are in some regards, but they do have major differences. Basically, the /dev directory is simple, it allows other programs to access devices themselves, while the /sys filesystem is used to view information and manage the device. The /sys filesystem basically contains all the information for all devices on your system, such as the manufacturer and model, where the device is plugged in, the state of the device, the hierarchy of devices and more. The files you see here aren't device nodes, so you don't really interact with devices from the /sys directory, rather you are managing devices. Take a look at the contents of the /sys directory: mo:~$ ls /sys/block/sda alignment_offset discard_alignment holders removable sda6 trace bdi events inflight ro size uevent capability events_async power sda1 slaves dev events_poll_msecs queue sda2 stat device ext_range range sda5 subsystem Exercise Check out the contents of the /sys directory and see what files are located in there. Quiz Questions Click the right arrow to view the answers What directory is used to view detailed information on devices? /sys","title":"Sysfs"},{"location":"devices/sysfs/#sysfs","text":"Sysfs was created long ago to better manage devices on our system that the /dev directory failed to do. Sysfs is a virtual filesystem, most often mounted to the /sys directory. It gives us more detailed information than what we would be able to see in the /dev directory. Both directories /sys and /dev seem to be very similar and they are in some regards, but they do have major differences. Basically, the /dev directory is simple, it allows other programs to access devices themselves, while the /sys filesystem is used to view information and manage the device. The /sys filesystem basically contains all the information for all devices on your system, such as the manufacturer and model, where the device is plugged in, the state of the device, the hierarchy of devices and more. The files you see here aren't device nodes, so you don't really interact with devices from the /sys directory, rather you are managing devices. Take a look at the contents of the /sys directory: mo:~$ ls /sys/block/sda alignment_offset discard_alignment holders removable sda6 trace bdi events inflight ro size uevent capability events_async power sda1 slaves dev events_poll_msecs queue sda2 stat device ext_range range sda5 subsystem","title":"sysfs"},{"location":"devices/sysfs/#exercise","text":"Check out the contents of the /sys directory and see what files are located in there.","title":"Exercise"},{"location":"devices/sysfs/#quiz-questions","text":"Click the right arrow to view the answers What directory is used to view detailed information on devices? /sys","title":"Quiz Questions"},{"location":"devices/udev/","text":"udev Lesson Content Back in the old days and actually today if you really wanted to, you would create device nodes using a command such as: $ mknod /dev/sdb1 b 8 3 This command will make a device node /dev/sdb1 and it will make it a block device (b) with a major number of 8 and a minor number of 3. To remove a device, you would simply rm the device file in the /dev directory. Luckily, we really don't need to do this anymore because of udev. The udev system dynamically creates and removes device files for us depending on whether or not they are connected. There is a udevd daemon that is running on the system and it listens for messages from the kernel about devices connected to the system. Udevd will parse that information and it will match the data with the rules that are specified in /etc/udev/rules.d, depending on those rules it will most likely create device nodes and symbolic links for the devices. You can write your own udev rules, but that is a little out of scope for this lesson. Fortunately, your system already comes with lots of udev rules so you may never need to write your own. You can also view the udev database and sysfs using the udevadm command. This tool is very useful, but sometimes can get very convoluted, a simple command to view information for a device would be: $ udevadm info --query=all --name=/dev/sda Exercise Run the udevadm command given and check out the input. Quiz Questions Click the right arrow to view the answers What dynamically adds and removes devices? udev","title":"Udev"},{"location":"devices/udev/#udev","text":"","title":"udev"},{"location":"devices/udev/#lesson-content","text":"Back in the old days and actually today if you really wanted to, you would create device nodes using a command such as: $ mknod /dev/sdb1 b 8 3 This command will make a device node /dev/sdb1 and it will make it a block device (b) with a major number of 8 and a minor number of 3. To remove a device, you would simply rm the device file in the /dev directory. Luckily, we really don't need to do this anymore because of udev. The udev system dynamically creates and removes device files for us depending on whether or not they are connected. There is a udevd daemon that is running on the system and it listens for messages from the kernel about devices connected to the system. Udevd will parse that information and it will match the data with the rules that are specified in /etc/udev/rules.d, depending on those rules it will most likely create device nodes and symbolic links for the devices. You can write your own udev rules, but that is a little out of scope for this lesson. Fortunately, your system already comes with lots of udev rules so you may never need to write your own. You can also view the udev database and sysfs using the udevadm command. This tool is very useful, but sometimes can get very convoluted, a simple command to view information for a device would be: $ udevadm info --query=all --name=/dev/sda","title":"Lesson Content"},{"location":"devices/udev/#exercise","text":"Run the udevadm command given and check out the input.","title":"Exercise"},{"location":"devices/udev/#quiz-questions","text":"Click the right arrow to view the answers What dynamically adds and removes devices? udev","title":"Quiz Questions"},{"location":"dns/dns-components/","text":"DNS Components The DNS database of the Internet relies on sites and organizations providing part of that database. To do that, they need: Name Server We setup DNS via \"name servers\", the name servers load up our DNS settings and configs and answers any questions from clients or other servers that want to know things like \"Who is google.com?\". If the name server doesn't know the answer to that query, it will redirect the request to other name servers. Name servers can be \"authoritative\", meaning they hold the actual DNS records that you're looking for, or \"recursive\" meaning they would ask other servers and those servers would ask other servers until they found an authoritative server that contained the DNS records. Recursive servers can also have the information we want cached instead of reaching an authoritative server. Zone File Inside a name server lives something called zone files. Zone files are how the name server stores information about the domain or how to get to the domain if it doesn't know. Resource Records A zone file is comprised of entries of resource records. Each line is a record and contains information about hosts, nameservers, other resources, etc. The fields consist of the following: Record name TTL - The time after which we discard the record and obtain a new one, in DNS TTL is denoted by time, so records could have a TTL of one hour. The reason we do this is because the Internet is constantly changing, one minute a host can be mapped to X IP address then next it can be at Y IP address Class - Namespace of the record information, most commonly IN is used for Internet Type - Type of information stored in the record data. We won't get into record types, but you've probably seen common ones like A for address, MX or mail exchanger, etc. Data - This field can contain an IP address if it's an A record or something else depending on the record type. patty IN A 192.168.0.4 Quiz Questions Click the right arrow to view the answers What resource record type is used for mail exchangers? MX","title":"Components"},{"location":"dns/dns-components/#dns-components","text":"The DNS database of the Internet relies on sites and organizations providing part of that database. To do that, they need: Name Server We setup DNS via \"name servers\", the name servers load up our DNS settings and configs and answers any questions from clients or other servers that want to know things like \"Who is google.com?\". If the name server doesn't know the answer to that query, it will redirect the request to other name servers. Name servers can be \"authoritative\", meaning they hold the actual DNS records that you're looking for, or \"recursive\" meaning they would ask other servers and those servers would ask other servers until they found an authoritative server that contained the DNS records. Recursive servers can also have the information we want cached instead of reaching an authoritative server. Zone File Inside a name server lives something called zone files. Zone files are how the name server stores information about the domain or how to get to the domain if it doesn't know. Resource Records A zone file is comprised of entries of resource records. Each line is a record and contains information about hosts, nameservers, other resources, etc. The fields consist of the following: Record name TTL - The time after which we discard the record and obtain a new one, in DNS TTL is denoted by time, so records could have a TTL of one hour. The reason we do this is because the Internet is constantly changing, one minute a host can be mapped to X IP address then next it can be at Y IP address Class - Namespace of the record information, most commonly IN is used for Internet Type - Type of information stored in the record data. We won't get into record types, but you've probably seen common ones like A for address, MX or mail exchanger, etc. Data - This field can contain an IP address if it's an A record or something else depending on the record type. patty IN A 192.168.0.4","title":"DNS Components"},{"location":"dns/dns-components/#quiz-questions","text":"Click the right arrow to view the answers What resource record type is used for mail exchangers? MX","title":"Quiz Questions"},{"location":"dns/dns-process/","text":"DNS Process Let's look at an example of how your host finds a domain (google.com) with DNS. Essentially, we funnel our way down until we reach the DNS server that knows of that domain. Local DNS Server First our host asks, \"Where is google.com?\", our local DNS server doesn't know so it goes and starts from the top of the funnel to ask the Root Servers. Keep in mind that our host is not making these requests to find google.com directly, most users talk to a recursive DNS server provided by their ISPs and that server is then tasked to find the location of google.com. Root Servers There are 13 Root Servers for the Internet, they are mirrored and distributed around the world to handle DNS requests for the Internet, so there are really hundreds of servers that are working, they are controlled by different organizations and they contain information about Top-Level Domains. Top-level domains are what you know as .org, .com, .net, etc addresses. So the Root Server doesn't know where google.com is, so it tells us ask the .com Top-Level Domain DNS Server at an IP address it gives us. Top-Level Domain So now we send another request to the name server that knows about \".com\" addresses and asks if it knows where google.com is? The TLD doesn't have the google.com in their zone files, but it does see a record for the name server for google.com. So it gives us the IP address of that name server and tells us to look there. Authoritative DNS Server Now we send a final request to the DNS server that actually has the record we want. The name server sees that it has a zone file for google.com and there is a resource record for 'www' for this host. It then gives us the IP address of this host and we can finally see some cats on the Internet. Quiz Questions Click the right arrow to view the answers What is the abbreviation for the nameservers where .com, .net, .org, etc addresses are found? TLD","title":"Process"},{"location":"dns/dns-process/#dns-process","text":"Let's look at an example of how your host finds a domain (google.com) with DNS. Essentially, we funnel our way down until we reach the DNS server that knows of that domain. Local DNS Server First our host asks, \"Where is google.com?\", our local DNS server doesn't know so it goes and starts from the top of the funnel to ask the Root Servers. Keep in mind that our host is not making these requests to find google.com directly, most users talk to a recursive DNS server provided by their ISPs and that server is then tasked to find the location of google.com. Root Servers There are 13 Root Servers for the Internet, they are mirrored and distributed around the world to handle DNS requests for the Internet, so there are really hundreds of servers that are working, they are controlled by different organizations and they contain information about Top-Level Domains. Top-level domains are what you know as .org, .com, .net, etc addresses. So the Root Server doesn't know where google.com is, so it tells us ask the .com Top-Level Domain DNS Server at an IP address it gives us. Top-Level Domain So now we send another request to the name server that knows about \".com\" addresses and asks if it knows where google.com is? The TLD doesn't have the google.com in their zone files, but it does see a record for the name server for google.com. So it gives us the IP address of that name server and tells us to look there. Authoritative DNS Server Now we send a final request to the DNS server that actually has the record we want. The name server sees that it has a zone file for google.com and there is a resource record for 'www' for this host. It then gives us the IP address of this host and we can finally see some cats on the Internet.","title":"DNS Process"},{"location":"dns/dns-process/#quiz-questions","text":"Click the right arrow to view the answers What is the abbreviation for the nameservers where .com, .net, .org, etc addresses are found? TLD","title":"Quiz Questions"},{"location":"dns/dns-setup/","text":"DNS Setup We won't got through setting up a DNS server, as that would be quite a lengthy tutorial. Instead here is a quick comparison list of the popular DNS servers to use with Linux. BIND The most popular DNS server on the Internet, it's the standard that is used with Linux distributions. It was originally developed at the University of California at Berkeley hence the name BIND (Berkeley Internet Name Domain). If you need full-featured power and flexibility, you can't go wrong with BIND. DNSmasq Lightweight and much easier to configure than BIND. If you want simplicity and don't need all the bells and whistles of BIND, use DNSmasq. It comes with all the tools you need to setup DHCP and DNS, recommended for a smaller network. PowerDNS Full-featured and similar to BIND, it offers you a little bit more flexibility with options. It reads information from multiple databases such as MySQL, PostgreSQL, etc. for easier administration. Just because BIND has been the way we do things, it doesn't mean it has to stay that way. This isn't a complete list, but it should give you an idea of where to look if you are setting up your own DNS server. Quiz Questions Click the right arrow to view the answers What is the de facto DNS server for Linux? BIND","title":"Setup"},{"location":"dns/dns-setup/#dns-setup","text":"We won't got through setting up a DNS server, as that would be quite a lengthy tutorial. Instead here is a quick comparison list of the popular DNS servers to use with Linux. BIND The most popular DNS server on the Internet, it's the standard that is used with Linux distributions. It was originally developed at the University of California at Berkeley hence the name BIND (Berkeley Internet Name Domain). If you need full-featured power and flexibility, you can't go wrong with BIND. DNSmasq Lightweight and much easier to configure than BIND. If you want simplicity and don't need all the bells and whistles of BIND, use DNSmasq. It comes with all the tools you need to setup DHCP and DNS, recommended for a smaller network. PowerDNS Full-featured and similar to BIND, it offers you a little bit more flexibility with options. It reads information from multiple databases such as MySQL, PostgreSQL, etc. for easier administration. Just because BIND has been the way we do things, it doesn't mean it has to stay that way. This isn't a complete list, but it should give you an idea of where to look if you are setting up your own DNS server.","title":"DNS Setup"},{"location":"dns/dns-setup/#quiz-questions","text":"Click the right arrow to view the answers What is the de facto DNS server for Linux? BIND","title":"Quiz Questions"},{"location":"dns/dns-tools/","text":"DNS Tools nslookup The \"name server lookup\" tool is used to query name servers to find information about resource records. Let's find where the name server for google.com is: mo:~$ nslookup www.google.com Server: 127.0.1.1 Address: 127.0.1.1#53 Non-authoritative answer: Name: www.google.com Address: 216.58.192.4 dig Dig (domain information groper) is a powerful tool for getting information about DNS name servers, it is more flexible than nslookup and great for troubleshooting DNS issues. mo:~$ dig www.google.com ; < < >> DiG 9.9.5-3-Ubuntu < < >> www.google.com ;; global options: +cmd ;; Got answer: ;; ->>HEADER < < - opcode: QUERY, status: NOERROR, id: 42376 ;; flags: qr rd ra; QUERY: 1, ANSWER: 5, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; MBZ: 0005 , udp: 512 ;; QUESTION SECTION: ;www.google.com. IN A ;; ANSWER SECTION: www.google.com. 5 IN A 74.125.239.147 www.google.com. 5 IN A 74.125.239.144 www.google.com. 5 IN A 74.125.239.146 www.google.com. 5 IN A 74.125.239.145 www.google.com. 5 IN A 74.125.239.148 ;; Query time: 27 msec ;; SERVER: 127.0.1.1#53(127.0.1.1) ;; WHEN: Mon Dec 04 10:14:00 GMT 2023 ;; MSG SIZE rcvd: 123 Exercise Read up on the manpage for dig. Quiz Questions Click the right arrow to view the answers What tool is used to get detailed information about DNS name servers? dig","title":"Tools"},{"location":"dns/dns-tools/#dns-tools","text":"nslookup The \"name server lookup\" tool is used to query name servers to find information about resource records. Let's find where the name server for google.com is: mo:~$ nslookup www.google.com Server: 127.0.1.1 Address: 127.0.1.1#53 Non-authoritative answer: Name: www.google.com Address: 216.58.192.4 dig Dig (domain information groper) is a powerful tool for getting information about DNS name servers, it is more flexible than nslookup and great for troubleshooting DNS issues. mo:~$ dig www.google.com ; < < >> DiG 9.9.5-3-Ubuntu < < >> www.google.com ;; global options: +cmd ;; Got answer: ;; ->>HEADER < < - opcode: QUERY, status: NOERROR, id: 42376 ;; flags: qr rd ra; QUERY: 1, ANSWER: 5, AUTHORITY: 0, ADDITIONAL: 1 ;; OPT PSEUDOSECTION: ; EDNS: version: 0, flags:; MBZ: 0005 , udp: 512 ;; QUESTION SECTION: ;www.google.com. IN A ;; ANSWER SECTION: www.google.com. 5 IN A 74.125.239.147 www.google.com. 5 IN A 74.125.239.144 www.google.com. 5 IN A 74.125.239.146 www.google.com. 5 IN A 74.125.239.145 www.google.com. 5 IN A 74.125.239.148 ;; Query time: 27 msec ;; SERVER: 127.0.1.1#53(127.0.1.1) ;; WHEN: Mon Dec 04 10:14:00 GMT 2023 ;; MSG SIZE rcvd: 123","title":"DNS Tools"},{"location":"dns/dns-tools/#exercise","text":"Read up on the manpage for dig.","title":"Exercise"},{"location":"dns/dns-tools/#quiz-questions","text":"Click the right arrow to view the answers What tool is used to get detailed information about DNS name servers? dig","title":"Quiz Questions"},{"location":"dns/etc-hosts/","text":"/etc/hosts Before our machine actually hits DNS to do a query, it first looks locally on our machines. /etc/hosts The /etc/hosts file contains mappings of some hostnames to IP addresses. The fields are pretty self explanatory, there is one for the IP address, the hostname and then any alias's for the host. mo:~$ cat /etc/hosts 127.0.0.1 localhost 127.0.1.1 icebox You'll typically see your localhost address listed as a default in this file. You can also manage access to hosts by modifying the /etc/hosts.deny or /etc/hosts.allow files. However, if you were security conscientious, this isn't really the way to go and you should be modifying your firewall rules instead. Let's see a fun example of /etc/hosts. Modify the file and add a line for: 123.45.6.7 www.google.com Save the file and now go to www.google.com. Having issues aren't you? Well that's because we just mapped www.google.com to a completely wrong IP address. Since our hosts first look locally for IP address mappings, it never reaches DNS to find google.com. /etc/resolv.conf Traditionally, we've used a file called /etc/resolv.conf to map DNS name servers for more efficient lookups, however with the improvements made to DNS this file is quite often irrelevant, in fact, you can see in my example below that /etc/resolv.conf isn't managed manually. Refer to your distribution specific settings to manage DNS name server mappings. conf(5) file for glibc resolver(3) generated by resolvconf(8) # DO NOT EDIT THIS FILE BY HAND -- YOUR CHANGES WILL BE OVERWRITTEN nameserver 127.0.1.1 search localdomain Quiz Questions Click the right arrow to view the answers What file is used to map hostnames to IP addresses on our machines? /etc/hosts","title":"etc-hosts"},{"location":"dns/etc-hosts/#etchosts","text":"Before our machine actually hits DNS to do a query, it first looks locally on our machines. /etc/hosts The /etc/hosts file contains mappings of some hostnames to IP addresses. The fields are pretty self explanatory, there is one for the IP address, the hostname and then any alias's for the host. mo:~$ cat /etc/hosts 127.0.0.1 localhost 127.0.1.1 icebox You'll typically see your localhost address listed as a default in this file. You can also manage access to hosts by modifying the /etc/hosts.deny or /etc/hosts.allow files. However, if you were security conscientious, this isn't really the way to go and you should be modifying your firewall rules instead. Let's see a fun example of /etc/hosts. Modify the file and add a line for: 123.45.6.7 www.google.com Save the file and now go to www.google.com. Having issues aren't you? Well that's because we just mapped www.google.com to a completely wrong IP address. Since our hosts first look locally for IP address mappings, it never reaches DNS to find google.com. /etc/resolv.conf Traditionally, we've used a file called /etc/resolv.conf to map DNS name servers for more efficient lookups, however with the improvements made to DNS this file is quite often irrelevant, in fact, you can see in my example below that /etc/resolv.conf isn't managed manually. Refer to your distribution specific settings to manage DNS name server mappings. conf(5) file for glibc resolver(3) generated by resolvconf(8) # DO NOT EDIT THIS FILE BY HAND -- YOUR CHANGES WILL BE OVERWRITTEN nameserver 127.0.1.1 search localdomain","title":"/etc/hosts"},{"location":"dns/etc-hosts/#quiz-questions","text":"Click the right arrow to view the answers What file is used to map hostnames to IP addresses on our machines? /etc/hosts","title":"Quiz Questions"},{"location":"dns/what-is-dns/","text":"What is DNS? Imagine if every time you wanted to do a search on Google you had to type in http://192.78.12.4 instead of www.google.com. Well without DNS (\"Domain Name System\") that's exactly what would happen. Low level networking only understands the raw IP address to identify a host. DNS allows us humans to keep track of websites and hosts by name instead of an IP address. It's like a contact list for the Internet. If you know someone's name but don\u2019t know their phone number, you can simply look it up in your contacts list. DNS is fundamentally a distributed database of hostnames to IP addresses, we manage our database so people know how to get to our site/domain, and somewhere else another person is managing their database so others can get to their domain. These domains are then able to talk to each other and build a massive contact list of the Internet. In this course, we will go over some basics of DNS, but be wary that DNS is an exhaustive topic and if you really want to get down and dirty with it, you'll need to do some additional research. Quiz Questions Click the right arrow to view the answers True or false, DNS helps us find MAC addresses for hostnames? false","title":"What is DNS?"},{"location":"dns/what-is-dns/#what-is-dns","text":"Imagine if every time you wanted to do a search on Google you had to type in http://192.78.12.4 instead of www.google.com. Well without DNS (\"Domain Name System\") that's exactly what would happen. Low level networking only understands the raw IP address to identify a host. DNS allows us humans to keep track of websites and hosts by name instead of an IP address. It's like a contact list for the Internet. If you know someone's name but don\u2019t know their phone number, you can simply look it up in your contacts list. DNS is fundamentally a distributed database of hostnames to IP addresses, we manage our database so people know how to get to our site/domain, and somewhere else another person is managing their database so others can get to their domain. These domains are then able to talk to each other and build a massive contact list of the Internet. In this course, we will go over some basics of DNS, but be wary that DNS is an exhaustive topic and if you really want to get down and dirty with it, you'll need to do some additional research.","title":"What is DNS?"},{"location":"dns/what-is-dns/#quiz-questions","text":"Click the right arrow to view the answers True or false, DNS helps us find MAC addresses for hostnames? false","title":"Quiz Questions"},{"location":"filesystem/anatomy-of-a-disk/","text":"Anatomy of a Disk Hard disks can be subdivided into partitions, essentially making multiple block devices. Recall such examples as, /dev/sda1 and /dev/sda2, /dev/sda is the whole disk, but /dev/sda1 is the first partition on that disk. Partitions are extremely useful for separating data and if you need a certain filesystem, you can easily create a partition instead of making the entire disk one filesystem type. Partition Table Every disk will have a partition table, this table tells the system how the disk is partitioned. This table tells you where partitions begin and end, which partitions are bootable, what sectors of the disk are allocated to what partition, etc. There are two main partition table schemes used, Master Boot Record (MBR) and GUID Partition Table (GPT). Partition Disks are comprised of partitions that help us organize our data. You can have multiple partitions on a disk and they can't overlap each other. If there is space that is not allocated to a partition, then it is known as free space. The types of partitions depend on your partition table. Inside a partition, you can have a filesystem or dedicate a partition to other things like swap (we'll get to that soon). MBR Traditional partition table, was used as the standard Can have primary, extended, and logical partitions MBR has a limit of four primary partitions Additional partitions can be made by making a primary partition into an extended partition (there can only be one extended partition on a disk). Then inside the extended partition you add logical partitions. The logical partitions are used just like any other partition. Silly I know. Supports disks up to 2 terabytes GPT GUID Partition Table (GPT) is becoming the new standard for disk partitioning Has only one type of partition and you can make many of them Each partition has a globally unique ID (GUID) Used mostly in conjunction with UEFI based booting (we'll get into details in another course) Filesystem Structure We know from our previous lesson that a filesystem is an organized collection of files and directories. In its simplest form, it is comprised of a database to manage files and the actual files themselves, however we're going to go into a little more detail. Boot block - This is located in the first few sectors of the filesystem, and it's not really used the by the filesystem. Rather, it contains information used to boot the operating system. Only one boot block is needed by the operating system. If you have multiple partitions, they will have boot blocks, but many of them are unused. Super block - This is a single block that comes after the boot block, and it contains information about the filesystem, such as the size of the inode table, size of the logical blocks and the size of the filesystem. Inode table - Think of this as the database that manages our files (we have a whole lesson on inodes, so don't worry). Each file or directory has a unique entry in the inode table and it has various information about the file. Data blocks - This is the actual data for the files and directories. Let's take a look at the different partition tables. Below is an example of a partition using the MBR partitioning table (msdos). You can see the primary, extended and logical partitions on the machine. mo:~$ sudo parted -l Model: Seagate (scsi) Disk /dev/sda: 21.5GB Sector size (logical/physical): 512B/512B Partition Table: msdos Number Start End Size Type File system Flags 1 1049kB 6860MB 6859MB primary ext4 boot 2 6861MB 21.5GB 14.6GB extended 5 6861MB 7380MB 519MB logical linux-swap(v1) 6 7381MB 21.5GB 14.1GB logical xfs This example is GPT, using just a unique ID for the partitions. Model: Thumb Drive (scsi) Disk /dev/sdb: 4041MB Sector size (logical/physical): 512B/512B Partition Table: gpt Number Start End Size File system Name Flags 1 17.4kB 1000MB 1000MB first 2 1000MB 4040MB 3040MB second Exercise Run parted -l on your machine and evaluate your results. Quiz Questions Click the right arrow to view the answers What partition type is used to create more than 4 partitions in the MBR partitioning scheme? extended","title":"Anatomy of a disk"},{"location":"filesystem/anatomy-of-a-disk/#anatomy-of-a-disk","text":"Hard disks can be subdivided into partitions, essentially making multiple block devices. Recall such examples as, /dev/sda1 and /dev/sda2, /dev/sda is the whole disk, but /dev/sda1 is the first partition on that disk. Partitions are extremely useful for separating data and if you need a certain filesystem, you can easily create a partition instead of making the entire disk one filesystem type. Partition Table Every disk will have a partition table, this table tells the system how the disk is partitioned. This table tells you where partitions begin and end, which partitions are bootable, what sectors of the disk are allocated to what partition, etc. There are two main partition table schemes used, Master Boot Record (MBR) and GUID Partition Table (GPT). Partition Disks are comprised of partitions that help us organize our data. You can have multiple partitions on a disk and they can't overlap each other. If there is space that is not allocated to a partition, then it is known as free space. The types of partitions depend on your partition table. Inside a partition, you can have a filesystem or dedicate a partition to other things like swap (we'll get to that soon). MBR Traditional partition table, was used as the standard Can have primary, extended, and logical partitions MBR has a limit of four primary partitions Additional partitions can be made by making a primary partition into an extended partition (there can only be one extended partition on a disk). Then inside the extended partition you add logical partitions. The logical partitions are used just like any other partition. Silly I know. Supports disks up to 2 terabytes GPT GUID Partition Table (GPT) is becoming the new standard for disk partitioning Has only one type of partition and you can make many of them Each partition has a globally unique ID (GUID) Used mostly in conjunction with UEFI based booting (we'll get into details in another course) Filesystem Structure We know from our previous lesson that a filesystem is an organized collection of files and directories. In its simplest form, it is comprised of a database to manage files and the actual files themselves, however we're going to go into a little more detail. Boot block - This is located in the first few sectors of the filesystem, and it's not really used the by the filesystem. Rather, it contains information used to boot the operating system. Only one boot block is needed by the operating system. If you have multiple partitions, they will have boot blocks, but many of them are unused. Super block - This is a single block that comes after the boot block, and it contains information about the filesystem, such as the size of the inode table, size of the logical blocks and the size of the filesystem. Inode table - Think of this as the database that manages our files (we have a whole lesson on inodes, so don't worry). Each file or directory has a unique entry in the inode table and it has various information about the file. Data blocks - This is the actual data for the files and directories. Let's take a look at the different partition tables. Below is an example of a partition using the MBR partitioning table (msdos). You can see the primary, extended and logical partitions on the machine. mo:~$ sudo parted -l Model: Seagate (scsi) Disk /dev/sda: 21.5GB Sector size (logical/physical): 512B/512B Partition Table: msdos Number Start End Size Type File system Flags 1 1049kB 6860MB 6859MB primary ext4 boot 2 6861MB 21.5GB 14.6GB extended 5 6861MB 7380MB 519MB logical linux-swap(v1) 6 7381MB 21.5GB 14.1GB logical xfs This example is GPT, using just a unique ID for the partitions. Model: Thumb Drive (scsi) Disk /dev/sdb: 4041MB Sector size (logical/physical): 512B/512B Partition Table: gpt Number Start End Size File system Name Flags 1 17.4kB 1000MB 1000MB first 2 1000MB 4040MB 3040MB second","title":"Anatomy of a Disk"},{"location":"filesystem/anatomy-of-a-disk/#exercise","text":"Run parted -l on your machine and evaluate your results.","title":"Exercise"},{"location":"filesystem/anatomy-of-a-disk/#quiz-questions","text":"Click the right arrow to view the answers What partition type is used to create more than 4 partitions in the MBR partitioning scheme? extended","title":"Quiz Questions"},{"location":"filesystem/creating-filesystems/","text":"Creating Filesystems Now that you've actually partitioned a disk, let's create a filesystem! $ sudo mkfs -t ext4 /dev/sdb2 Simple as that! The mkfs (make filesystem) tool allows us to specify the type of filesystem we want and where we want it. You'll only want to create a filesystem on a newly partitioned disk or if you are repartitioning an old one. You'll most likely leave your filesystem in a corrupted state if you try to create one on top of an existing one. Quiz Questions Click the right arrow to view the answers Make an ext4 filesystem on the USB drive. mkfs","title":"Creating filesytems"},{"location":"filesystem/creating-filesystems/#creating-filesystems","text":"Now that you've actually partitioned a disk, let's create a filesystem! $ sudo mkfs -t ext4 /dev/sdb2 Simple as that! The mkfs (make filesystem) tool allows us to specify the type of filesystem we want and where we want it. You'll only want to create a filesystem on a newly partitioned disk or if you are repartitioning an old one. You'll most likely leave your filesystem in a corrupted state if you try to create one on top of an existing one.","title":"Creating Filesystems"},{"location":"filesystem/creating-filesystems/#quiz-questions","text":"Click the right arrow to view the answers Make an ext4 filesystem on the USB drive. mkfs","title":"Quiz Questions"},{"location":"filesystem/disk-partitioning/","text":"Disk Partitioning Let's do some practical stuff with filesytems by working through the process on a USB drive. If you don't have one, no worries, you can still follow along these next couple of lessons. First we'll need to partition our disk. There are many tools available to do this: fdisk - basic command-line partitioning tool, it does not support GPT parted - this is a command line tool that supports both MBR and GPT partitioning gparted - this is the GUI version of parted gdisk - fdisk, but it does not support MBR only GPT Let's use parted to do our partitioning. Let's say I connect the USB device and we see the device name is /dev/sdb2. Launch parted $ sudo parted You'll be entered in the parted tool, here you can run commands to partition your device. Select the device select /dev/sdb2 To select the device you'll be working with, select it by its device name. View current partition table (parted) print Model: Seagate (scsi) Disk /dev/sda: 21.5GB Sector size (logical/physical): 512B/512B Partition Table: msdos Number Start End Size Type File system Flags 1 1049kB 6860MB 6859MB primary ext4 boot 2 6861MB 21.5GB 14.6GB extended 5 6861MB 7380MB 519MB logical linux-swap(v1) 6 7381MB 21.5GB 14.1GB logical xfs Here you will see the available partitions on the device. The start and end points are where the partitions take up space on the hard drive, you'll want to find a good start and end location for your partitions. Partition the device mkpart primary 123 4567 Now just choose a start and end point and make the partition, you'll need to specify the type of partition depending on what table you used. Resize a partition You can also resize a partition if you don't have any space. resize 2 1245 3456 Select the partition number and then the start and end points of where you want to resize it to. Parted is a very powerful tool and you should be careful when partitioning your disks. Exercise Partition a USB drive with half of the drive as ext4 and the other half as free space. Quiz Questions Click the right arrow to view the answers What is the parted command to make a partition? mkpart","title":"Disk partitioning"},{"location":"filesystem/disk-partitioning/#disk-partitioning","text":"Let's do some practical stuff with filesytems by working through the process on a USB drive. If you don't have one, no worries, you can still follow along these next couple of lessons. First we'll need to partition our disk. There are many tools available to do this: fdisk - basic command-line partitioning tool, it does not support GPT parted - this is a command line tool that supports both MBR and GPT partitioning gparted - this is the GUI version of parted gdisk - fdisk, but it does not support MBR only GPT Let's use parted to do our partitioning. Let's say I connect the USB device and we see the device name is /dev/sdb2. Launch parted $ sudo parted You'll be entered in the parted tool, here you can run commands to partition your device. Select the device select /dev/sdb2 To select the device you'll be working with, select it by its device name. View current partition table (parted) print Model: Seagate (scsi) Disk /dev/sda: 21.5GB Sector size (logical/physical): 512B/512B Partition Table: msdos Number Start End Size Type File system Flags 1 1049kB 6860MB 6859MB primary ext4 boot 2 6861MB 21.5GB 14.6GB extended 5 6861MB 7380MB 519MB logical linux-swap(v1) 6 7381MB 21.5GB 14.1GB logical xfs Here you will see the available partitions on the device. The start and end points are where the partitions take up space on the hard drive, you'll want to find a good start and end location for your partitions. Partition the device mkpart primary 123 4567 Now just choose a start and end point and make the partition, you'll need to specify the type of partition depending on what table you used. Resize a partition You can also resize a partition if you don't have any space. resize 2 1245 3456 Select the partition number and then the start and end points of where you want to resize it to. Parted is a very powerful tool and you should be careful when partitioning your disks.","title":"Disk Partitioning"},{"location":"filesystem/disk-partitioning/#exercise","text":"Partition a USB drive with half of the drive as ext4 and the other half as free space.","title":"Exercise"},{"location":"filesystem/disk-partitioning/#quiz-questions","text":"Click the right arrow to view the answers What is the parted command to make a partition? mkpart","title":"Quiz Questions"},{"location":"filesystem/disk-usage/","text":"Disk Usage There are a few tools you can used to see the utilization of your disks: mo:~$ df -h Filesystem 1K-blocks Used Available Use% Mounted on /dev/sda1 6.2G 2.3G 3.6G 40% / The df command shows you the utilization of your currently mounted filesystems. The -h flag gives you a human readable format. You can see what the device is, and how much capacity is used and available. Let's say your disk is getting full and you want to know what files or directories are taking up that space, for that you can use the du command. $ du -h This shows you the disk usage of the current directory you are in, you can take a peek at the root directory with du -h / but that can get a little cluttered. Both of these commands are so similar in syntax it can be hard to remember which one to use, to check how much of your disk is free use df. To check disk usage , use du. Exercise Look at your disk usage and free space with both du and df. Quiz Questions Click the right arrow to view the answers What command is use to show how much space is free on your disk? df","title":"Disk Usage"},{"location":"filesystem/disk-usage/#disk-usage","text":"There are a few tools you can used to see the utilization of your disks: mo:~$ df -h Filesystem 1K-blocks Used Available Use% Mounted on /dev/sda1 6.2G 2.3G 3.6G 40% / The df command shows you the utilization of your currently mounted filesystems. The -h flag gives you a human readable format. You can see what the device is, and how much capacity is used and available. Let's say your disk is getting full and you want to know what files or directories are taking up that space, for that you can use the du command. $ du -h This shows you the disk usage of the current directory you are in, you can take a peek at the root directory with du -h / but that can get a little cluttered. Both of these commands are so similar in syntax it can be hard to remember which one to use, to check how much of your disk is free use df. To check disk usage , use du.","title":"Disk Usage"},{"location":"filesystem/disk-usage/#exercise","text":"Look at your disk usage and free space with both du and df.","title":"Exercise"},{"location":"filesystem/disk-usage/#quiz-questions","text":"Click the right arrow to view the answers What command is use to show how much space is free on your disk? df","title":"Quiz Questions"},{"location":"filesystem/etc-fstab-file-system-table/","text":"/etc/fstab When we want to automatically mount filesystems at startup we can add them to a file called /etc/fstab (pronounced \"eff es tab\" not \"eff stab\") short for filesystem table. This file contains a permanent list of filesystems that are mounted. mo:~$ cat /etc/fstab UUID=130b882f-7d79-436d-a096-1e594c92bb76 / ext4 relatime,errors=remount-ro 0 1 UUID=78d203a0-7c18-49bd-9e07-54f44cdb5726 /home xfs relatime 0 2 UUID=22c3d34b-467e-467c-b44d-f03803c2c526 none swap sw 0 0 Each line represents one filesystem, the fields are: UUID - Device identifier Mount point - Directory the filesystem is mounted to Filesystem type Options - other mount options, see manpage for more details Dump - used by the dump utility to decide when to make a backup, you should just default to 0 Pass - Used by fsck to decide what order filesystems should be checked, if the value is 0, it will not be checked To add an entry, just directly modify the /etc/fstab file using the entry syntax above. Be careful when modifying this file, you could potentially make your life a little harder if you mess up. Exercise Add the USB drive we've been working on as a entry in /etc/fstab, when you reboot you should still see it mounted. Quiz Questions Click the right arrow to view the answers What file is used to define how filesystems should be mounted? /etc/fstab","title":"/etc/fstab"},{"location":"filesystem/etc-fstab-file-system-table/#etcfstab","text":"When we want to automatically mount filesystems at startup we can add them to a file called /etc/fstab (pronounced \"eff es tab\" not \"eff stab\") short for filesystem table. This file contains a permanent list of filesystems that are mounted. mo:~$ cat /etc/fstab UUID=130b882f-7d79-436d-a096-1e594c92bb76 / ext4 relatime,errors=remount-ro 0 1 UUID=78d203a0-7c18-49bd-9e07-54f44cdb5726 /home xfs relatime 0 2 UUID=22c3d34b-467e-467c-b44d-f03803c2c526 none swap sw 0 0 Each line represents one filesystem, the fields are: UUID - Device identifier Mount point - Directory the filesystem is mounted to Filesystem type Options - other mount options, see manpage for more details Dump - used by the dump utility to decide when to make a backup, you should just default to 0 Pass - Used by fsck to decide what order filesystems should be checked, if the value is 0, it will not be checked To add an entry, just directly modify the /etc/fstab file using the entry syntax above. Be careful when modifying this file, you could potentially make your life a little harder if you mess up.","title":"/etc/fstab"},{"location":"filesystem/etc-fstab-file-system-table/#exercise","text":"Add the USB drive we've been working on as a entry in /etc/fstab, when you reboot you should still see it mounted.","title":"Exercise"},{"location":"filesystem/etc-fstab-file-system-table/#quiz-questions","text":"Click the right arrow to view the answers What file is used to define how filesystems should be mounted? /etc/fstab","title":"Quiz Questions"},{"location":"filesystem/filesystem-hierarchy/","text":"Filesystem Hierarchy At this point, you're probably well familiar with the directory structure of your system, if not you will be soon. Filesystems can vary with how they are structured, but for the most part they should conform to the Filesystem Hierarchy Standard. Go ahead and do an ls -l / to see the directories listed under the root directory, yours may look different than mine, but the directories should for the most part look like the following: / - The root directory of the entire filesystem hierarchy, everything is nested under this directory. /bin - Essential ready-to-run programs (binaries), includes the most basic commands such as ls and cp. /boot - Contains kernel boot loader files. /dev - Device files. /etc - Core system configuration directory, should hold only configuration files and not any binaries. /home - Personal directories for users, holds your documents, files, settings, etc. /lib - Holds library files that binaries can use. /media - Used as an attachment point for removable media like USB drives. /mnt - Temporarily mounted filesystems. /opt - Optional application software packages. /proc - Information about currently running processes. /root - The root user's home directory. /run - Information about the running system since the last boot. /sbin - Contains essential system binaries, usually can only be ran by root. /srv - Site-specific data which are served by the system. /tmp - Storage for temporary files /usr - This is unfortunately named, most often it does not contain user files in the sense of a home folder. This is meant for user installed software and utilities, however that is not to say you can't add personal directories in there. Inside this directory are sub-directories for /usr/bin, /usr/local, etc. /var - Variable directory, it's used for system logging, user tracking, caches, etc. Basically anything that is subject to change all the time. Exercise Look inside your /usr directory, what kind of information is located there? Quiz Questions Click the right arrow to view the answers What directory is used to store logs? /var What directory is used to store configs? /etc","title":"Filesystem Hierarchy"},{"location":"filesystem/filesystem-hierarchy/#filesystem-hierarchy","text":"At this point, you're probably well familiar with the directory structure of your system, if not you will be soon. Filesystems can vary with how they are structured, but for the most part they should conform to the Filesystem Hierarchy Standard. Go ahead and do an ls -l / to see the directories listed under the root directory, yours may look different than mine, but the directories should for the most part look like the following: / - The root directory of the entire filesystem hierarchy, everything is nested under this directory. /bin - Essential ready-to-run programs (binaries), includes the most basic commands such as ls and cp. /boot - Contains kernel boot loader files. /dev - Device files. /etc - Core system configuration directory, should hold only configuration files and not any binaries. /home - Personal directories for users, holds your documents, files, settings, etc. /lib - Holds library files that binaries can use. /media - Used as an attachment point for removable media like USB drives. /mnt - Temporarily mounted filesystems. /opt - Optional application software packages. /proc - Information about currently running processes. /root - The root user's home directory. /run - Information about the running system since the last boot. /sbin - Contains essential system binaries, usually can only be ran by root. /srv - Site-specific data which are served by the system. /tmp - Storage for temporary files /usr - This is unfortunately named, most often it does not contain user files in the sense of a home folder. This is meant for user installed software and utilities, however that is not to say you can't add personal directories in there. Inside this directory are sub-directories for /usr/bin, /usr/local, etc. /var - Variable directory, it's used for system logging, user tracking, caches, etc. Basically anything that is subject to change all the time.","title":"Filesystem Hierarchy"},{"location":"filesystem/filesystem-hierarchy/#exercise","text":"Look inside your /usr directory, what kind of information is located there?","title":"Exercise"},{"location":"filesystem/filesystem-hierarchy/#quiz-questions","text":"Click the right arrow to view the answers What directory is used to store logs? /var What directory is used to store configs? /etc","title":"Quiz Questions"},{"location":"filesystem/filesystem-repair/","text":"Filesystem Repair Sometimes our filesystem isn't always in the best condition, if we have a sudden shutdown, our data can become corrupt. It's up to the system to try to get us back in a working state (although we sure can try ourselves). The fsck (filesystem check) command is used to check the consistency of a filesystem and can even try to repair it for us. Usually when you boot up a disk, fsck will run before your disk is mounted to make sure everything is ok. Sometimes though, your disk is so bad that you'll need to manually do this. However, be sure to do this while you are in a rescue disk or somewhere where you can access your filesystem without it being mounted. $ sudo fsck /dev/sda Exercise Look at the manpage for fsck to see what else it can do. Quiz Questions Click the right arrow to view the answers What command is used to check the integrity of a filesystem? fsck","title":"Filesystem repair"},{"location":"filesystem/filesystem-repair/#filesystem-repair","text":"Sometimes our filesystem isn't always in the best condition, if we have a sudden shutdown, our data can become corrupt. It's up to the system to try to get us back in a working state (although we sure can try ourselves). The fsck (filesystem check) command is used to check the consistency of a filesystem and can even try to repair it for us. Usually when you boot up a disk, fsck will run before your disk is mounted to make sure everything is ok. Sometimes though, your disk is so bad that you'll need to manually do this. However, be sure to do this while you are in a rescue disk or somewhere where you can access your filesystem without it being mounted. $ sudo fsck /dev/sda","title":"Filesystem Repair"},{"location":"filesystem/filesystem-repair/#exercise","text":"Look at the manpage for fsck to see what else it can do.","title":"Exercise"},{"location":"filesystem/filesystem-repair/#quiz-questions","text":"Click the right arrow to view the answers What command is used to check the integrity of a filesystem? fsck","title":"Quiz Questions"},{"location":"filesystem/filesystem-types/","text":"Filesystem Types There are many different filesystem implementations available. Some are faster than others, some support larger capacity storage and others only work on smaller capacity storage. Different filesystems have different ways of organizing their data and we'll go into detail about what types of filesystems there are. Since there are so many different implementations available, applications need a way to deal with the different operations. So there is something called the Virtual File System (VFS) abstraction layer. It is a layer between applications and the different filesystem types, so no matter what filesystem you have, your applications will be able to work with it. You can have many filesystem on your disks, depending on how they are partitioned and we will go through that in a coming lesson. Journaling Journaling comes by default on most filesystem types, but just in case it doesn't, you should know what it does. Let's say you're copying a large file and all of a sudden you lose power. Well if you are on a non-journaled filesystem, the file would end up corrupted and your filesystem would be inconsistent and then when you boot back up, your system would perform a filesystem check to make sure everything is ok. However, the repairs could take awhile depending on how large your filesystem was. Now if you were on a journaled system, before your machine even begins to copy the file, it will write what you're going to be doing in a log file (journal). Now when you actually copy the file, once it completes, the journal marks that task as complete. The filesystem is always in a consistent state because of this, so it will know exactly where you left off if your machine shutdown suddenly. This also decreases the boot time because instead of checking the entire filesystem it just looks at your journal. Common Desktop Filesystem Types ext4 - This is the most current version of the native Linux filesystems. It is compatible with the older ext2 and ext3 versions. It supports disk volumes up to 1 exabyte and file sizes up to 16 terabytes and much more. It is the standard choice for Linux filesystems. Btrfs - \"Better or Butter FS\" it is a new filesystem for Linux that comes with snapshots, incremental backups, performance increase and much more. It is widely available, but not quite stable and compatible yet. XFS - High performance journaling file system, great for a system with large files such as a media server. NTFS and FAT - Windows filesystems HFS+ - Macintosh filesystem Check out what filesystems are on your machine: mo:~$ df -T Filesystem Type 1K-blocks Used Available Use% Mounted on /dev/sda1 ext4 6461592 2402708 3707604 40% / udev devtmpfs 501356 4 501352 1% /dev tmpfs tmpfs 102544 1068 101476 2% /run /dev/sda6 xfs 13752320 460112 13292208 4% /home The df command reports file system disk space usage and other details about your disk, we will talk more about this tool later. Exercise Do a little bit of research online on the other filesystem types: ReiserFS, ZFS, JFS and others you can find. Quiz Questions Click the right arrow to view the answers What is the common Linux filesystem type? ext4","title":"Filesystem types"},{"location":"filesystem/filesystem-types/#filesystem-types","text":"There are many different filesystem implementations available. Some are faster than others, some support larger capacity storage and others only work on smaller capacity storage. Different filesystems have different ways of organizing their data and we'll go into detail about what types of filesystems there are. Since there are so many different implementations available, applications need a way to deal with the different operations. So there is something called the Virtual File System (VFS) abstraction layer. It is a layer between applications and the different filesystem types, so no matter what filesystem you have, your applications will be able to work with it. You can have many filesystem on your disks, depending on how they are partitioned and we will go through that in a coming lesson. Journaling Journaling comes by default on most filesystem types, but just in case it doesn't, you should know what it does. Let's say you're copying a large file and all of a sudden you lose power. Well if you are on a non-journaled filesystem, the file would end up corrupted and your filesystem would be inconsistent and then when you boot back up, your system would perform a filesystem check to make sure everything is ok. However, the repairs could take awhile depending on how large your filesystem was. Now if you were on a journaled system, before your machine even begins to copy the file, it will write what you're going to be doing in a log file (journal). Now when you actually copy the file, once it completes, the journal marks that task as complete. The filesystem is always in a consistent state because of this, so it will know exactly where you left off if your machine shutdown suddenly. This also decreases the boot time because instead of checking the entire filesystem it just looks at your journal. Common Desktop Filesystem Types ext4 - This is the most current version of the native Linux filesystems. It is compatible with the older ext2 and ext3 versions. It supports disk volumes up to 1 exabyte and file sizes up to 16 terabytes and much more. It is the standard choice for Linux filesystems. Btrfs - \"Better or Butter FS\" it is a new filesystem for Linux that comes with snapshots, incremental backups, performance increase and much more. It is widely available, but not quite stable and compatible yet. XFS - High performance journaling file system, great for a system with large files such as a media server. NTFS and FAT - Windows filesystems HFS+ - Macintosh filesystem Check out what filesystems are on your machine: mo:~$ df -T Filesystem Type 1K-blocks Used Available Use% Mounted on /dev/sda1 ext4 6461592 2402708 3707604 40% / udev devtmpfs 501356 4 501352 1% /dev tmpfs tmpfs 102544 1068 101476 2% /run /dev/sda6 xfs 13752320 460112 13292208 4% /home The df command reports file system disk space usage and other details about your disk, we will talk more about this tool later.","title":"Filesystem Types"},{"location":"filesystem/filesystem-types/#exercise","text":"Do a little bit of research online on the other filesystem types: ReiserFS, ZFS, JFS and others you can find.","title":"Exercise"},{"location":"filesystem/filesystem-types/#quiz-questions","text":"Click the right arrow to view the answers What is the common Linux filesystem type? ext4","title":"Quiz Questions"},{"location":"filesystem/inodes/","text":"Inodes Remember how our filesystem is comprised of all our actual files and a database that manages these files? The database is known as the inode table. What is an inode? An inode (index node) is an entry in this table and there is one for every file. It describes everything about the file, such as: File type - regular file, directory, character device, etc Owner Group Access permissions Timestamps - mtime (time of last file modification), ctime (time of last attribute change), atime (time of last access) Number of hardlinks to the file Size of the file Number of blocks allocated to the file Pointers to the data blocks of the file - most important! Basically inodes store everything about the file, except the filename and the file itself! When are inodes created? When a filesystem is created, space for inodes is allocated as well. There are algorithms that take place to determine how much inode space you need depending on the volume of the disk and more. You've probably at some point in your life seen errors for out of disk space issues. Well the same can occur for inodes as well (although less common), you can run out of inodes and therefore be unable to create more files. Remember data storage depends on both the data and the database (inodes). To see how many inodes are left on your system, use the command df -i Inode information Inodes are identified by numbers, when a file gets created it is assigned an inode number, the number is assigned in sequential order. However, you may sometimes notice when you create a new file, it gets an inode number that is lower than others, this is because once inodes are deleted, they can be reused by other files. To view inode numbers run ls -li : mo:~$ ls -li 140 drwxr-xr-x 2 mo mo 6 Jan 20 20:13 Desktop 141 drwxr-xr-x 2 mo mo 6 Jan 20 20:01 Documents The first field in this command lists the inode number. You can also see detailed information about a file with stat, it tells you information about the inode as well. mo:~$ stat ~/Desktop/ File: \u2018/home/mo/Desktop/\u2019 Size: 6 Blocks: 0 IO Block: 4096 directory Device: 806h/2054d Inode: 140 Links: 2 Access: (0755/drwxr-xr-x) Uid: ( 1000/ mo) Gid: ( 1000/ mo) Access: 2016-01-20 20:13:50.647435982 -0800 Modify: 2016-01-20 20:13:06.191675843 -0800 Change: 2016-01-20 20:13:06.191675843 -0800 Birth: - How do inodes locate files? We know our data is out there on the disk somewhere, unfortunately it probably wasn't stored sequentially, so we have to use inodes. Inodes point to the actual data blocks of your files. In a typical filesystem (not all work the same), each inode contains 15 pointers, the first 12 pointers point directly to the data blocks. The 13th pointer, points to a block containing pointers to more blocks, the 14th pointer points to another nested block of pointers, and the 15th pointer points yet again to another block of pointers! Confusing, I know! The reason this is done this way is to keep the inode structure the same for every inode, but be able to reference files of different sizes. If you had a small file, you could find it quicker with the first 12 direct pointers, larger files can be found with the nests of pointers. Either way the structure of the inode is the same. Exercise Observe some inode numbers for different files, which ones are usually created first? Quiz Questions Click the right arrow to view the answers How do you see how many inodes are left on your system? df -i","title":"Inodes"},{"location":"filesystem/inodes/#inodes","text":"Remember how our filesystem is comprised of all our actual files and a database that manages these files? The database is known as the inode table. What is an inode? An inode (index node) is an entry in this table and there is one for every file. It describes everything about the file, such as: File type - regular file, directory, character device, etc Owner Group Access permissions Timestamps - mtime (time of last file modification), ctime (time of last attribute change), atime (time of last access) Number of hardlinks to the file Size of the file Number of blocks allocated to the file Pointers to the data blocks of the file - most important! Basically inodes store everything about the file, except the filename and the file itself! When are inodes created? When a filesystem is created, space for inodes is allocated as well. There are algorithms that take place to determine how much inode space you need depending on the volume of the disk and more. You've probably at some point in your life seen errors for out of disk space issues. Well the same can occur for inodes as well (although less common), you can run out of inodes and therefore be unable to create more files. Remember data storage depends on both the data and the database (inodes). To see how many inodes are left on your system, use the command df -i Inode information Inodes are identified by numbers, when a file gets created it is assigned an inode number, the number is assigned in sequential order. However, you may sometimes notice when you create a new file, it gets an inode number that is lower than others, this is because once inodes are deleted, they can be reused by other files. To view inode numbers run ls -li : mo:~$ ls -li 140 drwxr-xr-x 2 mo mo 6 Jan 20 20:13 Desktop 141 drwxr-xr-x 2 mo mo 6 Jan 20 20:01 Documents The first field in this command lists the inode number. You can also see detailed information about a file with stat, it tells you information about the inode as well. mo:~$ stat ~/Desktop/ File: \u2018/home/mo/Desktop/\u2019 Size: 6 Blocks: 0 IO Block: 4096 directory Device: 806h/2054d Inode: 140 Links: 2 Access: (0755/drwxr-xr-x) Uid: ( 1000/ mo) Gid: ( 1000/ mo) Access: 2016-01-20 20:13:50.647435982 -0800 Modify: 2016-01-20 20:13:06.191675843 -0800 Change: 2016-01-20 20:13:06.191675843 -0800 Birth: - How do inodes locate files? We know our data is out there on the disk somewhere, unfortunately it probably wasn't stored sequentially, so we have to use inodes. Inodes point to the actual data blocks of your files. In a typical filesystem (not all work the same), each inode contains 15 pointers, the first 12 pointers point directly to the data blocks. The 13th pointer, points to a block containing pointers to more blocks, the 14th pointer points to another nested block of pointers, and the 15th pointer points yet again to another block of pointers! Confusing, I know! The reason this is done this way is to keep the inode structure the same for every inode, but be able to reference files of different sizes. If you had a small file, you could find it quicker with the first 12 direct pointers, larger files can be found with the nests of pointers. Either way the structure of the inode is the same.","title":"Inodes"},{"location":"filesystem/inodes/#exercise","text":"Observe some inode numbers for different files, which ones are usually created first?","title":"Exercise"},{"location":"filesystem/inodes/#quiz-questions","text":"Click the right arrow to view the answers How do you see how many inodes are left on your system? df -i","title":"Quiz Questions"},{"location":"filesystem/mounting/","text":"Mounting Before you can view the contents of your filesystem, you will have to mount it. To do that I'll need the device location, the filesystem type and a mount point, the mount point is a directory on the system where the filesystem is going to be attached. So we basically want to mount our device to a mount point. First create the mount point, in our case mkdir /mydrive $ sudo mount -t ext4 /dev/sdb2 /mydrive Simple as that! Now when we go to /mydrive we can see our filesystem contents, the -t specifies the type of filesystem, then we have the device location, then the mount point. To unmount a device from a mount point: $ sudo umount /mydrive or $ sudo umount /dev/sdb2 Remember that the kernel names devices in the order it finds them. What if our device name changes for some reason after we mount it? Well fortunately, you can use a device's universally unique ID (UUID) instead of a name. To view the UUIDS on your system for block devices: mo:~$ sudo blkid /dev/sda1: UUID=\"130b882f-7d79-436d-a096-1e594c92bb76\" TYPE=\"ext4\" /dev/sda5: UUID=\"22c3d34b-467e-467c-b44d-f03803c2c526\" TYPE=\"swap\" /dev/sda6: UUID=\"78d203a0-7c18-49bd-9e07-54f44cdb5726\" TYPE=\"xfs\" We can see our device names, their corresponding filesystem types and their UUIDs. Now when we want to mount something, we can use: $ sudo mount UUID=130b882f-7d79-436d-a096-1e594c92bb76 /mydrive Most of the time you won't need to mount devices via their UUIDs, it's much easier to use the device name and often times the operating system will know to mount common devices like USB drives. If you need to automatically mount a filesystem at startup though like if you added a secondary hard drive, you'll want to use the UUID and we'll go over that in the next lesson. Exercise Look at the manpage for mount and umount and see what other options you can use. Quiz Questions Click the right arrow to view the answers What command is used to attach a filesystem? mount","title":"Mounting"},{"location":"filesystem/mounting/#mounting","text":"Before you can view the contents of your filesystem, you will have to mount it. To do that I'll need the device location, the filesystem type and a mount point, the mount point is a directory on the system where the filesystem is going to be attached. So we basically want to mount our device to a mount point. First create the mount point, in our case mkdir /mydrive $ sudo mount -t ext4 /dev/sdb2 /mydrive Simple as that! Now when we go to /mydrive we can see our filesystem contents, the -t specifies the type of filesystem, then we have the device location, then the mount point. To unmount a device from a mount point: $ sudo umount /mydrive or $ sudo umount /dev/sdb2 Remember that the kernel names devices in the order it finds them. What if our device name changes for some reason after we mount it? Well fortunately, you can use a device's universally unique ID (UUID) instead of a name. To view the UUIDS on your system for block devices: mo:~$ sudo blkid /dev/sda1: UUID=\"130b882f-7d79-436d-a096-1e594c92bb76\" TYPE=\"ext4\" /dev/sda5: UUID=\"22c3d34b-467e-467c-b44d-f03803c2c526\" TYPE=\"swap\" /dev/sda6: UUID=\"78d203a0-7c18-49bd-9e07-54f44cdb5726\" TYPE=\"xfs\" We can see our device names, their corresponding filesystem types and their UUIDs. Now when we want to mount something, we can use: $ sudo mount UUID=130b882f-7d79-436d-a096-1e594c92bb76 /mydrive Most of the time you won't need to mount devices via their UUIDs, it's much easier to use the device name and often times the operating system will know to mount common devices like USB drives. If you need to automatically mount a filesystem at startup though like if you added a secondary hard drive, you'll want to use the UUID and we'll go over that in the next lesson.","title":"Mounting"},{"location":"filesystem/mounting/#exercise","text":"Look at the manpage for mount and umount and see what other options you can use.","title":"Exercise"},{"location":"filesystem/mounting/#quiz-questions","text":"Click the right arrow to view the answers What command is used to attach a filesystem? mount","title":"Quiz Questions"},{"location":"filesystem/swap-space/","text":"Swap In our previous example, I showed you how to see your partition table, let's revisit that example, more specifically this line: Number Start End Size Type File system Flags 5 6861MB 7380MB 519MB logical linux-swap(v1) What is this swap partition? Well swap is what we used to allocate virtual memory to our system. If you are low on memory, the system uses this partition to \"swap\" pieces of memory of idle processes to the disk, so you're not bogged for memory. Using a partition for swap space Let's say we wanted to set our partition of /dev/sdb2 to be used for swap space. First make sure we don't have anything on the partition Run: mkswap /dev/sdb2 to initialize swap areas Run: swapon /dev/sdb2 this will enable the swap device If you want the swap partition to persist on bootup, you need to add an entry to the /etc/fstab file. sw is the filesystem type that you'll use. To remove swap: swapoff /dev/sdb2 Generally you should allocate about twice as much swap space as you have memory. But modern systems today are usually pretty powerful enough and have enough RAM as it is. Exercise Partition the free space in the USB drive for swap space. Quiz Questions Click the right arrow to view the answers What is the command to enable swap space on a device? swapon","title":"Swap Space"},{"location":"filesystem/swap-space/#swap","text":"In our previous example, I showed you how to see your partition table, let's revisit that example, more specifically this line: Number Start End Size Type File system Flags 5 6861MB 7380MB 519MB logical linux-swap(v1) What is this swap partition? Well swap is what we used to allocate virtual memory to our system. If you are low on memory, the system uses this partition to \"swap\" pieces of memory of idle processes to the disk, so you're not bogged for memory. Using a partition for swap space Let's say we wanted to set our partition of /dev/sdb2 to be used for swap space. First make sure we don't have anything on the partition Run: mkswap /dev/sdb2 to initialize swap areas Run: swapon /dev/sdb2 this will enable the swap device If you want the swap partition to persist on bootup, you need to add an entry to the /etc/fstab file. sw is the filesystem type that you'll use. To remove swap: swapoff /dev/sdb2 Generally you should allocate about twice as much swap space as you have memory. But modern systems today are usually pretty powerful enough and have enough RAM as it is.","title":"Swap"},{"location":"filesystem/swap-space/#exercise","text":"Partition the free space in the USB drive for swap space.","title":"Exercise"},{"location":"filesystem/swap-space/#quiz-questions","text":"Click the right arrow to view the answers What is the command to enable swap space on a device? swapon","title":"Quiz Questions"},{"location":"filesystem/symlinks/","text":"Symbolic links (soft links & hard links) Let's use a previous example of inode information: mo:~$ ls -li 140 drwxr-xr-x 2 mo mo 6 Jan 20 20:13 Desktop 141 drwxr-xr-x 2 mo mo 6 Jan 20 20:01 Documents You may have noticed that we've been glossing over the third field in the ls command, that field is the link count. The link count is the total number of hard links a file has, well that doesn't mean anything to you right now. So let's discuss links first. Symlinks In the Windows operating system, there are things known as shortcuts, shortcuts are just aliases to other files. If you do something to the original file, you could potentially break the shortcut. In Linux, the equivalent of shortcuts are symbolic links (or soft links or symlinks). Symlinks allow us to link to another file by its filename. Another type of links found in Linux are hardlinks, these are actually another file with a link to an inode. Let's see what I mean in practice starting with symlinks. mo:~/Desktop$ echo 'myfile' > myfile mo:~/Desktop$ echo 'myfile2' > myfile2 mo:~/Desktop$ echo 'myfile3' > myfile3 mo:~/Desktop$ ln -s myfile myfilelink mo:~/Desktop$ ls -li total 12 151 -rw-rw-r-- 1 mo mo 7 Jan 21 21:36 myfile 93401 -rw-rw-r-- 1 mo mo 8 Jan 21 21:36 myfile2 93402 -rw-rw-r-- 1 mo mo 8 Jan 21 21:36 myfile3 93403 lrwxrwxrwx 1 mo mo 6 Jan 21 21:39 myfilelink -> myfile You can see that I've made a symbolic link named myfilelink that points to myfile. Symbolic links are denoted by ->. Notice how I got a new inode number though, symlinks are just files that point to filenames. When you modify a symlink, the file also gets modified. Inode numbers are unique to filesystems, you can't have two of the same inode number in a single filesystem, meaning you can't reference a file in a different filesystem by its inode number. However, if you use symlinks they do not use inode numbers, they use filenames, so they can be referenced across different filesystems. Hardlinks Let's see an example of a hardlink: mo:~/Desktop$ ln myfile2 myhardlink mo:~/Desktop$ ls -li total 16 151 -rw-rw-r-- 1 mo mo 7 Jan 21 21:36 myfile 93401 -rw-rw-r-- 2 mo mo 8 Jan 21 21:36 myfile2 93402 -rw-rw-r-- 1 mo mo 8 Jan 21 21:36 myfile3 93403 lrwxrwxrwx 1 mo mo 6 Jan 21 21:39 myfilelink -> myfile 93401 -rw-rw-r-- 2 mo mo 8 Jan 21 21:36 myhardlink A hardlink just creates another file with a link to the same inode. So if I modified the contents of myfile2 or myhardlink, the change would be seen on both, but if I deleted myfile2, the file would still be accessible through myhardlink. Here is where our link count in the ls command comes into play. The link count is the number of hardlinks that an inode has, when you remove a file, it will decrease that link count. The inode only gets deleted when all hardlinks to the inode have been deleted. When you create a file, it's link count is 1 because it is the only file that is pointing to that inode. Unlike symlinks, hardlinks do not span filesystems because inodes are unique to the filesystem. Creating a symlink $ ln -s myfile mylink To create a symbolic link, you use the ln command with -s for symbolic and you specific a target file and then a link name. Creating a hardlink $ ln somefile somelink Similar to a symlink creation, except this time you leave out the -s. Exercise Play around with making symlinks and hardlinks, delete a couple and see what happens. Quiz Questions Click the right arrow to view the answers What is the command used to make a symlink/soft link? ln -s","title":"Symbolic Links"},{"location":"filesystem/symlinks/#symbolic-links-soft-links-hard-links","text":"Let's use a previous example of inode information: mo:~$ ls -li 140 drwxr-xr-x 2 mo mo 6 Jan 20 20:13 Desktop 141 drwxr-xr-x 2 mo mo 6 Jan 20 20:01 Documents You may have noticed that we've been glossing over the third field in the ls command, that field is the link count. The link count is the total number of hard links a file has, well that doesn't mean anything to you right now. So let's discuss links first. Symlinks In the Windows operating system, there are things known as shortcuts, shortcuts are just aliases to other files. If you do something to the original file, you could potentially break the shortcut. In Linux, the equivalent of shortcuts are symbolic links (or soft links or symlinks). Symlinks allow us to link to another file by its filename. Another type of links found in Linux are hardlinks, these are actually another file with a link to an inode. Let's see what I mean in practice starting with symlinks. mo:~/Desktop$ echo 'myfile' > myfile mo:~/Desktop$ echo 'myfile2' > myfile2 mo:~/Desktop$ echo 'myfile3' > myfile3 mo:~/Desktop$ ln -s myfile myfilelink mo:~/Desktop$ ls -li total 12 151 -rw-rw-r-- 1 mo mo 7 Jan 21 21:36 myfile 93401 -rw-rw-r-- 1 mo mo 8 Jan 21 21:36 myfile2 93402 -rw-rw-r-- 1 mo mo 8 Jan 21 21:36 myfile3 93403 lrwxrwxrwx 1 mo mo 6 Jan 21 21:39 myfilelink -> myfile You can see that I've made a symbolic link named myfilelink that points to myfile. Symbolic links are denoted by ->. Notice how I got a new inode number though, symlinks are just files that point to filenames. When you modify a symlink, the file also gets modified. Inode numbers are unique to filesystems, you can't have two of the same inode number in a single filesystem, meaning you can't reference a file in a different filesystem by its inode number. However, if you use symlinks they do not use inode numbers, they use filenames, so they can be referenced across different filesystems. Hardlinks Let's see an example of a hardlink: mo:~/Desktop$ ln myfile2 myhardlink mo:~/Desktop$ ls -li total 16 151 -rw-rw-r-- 1 mo mo 7 Jan 21 21:36 myfile 93401 -rw-rw-r-- 2 mo mo 8 Jan 21 21:36 myfile2 93402 -rw-rw-r-- 1 mo mo 8 Jan 21 21:36 myfile3 93403 lrwxrwxrwx 1 mo mo 6 Jan 21 21:39 myfilelink -> myfile 93401 -rw-rw-r-- 2 mo mo 8 Jan 21 21:36 myhardlink A hardlink just creates another file with a link to the same inode. So if I modified the contents of myfile2 or myhardlink, the change would be seen on both, but if I deleted myfile2, the file would still be accessible through myhardlink. Here is where our link count in the ls command comes into play. The link count is the number of hardlinks that an inode has, when you remove a file, it will decrease that link count. The inode only gets deleted when all hardlinks to the inode have been deleted. When you create a file, it's link count is 1 because it is the only file that is pointing to that inode. Unlike symlinks, hardlinks do not span filesystems because inodes are unique to the filesystem. Creating a symlink $ ln -s myfile mylink To create a symbolic link, you use the ln command with -s for symbolic and you specific a target file and then a link name. Creating a hardlink $ ln somefile somelink Similar to a symlink creation, except this time you leave out the -s.","title":"Symbolic links (soft links &amp; hard links)"},{"location":"filesystem/symlinks/#exercise","text":"Play around with making symlinks and hardlinks, delete a couple and see what happens.","title":"Exercise"},{"location":"filesystem/symlinks/#quiz-questions","text":"Click the right arrow to view the answers What is the command used to make a symlink/soft link? ln -s","title":"Quiz Questions"},{"location":"getting-started/arch-linux/","text":"Arch Linux Lesson Content Overview Arch is a lightweight and flexible Linux distribution driven 100% by the community. Similar to Debian, Arch uses a rolling release model so incremental updates eventually become the Stable release. You really need to get your hands dirty to understand the system and its functions, but in turn you get complete and total control of your system. Package Management It uses its own package manager, Pacman, to install, update and manage packages. Configurability If you want a lightweight operating system and really want to understand Linux use Arch! There\u2019s a bit of a learning curve, but for the hardcore Linux users, this is a great choice. Uses Great for desktop and laptop. If you also have a small device such as a Raspberry Pi and need to stick a lightweight OS on it, you can\u2019t go wrong with Arch. Exercise If you're interested in having Arch as your operating system, head over to the installation section and give it a try: https://www.archlinux.org/ Quiz Questions What package manager does Arch Linux use? Quiz Answer Pacman","title":"Arch Linux"},{"location":"getting-started/arch-linux/#arch-linux","text":"","title":"Arch Linux"},{"location":"getting-started/arch-linux/#lesson-content","text":"Overview Arch is a lightweight and flexible Linux distribution driven 100% by the community. Similar to Debian, Arch uses a rolling release model so incremental updates eventually become the Stable release. You really need to get your hands dirty to understand the system and its functions, but in turn you get complete and total control of your system. Package Management It uses its own package manager, Pacman, to install, update and manage packages. Configurability If you want a lightweight operating system and really want to understand Linux use Arch! There\u2019s a bit of a learning curve, but for the hardcore Linux users, this is a great choice. Uses Great for desktop and laptop. If you also have a small device such as a Raspberry Pi and need to stick a lightweight OS on it, you can\u2019t go wrong with Arch.","title":"Lesson Content"},{"location":"getting-started/arch-linux/#exercise","text":"If you're interested in having Arch as your operating system, head over to the installation section and give it a try: https://www.archlinux.org/","title":"Exercise"},{"location":"getting-started/arch-linux/#quiz-questions","text":"What package manager does Arch Linux use?","title":"Quiz Questions"},{"location":"getting-started/arch-linux/#quiz-answer","text":"Pacman","title":"Quiz Answer"},{"location":"getting-started/choosing-a-linux-distribution/","text":"Choosing a Linux Distribution Lesson Content In the previous lesson, we learned about the Linux kernel which powers millions of devices a day. One thing before we move forward, the term Linux is actually quite a misnomer, since it actually refers to the Linux kernel. However, many distributions use the Linux kernel so therefore are commonly known as Linux operating systems. A Linux system is divided into three main parts: Hardware - This includes all the hardware that your system runs on as well as memory, CPU, disks, etc. Linux Kernel - As we discussed above, the kernel is the core of the operating system. It manages the hardware and tells it how to interact with the system. User Space - This is where users like yourself will be directly interacting with the system. So the first step we\u2019ll need to take is to install Linux on your machine. You have many options to choose from and this course will help inform you and get you started on choosing a Linux distribution. There are many Linux distributions to choose from, we\u2019ll just go over the most popular options. Exercise No exercises for this lesson. Quiz Question No questions, skip ahead! Quiz Answer","title":"Choosing a Linux Distribution"},{"location":"getting-started/choosing-a-linux-distribution/#choosing-a-linux-distribution","text":"","title":"Choosing a Linux Distribution"},{"location":"getting-started/choosing-a-linux-distribution/#lesson-content","text":"In the previous lesson, we learned about the Linux kernel which powers millions of devices a day. One thing before we move forward, the term Linux is actually quite a misnomer, since it actually refers to the Linux kernel. However, many distributions use the Linux kernel so therefore are commonly known as Linux operating systems. A Linux system is divided into three main parts: Hardware - This includes all the hardware that your system runs on as well as memory, CPU, disks, etc. Linux Kernel - As we discussed above, the kernel is the core of the operating system. It manages the hardware and tells it how to interact with the system. User Space - This is where users like yourself will be directly interacting with the system. So the first step we\u2019ll need to take is to install Linux on your machine. You have many options to choose from and this course will help inform you and get you started on choosing a Linux distribution. There are many Linux distributions to choose from, we\u2019ll just go over the most popular options.","title":"Lesson Content"},{"location":"getting-started/choosing-a-linux-distribution/#exercise","text":"No exercises for this lesson.","title":"Exercise"},{"location":"getting-started/choosing-a-linux-distribution/#quiz-question","text":"No questions, skip ahead!","title":"Quiz Question"},{"location":"getting-started/choosing-a-linux-distribution/#quiz-answer","text":"","title":"Quiz Answer"},{"location":"getting-started/debian/","text":"Debian Lesson Content Overview Debian is an operating system composed entirely of free and open-source software. It\u2019s widely known and has been in development for over 20 years. There are three branches that you can use, Stable, Testing and Unstable. Stable is an overall good branch to be on. Testing and Unstable are rolling releases. This means that any incremental changes in those branches will eventually become Stable. For example, if you wanted to get to the next update from Windows 8 to Windows 10, you\u2019ll have to do a complete Windows 10 installation. However being on the Testing release, you\u2019ll automatically get updates until it becomes the next operating system release without having to do a full installation. Package Management Debian also uses Debian package management tools. Every Linux distribution installs and manages packages differently and they use different package management tools. We\u2019ll get more into this in a later course. Configurability Debian may not get the latest updates, but it's extremely stable. If you want a good \"core\" operating system, this is the one for you. Uses Debian is an overall great operating system for any platform. Exercise If you're interested in having Debian as your operating system, head over to the installation section and give it a try: https://www.debian.org/ Quiz Question What kind of release does Testing and Unstable have? Quiz Answer Rolling","title":"Debian"},{"location":"getting-started/debian/#debian","text":"","title":"Debian"},{"location":"getting-started/debian/#lesson-content","text":"Overview Debian is an operating system composed entirely of free and open-source software. It\u2019s widely known and has been in development for over 20 years. There are three branches that you can use, Stable, Testing and Unstable. Stable is an overall good branch to be on. Testing and Unstable are rolling releases. This means that any incremental changes in those branches will eventually become Stable. For example, if you wanted to get to the next update from Windows 8 to Windows 10, you\u2019ll have to do a complete Windows 10 installation. However being on the Testing release, you\u2019ll automatically get updates until it becomes the next operating system release without having to do a full installation. Package Management Debian also uses Debian package management tools. Every Linux distribution installs and manages packages differently and they use different package management tools. We\u2019ll get more into this in a later course. Configurability Debian may not get the latest updates, but it's extremely stable. If you want a good \"core\" operating system, this is the one for you. Uses Debian is an overall great operating system for any platform.","title":"Lesson Content"},{"location":"getting-started/debian/#exercise","text":"If you're interested in having Debian as your operating system, head over to the installation section and give it a try: https://www.debian.org/","title":"Exercise"},{"location":"getting-started/debian/#quiz-question","text":"What kind of release does Testing and Unstable have?","title":"Quiz Question"},{"location":"getting-started/debian/#quiz-answer","text":"Rolling","title":"Quiz Answer"},{"location":"getting-started/fedora/","text":"Fedora Lesson Content Overview Backed by Red Hat, the Fedora Project is community driven containing open-source and free software. Red Hat Enterprise Linux branches off Fedora, so think of Fedora as an upstream RHEL operating system. Eventually RHEL will get updates from Fedora after thorough testing and quality assurance. Think of Fedora as an Ubuntu equivalent that uses a Red Hat backend instead of Debian. Package Management Uses Red Hat package manager. Configurability If you want to use a Red Hat based operating system, this is a user friendly version. Uses Fedora is great if you want a Red Hat based operating system without the price tag. Recommended for desktop and laptop. Exercise If you're interested in having Fedora as your operating system, head over to the installation section and give it a try: https://getfedora.org/ Quiz Questions What is RHEL branched off of? Quiz Answer Fedora","title":"Fedora"},{"location":"getting-started/fedora/#fedora","text":"","title":"Fedora"},{"location":"getting-started/fedora/#lesson-content","text":"Overview Backed by Red Hat, the Fedora Project is community driven containing open-source and free software. Red Hat Enterprise Linux branches off Fedora, so think of Fedora as an upstream RHEL operating system. Eventually RHEL will get updates from Fedora after thorough testing and quality assurance. Think of Fedora as an Ubuntu equivalent that uses a Red Hat backend instead of Debian. Package Management Uses Red Hat package manager. Configurability If you want to use a Red Hat based operating system, this is a user friendly version. Uses Fedora is great if you want a Red Hat based operating system without the price tag. Recommended for desktop and laptop.","title":"Lesson Content"},{"location":"getting-started/fedora/#exercise","text":"If you're interested in having Fedora as your operating system, head over to the installation section and give it a try: https://getfedora.org/","title":"Exercise"},{"location":"getting-started/fedora/#quiz-questions","text":"What is RHEL branched off of?","title":"Quiz Questions"},{"location":"getting-started/fedora/#quiz-answer","text":"Fedora","title":"Quiz Answer"},{"location":"getting-started/gentoo/","text":"Gentoo Lesson Content Overview Gentoo offers ridiculous flexibility with the operating system at a price. It\u2019s made for advanced users who don\u2019t mind getting their hands dirty with the system. Package Management Gentoo uses its own package management, Portage. The Portage package management is very modular and easy to maintain, which plays a big part in the operating system as a whole being very flexible. Configurability If you\u2019re just getting started with Linux and want to take a more difficult path, I\u2019d choose Gentoo or Arch Linux as your distribution. Uses Great for desktop and laptop. Exercise If you're interested in having Gentoo as your operating system, head over to the installation section and give it a try: https://www.gentoo.org/ Quiz Questions What package management system does Gentoo use? Quiz Answer Portage","title":"Gentoo"},{"location":"getting-started/gentoo/#gentoo","text":"","title":"Gentoo"},{"location":"getting-started/gentoo/#lesson-content","text":"Overview Gentoo offers ridiculous flexibility with the operating system at a price. It\u2019s made for advanced users who don\u2019t mind getting their hands dirty with the system. Package Management Gentoo uses its own package management, Portage. The Portage package management is very modular and easy to maintain, which plays a big part in the operating system as a whole being very flexible. Configurability If you\u2019re just getting started with Linux and want to take a more difficult path, I\u2019d choose Gentoo or Arch Linux as your distribution. Uses Great for desktop and laptop.","title":"Lesson Content"},{"location":"getting-started/gentoo/#exercise","text":"If you're interested in having Gentoo as your operating system, head over to the installation section and give it a try: https://www.gentoo.org/","title":"Exercise"},{"location":"getting-started/gentoo/#quiz-questions","text":"What package management system does Gentoo use?","title":"Quiz Questions"},{"location":"getting-started/gentoo/#quiz-answer","text":"Portage","title":"Quiz Answer"},{"location":"getting-started/linux-history/","text":"History Lesson Content Hey rookie! So you decided to dive into this wonderful world known as Linux? Well you better strap in, because it\u2019s gonna be a long and hard road. My name is Mohamed Abukar and I\u2019m here to guide you through this journey. Let\u2019s get started with a little bit of backstory about Linux. To learn about how Linux came to be, let\u2019s go back to the beginning to 1969 where Ken Thompson and Dennis Ritchie of Bell Laboratories developed the UNIX operating system. It was later rewritten in C to make it more portable and eventually became a widely used operating system. A decade or so later, Richard Stallman started working on the GNU (GNU is Not UNIX) project, the GNU kernel called Hurd, which unfortunately never came to completion. The GNU General Public License (GPL), a free software license, was also created as a result of this. The kernel is the most important piece in the operating system. It allows the hardware to talk to the software. It also does a whole lot of other things, but we\u2019ll dig into that in a different course. For now, just know that the kernel controls pretty much everything that happens on your system. During this time other efforts such as BSD, MINIX, etc were developed to be UNIX like-systems. However, one thing that all these UNIX like-systems had in common was the lack of a unified kernel. Then in 1991, a young fellow named Linus Torvalds started developing what we now know today as the Linux kernel. Exercise Additional reading: GNU Ken Thompson Richard Stallman Linus Torvalds Quiz Question Who developed the Linux kernel? Quiz Answer Linus Torvalds","title":"History"},{"location":"getting-started/linux-history/#history","text":"","title":"History"},{"location":"getting-started/linux-history/#lesson-content","text":"Hey rookie! So you decided to dive into this wonderful world known as Linux? Well you better strap in, because it\u2019s gonna be a long and hard road. My name is Mohamed Abukar and I\u2019m here to guide you through this journey. Let\u2019s get started with a little bit of backstory about Linux. To learn about how Linux came to be, let\u2019s go back to the beginning to 1969 where Ken Thompson and Dennis Ritchie of Bell Laboratories developed the UNIX operating system. It was later rewritten in C to make it more portable and eventually became a widely used operating system. A decade or so later, Richard Stallman started working on the GNU (GNU is Not UNIX) project, the GNU kernel called Hurd, which unfortunately never came to completion. The GNU General Public License (GPL), a free software license, was also created as a result of this. The kernel is the most important piece in the operating system. It allows the hardware to talk to the software. It also does a whole lot of other things, but we\u2019ll dig into that in a different course. For now, just know that the kernel controls pretty much everything that happens on your system. During this time other efforts such as BSD, MINIX, etc were developed to be UNIX like-systems. However, one thing that all these UNIX like-systems had in common was the lack of a unified kernel. Then in 1991, a young fellow named Linus Torvalds started developing what we now know today as the Linux kernel.","title":"Lesson Content"},{"location":"getting-started/linux-history/#exercise","text":"Additional reading: GNU Ken Thompson Richard Stallman Linus Torvalds","title":"Exercise"},{"location":"getting-started/linux-history/#quiz-question","text":"Who developed the Linux kernel?","title":"Quiz Question"},{"location":"getting-started/linux-history/#quiz-answer","text":"Linus Torvalds","title":"Quiz Answer"},{"location":"getting-started/linux-mint/","text":"Linux Mint Lesson Content Overview Linux Mint is based off of Ubuntu. It uses Ubuntu\u2019s software repositories so the same packages are available on both distributions. Linux Mint is preferred by others over Ubuntu because it doesn\u2019t come with some of the proprietary software that Ubuntu includes such as Unity. Package Management Since Linux Mint is Ubuntu based, it uses the Debian package manager. Configurability Great user interface, great for beginners and less bloated than Ubuntu. In this course, I\u2019ll be using Linux Mint, but any other distribution can be used. Uses Great for desktop and laptop. Exercise If you're interested in having Linux Mint as your operating system, head over to the installation section and give it a try: http://linuxmint.com/ Quiz Questions What is Linux Mint based off of? Quiz Answer Ubuntu","title":"Linux Mint"},{"location":"getting-started/linux-mint/#linux-mint","text":"","title":"Linux Mint"},{"location":"getting-started/linux-mint/#lesson-content","text":"Overview Linux Mint is based off of Ubuntu. It uses Ubuntu\u2019s software repositories so the same packages are available on both distributions. Linux Mint is preferred by others over Ubuntu because it doesn\u2019t come with some of the proprietary software that Ubuntu includes such as Unity. Package Management Since Linux Mint is Ubuntu based, it uses the Debian package manager. Configurability Great user interface, great for beginners and less bloated than Ubuntu. In this course, I\u2019ll be using Linux Mint, but any other distribution can be used. Uses Great for desktop and laptop.","title":"Lesson Content"},{"location":"getting-started/linux-mint/#exercise","text":"If you're interested in having Linux Mint as your operating system, head over to the installation section and give it a try: http://linuxmint.com/","title":"Exercise"},{"location":"getting-started/linux-mint/#quiz-questions","text":"What is Linux Mint based off of?","title":"Quiz Questions"},{"location":"getting-started/linux-mint/#quiz-answer","text":"Ubuntu","title":"Quiz Answer"},{"location":"getting-started/openSUSE/","text":"openSUSE Lesson Content Overview openSUSE Linux is created by the openSUSE Project. A community that promotes the use of Linux everywhere, working together in an open, transparent and friendly manner as part of the worldwide Free and Open Source Software community. openSUSE is the second oldest still running Linux Distributions and shares the base system with SUSE's award-winning SUSE Linux Enterprise products. Package Management Uses RPM package manager. Configurability openSUSE is a great choice for a new Linux user. It offers an easy to use graphical installer/administration application ( YaST ) and a tiday base system, easy to tinker with. openSUSE includes everything you need to enjoy the Internet worry free of viruses/spy-ware and to live out your creativity, be it with your photos, videos, music or code. Uses openSUSE Leap is fully capable of being used on a desktop PC and laptop. Exercise If you're interested in having openSUSE as your operating system, head over to the download page and give it a try: software.opensuse.org Quiz Questions What is the name of openSUSE's Administration/Installation Tool? Quiz Answer yast","title":"openSUSE"},{"location":"getting-started/openSUSE/#opensuse","text":"","title":"openSUSE"},{"location":"getting-started/openSUSE/#lesson-content","text":"Overview openSUSE Linux is created by the openSUSE Project. A community that promotes the use of Linux everywhere, working together in an open, transparent and friendly manner as part of the worldwide Free and Open Source Software community. openSUSE is the second oldest still running Linux Distributions and shares the base system with SUSE's award-winning SUSE Linux Enterprise products. Package Management Uses RPM package manager. Configurability openSUSE is a great choice for a new Linux user. It offers an easy to use graphical installer/administration application ( YaST ) and a tiday base system, easy to tinker with. openSUSE includes everything you need to enjoy the Internet worry free of viruses/spy-ware and to live out your creativity, be it with your photos, videos, music or code. Uses openSUSE Leap is fully capable of being used on a desktop PC and laptop.","title":"Lesson Content"},{"location":"getting-started/openSUSE/#exercise","text":"If you're interested in having openSUSE as your operating system, head over to the download page and give it a try: software.opensuse.org","title":"Exercise"},{"location":"getting-started/openSUSE/#quiz-questions","text":"What is the name of openSUSE's Administration/Installation Tool?","title":"Quiz Questions"},{"location":"getting-started/openSUSE/#quiz-answer","text":"yast","title":"Quiz Answer"},{"location":"getting-started/red-hat-enterprise-linux/","text":"Red Hat Enterprise Linux Lesson Content Overview Red Hat Enterprise Linux commonly referred to as RHEL is developed by Red Hat. RHEL has strict rules to restrict free re-distribution although it still provides source code for free. Package Management RHEL uses a different package manager than Debian, RPM package manager, which we will eventually learn about as well. Configurability RHEL-based operating systems will differ slightly from the Debian-based operating systems, most noticeably in package management. If you decide to go with RHEL it\u2019s probably best if you know you\u2019ll be working with it. Uses As described by the name it's mostly used in enterprise, so if you need a solid server OS this would be a good one. Exercise If you're interested in having RHEL as your operating system, head over to the installation section and give it a try: https://www.redhat.com/rhel/ Quiz Questions What package manager does RHEL use? Quiz Answer RPM","title":"Red Hat Enterprise Linux"},{"location":"getting-started/red-hat-enterprise-linux/#red-hat-enterprise-linux","text":"","title":"Red Hat Enterprise Linux"},{"location":"getting-started/red-hat-enterprise-linux/#lesson-content","text":"Overview Red Hat Enterprise Linux commonly referred to as RHEL is developed by Red Hat. RHEL has strict rules to restrict free re-distribution although it still provides source code for free. Package Management RHEL uses a different package manager than Debian, RPM package manager, which we will eventually learn about as well. Configurability RHEL-based operating systems will differ slightly from the Debian-based operating systems, most noticeably in package management. If you decide to go with RHEL it\u2019s probably best if you know you\u2019ll be working with it. Uses As described by the name it's mostly used in enterprise, so if you need a solid server OS this would be a good one.","title":"Lesson Content"},{"location":"getting-started/red-hat-enterprise-linux/#exercise","text":"If you're interested in having RHEL as your operating system, head over to the installation section and give it a try: https://www.redhat.com/rhel/","title":"Exercise"},{"location":"getting-started/red-hat-enterprise-linux/#quiz-questions","text":"What package manager does RHEL use?","title":"Quiz Questions"},{"location":"getting-started/red-hat-enterprise-linux/#quiz-answer","text":"RPM","title":"Quiz Answer"},{"location":"getting-started/ubuntu/","text":"Ubuntu Lesson Content Overview One of the most popular Linux distributions for personal machines is Ubuntu. Ubuntu also releases its own desktop environment manager Unity by default. Package Management Ubuntu is a Debian-based operating system developed by Canonical. So it uses a core Debian package management system. Configurability Ubuntu is a great choice for a beginner who wants to get into Linux. Ubuntu offers ease of use and a great user interface experience that has led to its wide adoption. It\u2019s widely used and supported and is most like other operating systems like OSX and Windows in terms of usability. Uses Great for any platform, desktop, laptop and server. Exercise If you're interested in having Ubuntu as your operating system, head over to the installation section and give it a try: http://www.ubuntu.com/ Quiz Questions What operating system is Ubuntu based off of? Quiz Answer Debian","title":"Ubuntu"},{"location":"getting-started/ubuntu/#ubuntu","text":"","title":"Ubuntu"},{"location":"getting-started/ubuntu/#lesson-content","text":"Overview One of the most popular Linux distributions for personal machines is Ubuntu. Ubuntu also releases its own desktop environment manager Unity by default. Package Management Ubuntu is a Debian-based operating system developed by Canonical. So it uses a core Debian package management system. Configurability Ubuntu is a great choice for a beginner who wants to get into Linux. Ubuntu offers ease of use and a great user interface experience that has led to its wide adoption. It\u2019s widely used and supported and is most like other operating systems like OSX and Windows in terms of usability. Uses Great for any platform, desktop, laptop and server.","title":"Lesson Content"},{"location":"getting-started/ubuntu/#exercise","text":"If you're interested in having Ubuntu as your operating system, head over to the installation section and give it a try: http://www.ubuntu.com/","title":"Exercise"},{"location":"getting-started/ubuntu/#quiz-questions","text":"What operating system is Ubuntu based off of?","title":"Quiz Questions"},{"location":"getting-started/ubuntu/#quiz-answer","text":"Debian","title":"Quiz Answer"},{"location":"init/power-states/","text":"Power States Lesson Content Hard to believe we haven't actually discussed ways to control your system state through the command line, but when talking about init, we not only talk about the modes that get us starting our system, but also the ones that stop our system. To shutdown your system: $ sudo shutdown -h now This will halt the system (power it off), you must also specify a time when you want this to take place. You can add a time in minutes that will shutdown the system in that amount of time. $ sudo shutdown -h +2 This will shutdown your system in two minutes. You can also restart with the shutdown command: $ sudo shutdown -r now Or just use the reboot command: $ sudo reboot Exercise What do you think is happening with init when you shutdown your machine? Quiz Question What is the command to poweroff your system in 4 minutes? Quiz Answer sudo shutdown -h +4","title":"Power States"},{"location":"init/power-states/#power-states","text":"","title":"Power States"},{"location":"init/power-states/#lesson-content","text":"Hard to believe we haven't actually discussed ways to control your system state through the command line, but when talking about init, we not only talk about the modes that get us starting our system, but also the ones that stop our system. To shutdown your system: $ sudo shutdown -h now This will halt the system (power it off), you must also specify a time when you want this to take place. You can add a time in minutes that will shutdown the system in that amount of time. $ sudo shutdown -h +2 This will shutdown your system in two minutes. You can also restart with the shutdown command: $ sudo shutdown -r now Or just use the reboot command: $ sudo reboot","title":"Lesson Content"},{"location":"init/power-states/#exercise","text":"What do you think is happening with init when you shutdown your machine?","title":"Exercise"},{"location":"init/power-states/#quiz-question","text":"What is the command to poweroff your system in 4 minutes?","title":"Quiz Question"},{"location":"init/power-states/#quiz-answer","text":"sudo shutdown -h +4","title":"Quiz Answer"},{"location":"init/systemd-goals/","text":"Systemd Goals Lesson Content We won't get into the details of writing systemd unit files. We will however go over a brief overview of a unit file and how to manually control units. Here is a basic service unit file: foobar.service [Unit] Description=My Foobar Before=bar.target [Service] ExecStart=/usr/bin/foobar [Install] WantedBy=multi-user.target This is a simple service target, at the beginning of the file we see a section for [Unit], this allows us to give our unit file a description as well as control the ordering of when to activate the unit. The next portion is the [Service] section, under here we can start, stop or reload a service. And the [Install] section is used for dependency. This is only the tip of the iceberg for writing systemd files, so I implore you to read up on the subject if you want to know more. Now, let's get into some commands you can use with systemd units: List units $ systemctl list-units View status of unit $ systemctl status networking.service Start a service $ sudo systemctl start networking.service Stop a service $ sudo systemctl stop networking.service Restart a service $ sudo systemctl restart networking.service Enable a unit $ sudo systemctl enable networking.service Disable a unit $ sudo systemctl disable networking.service Again, you have yet to see how much depth systemd gets into, so read up on it if you want to learn more. Exercise View the unit statuses and start and stop a few services. What do you observe? Quiz Question What is the command to start a service named peanut.service? Quiz Answer sudo systemctl start peanut.service","title":"Systemd Goals"},{"location":"init/systemd-goals/#systemd-goals","text":"","title":"Systemd Goals"},{"location":"init/systemd-goals/#lesson-content","text":"We won't get into the details of writing systemd unit files. We will however go over a brief overview of a unit file and how to manually control units. Here is a basic service unit file: foobar.service [Unit] Description=My Foobar Before=bar.target [Service] ExecStart=/usr/bin/foobar [Install] WantedBy=multi-user.target This is a simple service target, at the beginning of the file we see a section for [Unit], this allows us to give our unit file a description as well as control the ordering of when to activate the unit. The next portion is the [Service] section, under here we can start, stop or reload a service. And the [Install] section is used for dependency. This is only the tip of the iceberg for writing systemd files, so I implore you to read up on the subject if you want to know more. Now, let's get into some commands you can use with systemd units: List units $ systemctl list-units View status of unit $ systemctl status networking.service Start a service $ sudo systemctl start networking.service Stop a service $ sudo systemctl stop networking.service Restart a service $ sudo systemctl restart networking.service Enable a unit $ sudo systemctl enable networking.service Disable a unit $ sudo systemctl disable networking.service Again, you have yet to see how much depth systemd gets into, so read up on it if you want to learn more.","title":"Lesson Content"},{"location":"init/systemd-goals/#exercise","text":"View the unit statuses and start and stop a few services. What do you observe?","title":"Exercise"},{"location":"init/systemd-goals/#quiz-question","text":"What is the command to start a service named peanut.service?","title":"Quiz Question"},{"location":"init/systemd-goals/#quiz-answer","text":"sudo systemctl start peanut.service","title":"Quiz Answer"},{"location":"init/systemd-overview/","text":"Systemd Overview Lesson Content Systemd is slowly becoming the emerging standard for init. If you have a /usr/lib/systemd directory, you're most likely using systemd. Systemd uses goals to get your system up and running. Basically you have a target that you want to achieve and this target also has dependencies that we need to achieve. Systemd is extremely flexible and robust, it does not follow a strict sequence to get processes started. Here's what happens during the typical systemd boot: First, systemd loads it's configuration files, usually located in /etc/systemd/system or /usr/lib/systemd/system Then it determines its boot goal, which is usually default.target Systemd figures out the dependencies of the boot target and activates them Similar to Sys V runlevels, systemd boots into different targets: poweroff.target - shutdown system rescue.target - single user mode multi-user.target - multiuser with networking graphical.target - multiuser with networking and GUI reboot.target - restart The default boot goal of default.target usually points to the graphical.target. The main object that systemd works with are known as units. Systemd doesn't just stop and start services, it can mount filesystems, monitor your network sockets, etc and because of that robustness it has different types of units it operates. The most common units are: Service units - these are the services we've been starting and stopping, these unit files end in .service Mount units - These mount filesystems, these unit files end in .mount Target units - These group together other units, the files end in .target For example, let's say we boot into our default.target, well this target groups together the networking.service unit, crond.service unit, etc, so once we activate a single unit, everything below that unit gets activated as well. Exercise No exercises for this lesson. Quiz Question What unit is used to group together other units? Quiz Answer target","title":"Systemd Overview"},{"location":"init/systemd-overview/#systemd-overview","text":"","title":"Systemd Overview"},{"location":"init/systemd-overview/#lesson-content","text":"Systemd is slowly becoming the emerging standard for init. If you have a /usr/lib/systemd directory, you're most likely using systemd. Systemd uses goals to get your system up and running. Basically you have a target that you want to achieve and this target also has dependencies that we need to achieve. Systemd is extremely flexible and robust, it does not follow a strict sequence to get processes started. Here's what happens during the typical systemd boot: First, systemd loads it's configuration files, usually located in /etc/systemd/system or /usr/lib/systemd/system Then it determines its boot goal, which is usually default.target Systemd figures out the dependencies of the boot target and activates them Similar to Sys V runlevels, systemd boots into different targets: poweroff.target - shutdown system rescue.target - single user mode multi-user.target - multiuser with networking graphical.target - multiuser with networking and GUI reboot.target - restart The default boot goal of default.target usually points to the graphical.target. The main object that systemd works with are known as units. Systemd doesn't just stop and start services, it can mount filesystems, monitor your network sockets, etc and because of that robustness it has different types of units it operates. The most common units are: Service units - these are the services we've been starting and stopping, these unit files end in .service Mount units - These mount filesystems, these unit files end in .mount Target units - These group together other units, the files end in .target For example, let's say we boot into our default.target, well this target groups together the networking.service unit, crond.service unit, etc, so once we activate a single unit, everything below that unit gets activated as well.","title":"Lesson Content"},{"location":"init/systemd-overview/#exercise","text":"No exercises for this lesson.","title":"Exercise"},{"location":"init/systemd-overview/#quiz-question","text":"What unit is used to group together other units?","title":"Quiz Question"},{"location":"init/systemd-overview/#quiz-answer","text":"target","title":"Quiz Answer"},{"location":"init/sysv-overview/","text":"System V Overview Lesson Content The main purpose of init is to start and stop essential processes on the system. There are three major implementations of init in Linux, System V, Upstart and systemd. In this lesson, we're going to go over the most traditional version of init, System V init or Sys V (pronounced as 'System Five'). To find out if you are using the Sys V init implementation, if you have an /etc/inittab file you are most likely running Sys V. Sys V starts and stops processes sequentially, so let's say if you wanted to start up a service named foo-a, well before foo-b can work, you have to make sure foo-a is already running. Sys V does that with scripts, these scripts start and stop services for us, we can write our own scripts or most of the time use the ones that are already built in the operating system and are used to load essential services. The pros of using this implementation of init, is that it's relatively easy to solve dependencies, since you know foo-a comes before foo-b, however performance isn't great because usually one thing is starting or stopping at a time. When using Sys V, the state of the machine is defined by runlevels which are set from 0 to 6. These different modes will vary depending on the distribution, but most of the time will look like the following: 0: Shutdown 1: Single User Mode 2: Multiuser mode without networking 3: Multiuser mode with networking 4: Unused 5: Multiuser mode with networking and GUI 6: Reboot When your system starts up, it looks to see what runlevel you are in and executes scripts located inside that runlevel configuration. The scripts are located in /etc/rc.d/rc[runlevel number].d/ or /etc/init.d . Scripts that start with S(start) or K(kill) will run on startup and shutdown, respectively. The numbers next to these characters are the sequence they run in. For example: mo@icebox:/etc/rc.d/rc0.d$ ls K10updates K80openvpn We see when we switch to runlevel 0 or shutdown mode, our machine will try to run a script to kill the updates services and then openvpn. To find out what runlevel your machine is booting into, you can see the default runlevel in the /etc/inittab file. You can also change your default runlevel in this file as well. One thing to note, System V is slowly getting replaced, maybe not today, or even years from now. However, you may see runlevels come up in other init implementations, this is primarily to support those services that are only started or stopped using System V init scripts. Exercise If you are running System V, change the default runlevel of your machine to something else and see what happens. Quiz Question What runlevel is usually used for shutdown? Quiz Answer 0","title":"System V Overview"},{"location":"init/sysv-overview/#system-v-overview","text":"","title":"System V Overview"},{"location":"init/sysv-overview/#lesson-content","text":"The main purpose of init is to start and stop essential processes on the system. There are three major implementations of init in Linux, System V, Upstart and systemd. In this lesson, we're going to go over the most traditional version of init, System V init or Sys V (pronounced as 'System Five'). To find out if you are using the Sys V init implementation, if you have an /etc/inittab file you are most likely running Sys V. Sys V starts and stops processes sequentially, so let's say if you wanted to start up a service named foo-a, well before foo-b can work, you have to make sure foo-a is already running. Sys V does that with scripts, these scripts start and stop services for us, we can write our own scripts or most of the time use the ones that are already built in the operating system and are used to load essential services. The pros of using this implementation of init, is that it's relatively easy to solve dependencies, since you know foo-a comes before foo-b, however performance isn't great because usually one thing is starting or stopping at a time. When using Sys V, the state of the machine is defined by runlevels which are set from 0 to 6. These different modes will vary depending on the distribution, but most of the time will look like the following: 0: Shutdown 1: Single User Mode 2: Multiuser mode without networking 3: Multiuser mode with networking 4: Unused 5: Multiuser mode with networking and GUI 6: Reboot When your system starts up, it looks to see what runlevel you are in and executes scripts located inside that runlevel configuration. The scripts are located in /etc/rc.d/rc[runlevel number].d/ or /etc/init.d . Scripts that start with S(start) or K(kill) will run on startup and shutdown, respectively. The numbers next to these characters are the sequence they run in. For example: mo@icebox:/etc/rc.d/rc0.d$ ls K10updates K80openvpn We see when we switch to runlevel 0 or shutdown mode, our machine will try to run a script to kill the updates services and then openvpn. To find out what runlevel your machine is booting into, you can see the default runlevel in the /etc/inittab file. You can also change your default runlevel in this file as well. One thing to note, System V is slowly getting replaced, maybe not today, or even years from now. However, you may see runlevels come up in other init implementations, this is primarily to support those services that are only started or stopped using System V init scripts.","title":"Lesson Content"},{"location":"init/sysv-overview/#exercise","text":"If you are running System V, change the default runlevel of your machine to something else and see what happens.","title":"Exercise"},{"location":"init/sysv-overview/#quiz-question","text":"What runlevel is usually used for shutdown?","title":"Quiz Question"},{"location":"init/sysv-overview/#quiz-answer","text":"0","title":"Quiz Answer"},{"location":"init/sysv-services/","text":"System V Service Lesson Content There are many command line tools you can use to manage Sys V services. List services $ service --status-all Start a service $ sudo service networking start Stop a service $ sudo service networking stop Restart a service $ sudo service networking restart These commands aren't specific to Sys V init systems, you can use these commands to manage Upstart services as well. Since Linux is trying to move away from the more traditional Sys V init scripts, there are still things in place to help that transition. Exercise Manage a couple of services and change their states, what do you observe? Quiz Question What is the command to stop a service named peanut with Sys V? Quiz Answer sudo service peanut stop","title":"System V Service"},{"location":"init/sysv-services/#system-v-service","text":"","title":"System V Service"},{"location":"init/sysv-services/#lesson-content","text":"There are many command line tools you can use to manage Sys V services. List services $ service --status-all Start a service $ sudo service networking start Stop a service $ sudo service networking stop Restart a service $ sudo service networking restart These commands aren't specific to Sys V init systems, you can use these commands to manage Upstart services as well. Since Linux is trying to move away from the more traditional Sys V init scripts, there are still things in place to help that transition.","title":"Lesson Content"},{"location":"init/sysv-services/#exercise","text":"Manage a couple of services and change their states, what do you observe?","title":"Exercise"},{"location":"init/sysv-services/#quiz-question","text":"What is the command to stop a service named peanut with Sys V?","title":"Quiz Question"},{"location":"init/sysv-services/#quiz-answer","text":"sudo service peanut stop","title":"Quiz Answer"},{"location":"init/upstart-jobs/","text":"Upstart Jobs Lesson Content Upstart can trigger a lot of events and jobs to run, unfortunately there is no easy way to see where an event or job originated, so you'll have to poke around the job configurations in /etc/init. Most of the time, you won't ever need to look at the Upstart job configuration files, but you will want to control some specific jobs more easily. There are a lot of useful commands you can use in an Upstart system. View jobs initctl list shutdown stop/waiting console stop/waiting ... You'll see a list of Upstart jobs with different statuses applied to them. In each line, the job name is the first value and the second field (before the /) is actually the goal of the job, the third value (after the /) is the current status. So we see that our shutdown job eventually wants to stop, but it is currently in a state of waiting. The job status and goals will change as you start or stop jobs. View specific job initctl status networking networking start/running We won't get into the details of how to write an Upstart job configuration, however we already know that jobs are stopped, started and restarted in these configurations. These jobs also emit events, so they can start other jobs. We'll go through the manual commands of the Upstart operation, but if you are curious, you should dig into the .conf files in more depth. Manually start a job $ sudo initctl start networking Manually stop a job $ sudo initctl stop networking Manually restart a job $ sudo initctl restart networking Manually emit an event $ sudo initctl emit some_event Exercise Observe your list of Upstart jobs, now change the job state with one of the commands we learned today. What do you notice afterwards? Quiz Question How would I manually restart an Upstart job called peanuts? Quiz Answer sudo initctl restart peanuts","title":"Upstart Jobs"},{"location":"init/upstart-jobs/#upstart-jobs","text":"","title":"Upstart Jobs"},{"location":"init/upstart-jobs/#lesson-content","text":"Upstart can trigger a lot of events and jobs to run, unfortunately there is no easy way to see where an event or job originated, so you'll have to poke around the job configurations in /etc/init. Most of the time, you won't ever need to look at the Upstart job configuration files, but you will want to control some specific jobs more easily. There are a lot of useful commands you can use in an Upstart system. View jobs initctl list shutdown stop/waiting console stop/waiting ... You'll see a list of Upstart jobs with different statuses applied to them. In each line, the job name is the first value and the second field (before the /) is actually the goal of the job, the third value (after the /) is the current status. So we see that our shutdown job eventually wants to stop, but it is currently in a state of waiting. The job status and goals will change as you start or stop jobs. View specific job initctl status networking networking start/running We won't get into the details of how to write an Upstart job configuration, however we already know that jobs are stopped, started and restarted in these configurations. These jobs also emit events, so they can start other jobs. We'll go through the manual commands of the Upstart operation, but if you are curious, you should dig into the .conf files in more depth. Manually start a job $ sudo initctl start networking Manually stop a job $ sudo initctl stop networking Manually restart a job $ sudo initctl restart networking Manually emit an event $ sudo initctl emit some_event","title":"Lesson Content"},{"location":"init/upstart-jobs/#exercise","text":"Observe your list of Upstart jobs, now change the job state with one of the commands we learned today. What do you notice afterwards?","title":"Exercise"},{"location":"init/upstart-jobs/#quiz-question","text":"How would I manually restart an Upstart job called peanuts?","title":"Quiz Question"},{"location":"init/upstart-jobs/#quiz-answer","text":"sudo initctl restart peanuts","title":"Quiz Answer"},{"location":"init/upstart-overview/","text":"Upstart Overview Lesson Content Upstart was developed by Canonical, so it was the init implementation on Ubuntu for a while, however on modern Ubuntu installations systemd is now used. Upstart was created to improve upon the issues with Sys V, such as the strict startup processes, blocking of tasks, etc. Upstart's event and job driven model allow it to respond to events as they happen. To find out if you are using Upstart, if you have a /usr/share/upstart directory that's a pretty good indicator. Jobs are the actions that Upstart performs and events are messages that are received from other processes to trigger jobs. To see a list of jobs and their configuration: mo@icebox:~$ ls /etc/init acpid.conf mountnfs.sh.conf alsa-restore.conf mtab.sh.conf alsa-state.conf networking.conf alsa-store.conf network-interface.conf anacron.conf network-interface-container.conf Inside these job configurations, it'll include information on how to start jobs and when to start jobs. For example, in the networking.conf file, it could say something as simple as: start on runlevel [235] stop on runlevel [0] This means that it will start setting up networking on runlevel 2, 3 or 5 and will stop networking on runlevel 0. There are many ways to write the configuration file and you'll discover that when you look at the different job configurations available. The way that Upstart works is that: First, it loads up the job configurations from /etc/init Once a startup event occurs, it will run jobs triggered by that event. These jobs will make new events and then those events will trigger more jobs Upstart continues to do this until it completes all the necessary jobs Exercise If you are running Upstart, see if you can make sense of the job configurations in /etc/init. Quiz Question What is the init implementation that is used by Ubuntu? Quiz Answer upstart","title":"Upstart Overview"},{"location":"init/upstart-overview/#upstart-overview","text":"","title":"Upstart Overview"},{"location":"init/upstart-overview/#lesson-content","text":"Upstart was developed by Canonical, so it was the init implementation on Ubuntu for a while, however on modern Ubuntu installations systemd is now used. Upstart was created to improve upon the issues with Sys V, such as the strict startup processes, blocking of tasks, etc. Upstart's event and job driven model allow it to respond to events as they happen. To find out if you are using Upstart, if you have a /usr/share/upstart directory that's a pretty good indicator. Jobs are the actions that Upstart performs and events are messages that are received from other processes to trigger jobs. To see a list of jobs and their configuration: mo@icebox:~$ ls /etc/init acpid.conf mountnfs.sh.conf alsa-restore.conf mtab.sh.conf alsa-state.conf networking.conf alsa-store.conf network-interface.conf anacron.conf network-interface-container.conf Inside these job configurations, it'll include information on how to start jobs and when to start jobs. For example, in the networking.conf file, it could say something as simple as: start on runlevel [235] stop on runlevel [0] This means that it will start setting up networking on runlevel 2, 3 or 5 and will stop networking on runlevel 0. There are many ways to write the configuration file and you'll discover that when you look at the different job configurations available. The way that Upstart works is that: First, it loads up the job configurations from /etc/init Once a startup event occurs, it will run jobs triggered by that event. These jobs will make new events and then those events will trigger more jobs Upstart continues to do this until it completes all the necessary jobs","title":"Lesson Content"},{"location":"init/upstart-overview/#exercise","text":"If you are running Upstart, see if you can make sense of the job configurations in /etc/init.","title":"Exercise"},{"location":"init/upstart-overview/#quiz-question","text":"What is the init implementation that is used by Ubuntu?","title":"Quiz Question"},{"location":"init/upstart-overview/#quiz-answer","text":"upstart","title":"Quiz Answer"},{"location":"kernel/kernel-installation/","text":"Kernel Installation Ok, now that we've got all that boring stuff out of the way, let's talk about actually installing and modifying kernels. You can install multiple kernels on your system, remember in our lesson on the boot process? In our GRUB menu we can choose which kernel to boot to. To see what kernel version you have on your system, use the following command: $ uname -r 3.19.0-43-generic The uname command prints system information, the -r command will print out all of the kernel release version. You can install the Linux kernel in different ways, you can download the source package and compile from source or you can install it using package management tools. $ sudo apt install linux-generic-lts-vivid and then just reboot into the kernel you installed. Simple right? Kind of, you'll need to also install other linux packages such as the linux-headers, linux-image-generic, etc). You can also specify the version number, so the above command can look like, sudo apt install 3.19.0-43-generic Alternatively, if you just want the updated kernel version, just use dist-upgrade, it performs upgrades to all package on your system: $ sudo apt dist-upgrade There are many different kernel versions, some are used as LTS (long term support), some are the latest and greatest, the compatibility may be very different between kernel versions so you may want to try out different kernels. Exercise Find out what kernel version you have. Research the different versions of kernels available Quiz Questions Click the right arrow to view the answers How do you see the kernel version of your system? uname -r","title":"Installation"},{"location":"kernel/kernel-installation/#kernel-installation","text":"Ok, now that we've got all that boring stuff out of the way, let's talk about actually installing and modifying kernels. You can install multiple kernels on your system, remember in our lesson on the boot process? In our GRUB menu we can choose which kernel to boot to. To see what kernel version you have on your system, use the following command: $ uname -r 3.19.0-43-generic The uname command prints system information, the -r command will print out all of the kernel release version. You can install the Linux kernel in different ways, you can download the source package and compile from source or you can install it using package management tools. $ sudo apt install linux-generic-lts-vivid and then just reboot into the kernel you installed. Simple right? Kind of, you'll need to also install other linux packages such as the linux-headers, linux-image-generic, etc). You can also specify the version number, so the above command can look like, sudo apt install 3.19.0-43-generic Alternatively, if you just want the updated kernel version, just use dist-upgrade, it performs upgrades to all package on your system: $ sudo apt dist-upgrade There are many different kernel versions, some are used as LTS (long term support), some are the latest and greatest, the compatibility may be very different between kernel versions so you may want to try out different kernels.","title":"Kernel Installation"},{"location":"kernel/kernel-installation/#exercise","text":"Find out what kernel version you have. Research the different versions of kernels available","title":"Exercise"},{"location":"kernel/kernel-installation/#quiz-questions","text":"Click the right arrow to view the answers How do you see the kernel version of your system? uname -r","title":"Quiz Questions"},{"location":"kernel/kernel-location/","text":"Kernel Location What happens when you install a new kernel? Well it actually adds a couple of files to your system, these files are usually added to the /boot directory. You will see multiple files for different kernel versions: vmlinuz - this is the actual linux kernel initrd - as we've discussed before, the initrd is used as a temporary file system, used before loading the kernel System.map - symbolic lookup table config - kernel configuration settings, if you are compiling your own kernel, you can set which modules can be loaded If your /boot directory runs out of space, you can always delete old versions of these files or just use a package manager, but be careful when doing maintenance in this directory and don't accidentally delete the kernel you are using. Exercise Go into your boot directory and see what files are in there. Quiz Questions Click the right arrow to view the answers What is the kernel image called in /boot? vmlinuz","title":"Location"},{"location":"kernel/kernel-location/#kernel-location","text":"What happens when you install a new kernel? Well it actually adds a couple of files to your system, these files are usually added to the /boot directory. You will see multiple files for different kernel versions: vmlinuz - this is the actual linux kernel initrd - as we've discussed before, the initrd is used as a temporary file system, used before loading the kernel System.map - symbolic lookup table config - kernel configuration settings, if you are compiling your own kernel, you can set which modules can be loaded If your /boot directory runs out of space, you can always delete old versions of these files or just use a package manager, but be careful when doing maintenance in this directory and don't accidentally delete the kernel you are using.","title":"Kernel Location"},{"location":"kernel/kernel-location/#exercise","text":"Go into your boot directory and see what files are in there.","title":"Exercise"},{"location":"kernel/kernel-location/#quiz-questions","text":"Click the right arrow to view the answers What is the kernel image called in /boot? vmlinuz","title":"Quiz Questions"},{"location":"kernel/kernel-modules/","text":"Kernel Modules Let's say I have a sweet ride, I invest a lot of time and money into it. I add a spoiler, hitch, bike rack and other random things. These components don't actually change the core functionality of the car and I can remove and add them very easily. The kernel uses the same concept with kernel modules. The kernel in itself is a monolithic piece of software, when we want to add support for a new type of keyboard, we don't write this code directly into the kernel code. Just as we wouldn't meld a bike rack to our car (well maybe some people would do that). Kernel modules are pieces of code that can be loaded and unloaded into the kernel on demand. They allow us to extend the functionality of the kernel without actually adding to the core kernel code. We can also add modules and not have to reboot the system (in most cases). View a list of currently loaded modules $ lsmod Load a module $ sudo modprobe bluetooth Modprobe loads tries the module from /lib/modules/(kernel version)/kernel/drivers . Kernel modules may also have dependencies, modprobe loads our module dependencies if they are not already loaded. Remove a module $ sudo modprobe -r bluetooth Load on bootup You can also load modules during system boot, instead of temporarily loading them with modprobe (which will be unloaded when you reboot). Just modify the /etc/modprobe.d directory and add a configuration file in it like so: mo@icebox:~$ /etc/modprobe.d/peanutbutter.conf options peanut_butter type=almond A bit of a outlandish example, but if you had a module named peanut_butter and you wanted to add a kernel parameter for type=almond, you can have it load on startup using this configuration file. Also note that kernel modules have their own kernel parameters so you'll want to read about the module specifically to find out more. Do not load on bootup You can also make sure a module does not load on bootup by adding a configuration file like so: mo@icebox:~$ /etc/modprobe.d/peanutbutter.conf blacklist peanut_butter Exercise Unload your bluetooth module with modprobe and see what happens. How will you fix this? Quiz Questions Click the right arrow to view the answers What command is used to unload a module? modprobe -r","title":"Modules"},{"location":"kernel/kernel-modules/#kernel-modules","text":"Let's say I have a sweet ride, I invest a lot of time and money into it. I add a spoiler, hitch, bike rack and other random things. These components don't actually change the core functionality of the car and I can remove and add them very easily. The kernel uses the same concept with kernel modules. The kernel in itself is a monolithic piece of software, when we want to add support for a new type of keyboard, we don't write this code directly into the kernel code. Just as we wouldn't meld a bike rack to our car (well maybe some people would do that). Kernel modules are pieces of code that can be loaded and unloaded into the kernel on demand. They allow us to extend the functionality of the kernel without actually adding to the core kernel code. We can also add modules and not have to reboot the system (in most cases). View a list of currently loaded modules $ lsmod Load a module $ sudo modprobe bluetooth Modprobe loads tries the module from /lib/modules/(kernel version)/kernel/drivers . Kernel modules may also have dependencies, modprobe loads our module dependencies if they are not already loaded. Remove a module $ sudo modprobe -r bluetooth Load on bootup You can also load modules during system boot, instead of temporarily loading them with modprobe (which will be unloaded when you reboot). Just modify the /etc/modprobe.d directory and add a configuration file in it like so: mo@icebox:~$ /etc/modprobe.d/peanutbutter.conf options peanut_butter type=almond A bit of a outlandish example, but if you had a module named peanut_butter and you wanted to add a kernel parameter for type=almond, you can have it load on startup using this configuration file. Also note that kernel modules have their own kernel parameters so you'll want to read about the module specifically to find out more. Do not load on bootup You can also make sure a module does not load on bootup by adding a configuration file like so: mo@icebox:~$ /etc/modprobe.d/peanutbutter.conf blacklist peanut_butter","title":"Kernel Modules"},{"location":"kernel/kernel-modules/#exercise","text":"Unload your bluetooth module with modprobe and see what happens. How will you fix this?","title":"Exercise"},{"location":"kernel/kernel-modules/#quiz-questions","text":"Click the right arrow to view the answers What command is used to unload a module? modprobe -r","title":"Quiz Questions"},{"location":"kernel/kernel-overview/","text":"Overview of the Kernel As you've learned up to this point, the kernel is the core of the operating system. We've talked about the other parts of the operating system but have yet to show how they all work together. The Linux operating system can be organized into three different levels of abstraction. The most basic level is hardware, this includes our CPU, memory, hard disks, networking ports, etc. The physical layer that actually computes what our machine is doing. The next level is the kernel, which handles process and memory management, device communication, system calls, sets up our filesystem, etc. The kernel's job is to talk to the hardware to make sure it does what we want our processes to do. And the level that you are familiar with is the user space, the user space includes the shell, the programs that you run, the graphics, etc. In this course, we'll be focusing on the kernel and learning its intricacies. Quiz Questions Click the right arrow to view the answers What level of the operating system manages devices? kernel","title":"Overview"},{"location":"kernel/kernel-overview/#overview-of-the-kernel","text":"As you've learned up to this point, the kernel is the core of the operating system. We've talked about the other parts of the operating system but have yet to show how they all work together. The Linux operating system can be organized into three different levels of abstraction. The most basic level is hardware, this includes our CPU, memory, hard disks, networking ports, etc. The physical layer that actually computes what our machine is doing. The next level is the kernel, which handles process and memory management, device communication, system calls, sets up our filesystem, etc. The kernel's job is to talk to the hardware to make sure it does what we want our processes to do. And the level that you are familiar with is the user space, the user space includes the shell, the programs that you run, the graphics, etc. In this course, we'll be focusing on the kernel and learning its intricacies.","title":"Overview of the Kernel"},{"location":"kernel/kernel-overview/#quiz-questions","text":"Click the right arrow to view the answers What level of the operating system manages devices? kernel","title":"Quiz Questions"},{"location":"kernel/kernel-privilege-levels/","text":"Privilege Levels The next few lessons get pretty theoretical, so if you're looking for some practical stuff you can skip ahead and come back later. Why do we have different abstraction layers for user space and kernel? Why can't you combine both powers into one layer? Well there is a very good reason why these two layers exist separately. They both operate in different modes, the kernel operates in kernel mode and the user space operates in user mode. In kernel mode, the kernel has complete access to the hardware, it controls everything. In user space mode, there is a very small amount of safe memory and CPU that you are allowed to access. Basically, when we want to do anything that involves hardware, reading data from our disks, writing data to our disks, controlling our network, etc, it is all done in kernel mode. Why is this necessary? Imagine if your machine was infected with spyware, you wouldn't want it to be able to have direct access to your system's hardware. It can access all your data, your webcam, etc. and that's no good. These different modes are called privilege levels (aptly named for the levels of privilege you get) and are often described as protection rings. To make this picture easier to paint, let's say you find out that Britney Spears is in town at your local klerb, she's protected by her groupies, then her personal bodyguards, then the bouncer outside the klerb. You want to get her autograph (because why not?), but you can't get to her because she is heavily protected. The rings work the same way, the innermost ring corresponds to the highest privilege level. There are two main levels or modes in an x86 computer architecture. Ring #3 is the privilege that user mode applications run in, Ring #0 is the privilege that the kernel runs in. Ring #0 can execute any system instruction and is given full trust. So now that we know how those privilege levels work, how are we able to write anything to our hardware? Won't we always be in a different mode than the kernel? The answer is with system calls, system calls allow us to perform a privileged instruction in kernel mode and then switch back to user mode. Quiz Questions Click the right arrow to view the answers What ring number has the highest privileges? 0","title":"Privilege Levels"},{"location":"kernel/kernel-privilege-levels/#privilege-levels","text":"The next few lessons get pretty theoretical, so if you're looking for some practical stuff you can skip ahead and come back later. Why do we have different abstraction layers for user space and kernel? Why can't you combine both powers into one layer? Well there is a very good reason why these two layers exist separately. They both operate in different modes, the kernel operates in kernel mode and the user space operates in user mode. In kernel mode, the kernel has complete access to the hardware, it controls everything. In user space mode, there is a very small amount of safe memory and CPU that you are allowed to access. Basically, when we want to do anything that involves hardware, reading data from our disks, writing data to our disks, controlling our network, etc, it is all done in kernel mode. Why is this necessary? Imagine if your machine was infected with spyware, you wouldn't want it to be able to have direct access to your system's hardware. It can access all your data, your webcam, etc. and that's no good. These different modes are called privilege levels (aptly named for the levels of privilege you get) and are often described as protection rings. To make this picture easier to paint, let's say you find out that Britney Spears is in town at your local klerb, she's protected by her groupies, then her personal bodyguards, then the bouncer outside the klerb. You want to get her autograph (because why not?), but you can't get to her because she is heavily protected. The rings work the same way, the innermost ring corresponds to the highest privilege level. There are two main levels or modes in an x86 computer architecture. Ring #3 is the privilege that user mode applications run in, Ring #0 is the privilege that the kernel runs in. Ring #0 can execute any system instruction and is given full trust. So now that we know how those privilege levels work, how are we able to write anything to our hardware? Won't we always be in a different mode than the kernel? The answer is with system calls, system calls allow us to perform a privileged instruction in kernel mode and then switch back to user mode.","title":"Privilege Levels"},{"location":"kernel/kernel-privilege-levels/#quiz-questions","text":"Click the right arrow to view the answers What ring number has the highest privileges? 0","title":"Quiz Questions"},{"location":"kernel/system-calls/","text":"System Calls Remember Britney in the previous lesson? Let's say we want to see her and get some drinks together, how do we get from standing outside in the crowds of people to inside her innermost circle? We would use system calls. System calls are like the VIP passes that get you to a secret side door that leads directly to Britney. System calls (syscall) provide user space processes a way to request the kernel to do something for us. The kernel makes certain services available through the system call API. These services allow us to read or write to a file, modify memory usage, modify our network, etc. The amount of services are fixed, so you can't be adding system calls nilly willy, your system already has a table of what system calls exist and each system call has a unique ID. I won't get into specifics of system calls, as that will require you to know a bit of C, but the basics is that when you call a program like ls, the code inside this program contains a system call wrapper (so not the actual system call yet). Inside this wrapper it invokes the system call which will execute a trap, this trap then gets caught by the system call handler and then references the system call in the system call table. Let's say we are trying to call the stat() system call, it's identified by a syscall ID and the purpose of the stat() system call is to query the status of a file. Now remember, you were running the ls program in non-privilege mode. So now it sees you're trying to make a syscall, it then switches you over to kernel mode, there it does lots of things but most importantly it looks up your syscall number, finds it in a table based on the syscall ID and then executes the function you wanted to run. Once it's done, it will return back to user mode and your process will receive a return status if it was successful or if it had an error. The inner workings of syscalls get really detailed, I would recommend looking at information online if you want to learn more. You can actually view the system calls that a process makes with the strace command. The strace command is useful for debugging how a program executed. $ strace ls Quiz Questions Click the right arrow to view the answers What is used to switch from user mode to kernel mode? system call","title":"System calls"},{"location":"kernel/system-calls/#system-calls","text":"Remember Britney in the previous lesson? Let's say we want to see her and get some drinks together, how do we get from standing outside in the crowds of people to inside her innermost circle? We would use system calls. System calls are like the VIP passes that get you to a secret side door that leads directly to Britney. System calls (syscall) provide user space processes a way to request the kernel to do something for us. The kernel makes certain services available through the system call API. These services allow us to read or write to a file, modify memory usage, modify our network, etc. The amount of services are fixed, so you can't be adding system calls nilly willy, your system already has a table of what system calls exist and each system call has a unique ID. I won't get into specifics of system calls, as that will require you to know a bit of C, but the basics is that when you call a program like ls, the code inside this program contains a system call wrapper (so not the actual system call yet). Inside this wrapper it invokes the system call which will execute a trap, this trap then gets caught by the system call handler and then references the system call in the system call table. Let's say we are trying to call the stat() system call, it's identified by a syscall ID and the purpose of the stat() system call is to query the status of a file. Now remember, you were running the ls program in non-privilege mode. So now it sees you're trying to make a syscall, it then switches you over to kernel mode, there it does lots of things but most importantly it looks up your syscall number, finds it in a table based on the syscall ID and then executes the function you wanted to run. Once it's done, it will return back to user mode and your process will receive a return status if it was successful or if it had an error. The inner workings of syscalls get really detailed, I would recommend looking at information online if you want to learn more. You can actually view the system calls that a process makes with the strace command. The strace command is useful for debugging how a program executed. $ strace ls","title":"System Calls"},{"location":"kernel/system-calls/#quiz-questions","text":"Click the right arrow to view the answers What is used to switch from user mode to kernel mode? system call","title":"Quiz Questions"},{"location":"logging/authentication-logging/","text":"Authentication Logging Authentication logging can be very useful to look at if you are having issues logging in. /var/log/auth.log This contains system authorization logs, such as user login and the authentication method used. Sample snippet: Jan 31 10:37:50 box pkexec: pam_unix(polkit-1:session): session opened for user root by (uid=1000) Exercise Do some failed logins and then a successful one, look at your /var/log/auth.log and see what happened. Quiz Question What log is used for user authentication? Quiz Answer auth.log","title":"Authentication Logging"},{"location":"logging/authentication-logging/#authentication-logging","text":"Authentication logging can be very useful to look at if you are having issues logging in. /var/log/auth.log This contains system authorization logs, such as user login and the authentication method used. Sample snippet: Jan 31 10:37:50 box pkexec: pam_unix(polkit-1:session): session opened for user root by (uid=1000)","title":"Authentication Logging"},{"location":"logging/authentication-logging/#exercise","text":"Do some failed logins and then a successful one, look at your /var/log/auth.log and see what happened.","title":"Exercise"},{"location":"logging/authentication-logging/#quiz-question","text":"What log is used for user authentication?","title":"Quiz Question"},{"location":"logging/authentication-logging/#quiz-answer","text":"auth.log","title":"Quiz Answer"},{"location":"logging/general-logging/","text":"General Logging There are many log files you can view on your system, many important ones can be found under /var/log. We won't go through them all, but we'll discuss a couple of the major ones. There are two general log files you can view to get a glimpse of what your system is doing: /var/log/messages This log contains all non-critical and non-debug messages, includes messages logged during bootup (dmesg), auth, cron, daemon, etc. Very useful to get a glimpse of how your machine is acting. /var/log/syslog This logs everything except auth messages, it's extremely useful for debugging errors on your machine. These two logs should be more than enough when troubleshooting issues with your system, However, if you just want to view a specific log component, there are also separate logs for those as well. Exercise Look at your /var/log/messages and /var/log/syslog files and see what the differences are. Quiz Question What log file logs everything except auth messages? Quiz Answer syslog","title":"General Logging"},{"location":"logging/general-logging/#general-logging","text":"There are many log files you can view on your system, many important ones can be found under /var/log. We won't go through them all, but we'll discuss a couple of the major ones. There are two general log files you can view to get a glimpse of what your system is doing: /var/log/messages This log contains all non-critical and non-debug messages, includes messages logged during bootup (dmesg), auth, cron, daemon, etc. Very useful to get a glimpse of how your machine is acting. /var/log/syslog This logs everything except auth messages, it's extremely useful for debugging errors on your machine. These two logs should be more than enough when troubleshooting issues with your system, However, if you just want to view a specific log component, there are also separate logs for those as well.","title":"General Logging"},{"location":"logging/general-logging/#exercise","text":"Look at your /var/log/messages and /var/log/syslog files and see what the differences are.","title":"Exercise"},{"location":"logging/general-logging/#quiz-question","text":"What log file logs everything except auth messages?","title":"Quiz Question"},{"location":"logging/general-logging/#quiz-answer","text":"syslog","title":"Quiz Answer"},{"location":"logging/kernel-logging/","text":"Kernel Logging /var/log/dmesg On boot-time your system logs information about the kernel ring buffer. This shows us information about hardware drivers, kernel information and status during bootup and more. This log file can be found at /var/log/dmesg and gets reset on every boot, you may not actually see any use in it now, but if you were to ever have issues with something during bootup or a hardware issue, dmesg is the best place to look. You can also view this log using the dmesg command. /var/log/kern.log Another log you can use to view kernel information is the /var/log/kern.log file, this logs the kernel information and events on your system, it also logs dmesg output. Exercise Look at your dmesg and kern logs, what differences do you notice? Quiz Questions Click the right arrow to view the answers What command can be used to view kernel bootup messages? dmesg","title":"Kernel Logging"},{"location":"logging/kernel-logging/#kernel-logging","text":"/var/log/dmesg On boot-time your system logs information about the kernel ring buffer. This shows us information about hardware drivers, kernel information and status during bootup and more. This log file can be found at /var/log/dmesg and gets reset on every boot, you may not actually see any use in it now, but if you were to ever have issues with something during bootup or a hardware issue, dmesg is the best place to look. You can also view this log using the dmesg command. /var/log/kern.log Another log you can use to view kernel information is the /var/log/kern.log file, this logs the kernel information and events on your system, it also logs dmesg output.","title":"Kernel Logging"},{"location":"logging/kernel-logging/#exercise","text":"Look at your dmesg and kern logs, what differences do you notice?","title":"Exercise"},{"location":"logging/kernel-logging/#quiz-questions","text":"Click the right arrow to view the answers What command can be used to view kernel bootup messages? dmesg","title":"Quiz Questions"},{"location":"logging/managing-log-files/","text":"Managing Log Files Log files generate lots of data and they store this data on your hard disks, however there are lots of issues with this, for the most part we just want to be able to see newer logs, we also want to manage our disk space efficiently, so how do we do all of this? The answer is with logrotate. The logrotate utility does log management for us. It has a configuration file that allows us to specify how many and what logs to keep, how to compress our logs to save space and more. The logrotate tool is usually run out of cron once a day and the configuration files can be found in /etc/logrotate.d. There are other logrotating tools you can use to manage your logs, but logrotate is the most common one. Exercise Look at your logrotate configuration file and see how it manages some of your logs. Quiz Questions Click the right arrow to view the answers What utility is used to manage logs? logrotate","title":"Managing Log Files"},{"location":"logging/managing-log-files/#managing-log-files","text":"Log files generate lots of data and they store this data on your hard disks, however there are lots of issues with this, for the most part we just want to be able to see newer logs, we also want to manage our disk space efficiently, so how do we do all of this? The answer is with logrotate. The logrotate utility does log management for us. It has a configuration file that allows us to specify how many and what logs to keep, how to compress our logs to save space and more. The logrotate tool is usually run out of cron once a day and the configuration files can be found in /etc/logrotate.d. There are other logrotating tools you can use to manage your logs, but logrotate is the most common one.","title":"Managing Log Files"},{"location":"logging/managing-log-files/#exercise","text":"Look at your logrotate configuration file and see how it manages some of your logs.","title":"Exercise"},{"location":"logging/managing-log-files/#quiz-questions","text":"Click the right arrow to view the answers What utility is used to manage logs? logrotate","title":"Quiz Questions"},{"location":"logging/syslog/","text":"syslog The syslog service manages and sends logs to the system logger. Rsyslog is an advanced version of syslog, most Linux distributions should be using this new version. The output of all the logs the syslog service collects can be found at /var/log/syslog (every message except auth messages). To find out what files are maintained by our system logger, look at the configuration files in /etc/rsyslog.d: mo:~$ less /etc/rsyslog.d/50-default.conf # First some standard log files. Log by facility. # auth,authpriv.* /var/log/auth.log *.*;auth,authpriv.none -/var/log/syslog #cron.* /var/log/cron.log #daemon.* -/var/log/daemon.log kern.* -/var/log/kern.log #lpr.* -/var/log/lpr.log mail.* -/var/log/mail.log #user.* -/var/log/user.log These rules to log files are denoted by the selector on the left column and the action on the right column. The action tells us where to send the log information, in a file, console, etc. Remember not every application and service uses rsyslog to manage their logs, so if you want to know specifically what is logged you'll have to look inside this directory. Let's actually see logging in action, you can manually send a log with the logger command: logger -s Hello Now look inside your /var/log/syslog and you should see this entry in your logs! Exercise Look at your /etc/rsyslog.d configuration file and see what else is being logged via the system logger. Quiz Questions Click the right arrow to view the answers What command can you use to manually log a message? logger","title":"syslog"},{"location":"logging/syslog/#syslog","text":"The syslog service manages and sends logs to the system logger. Rsyslog is an advanced version of syslog, most Linux distributions should be using this new version. The output of all the logs the syslog service collects can be found at /var/log/syslog (every message except auth messages). To find out what files are maintained by our system logger, look at the configuration files in /etc/rsyslog.d: mo:~$ less /etc/rsyslog.d/50-default.conf # First some standard log files. Log by facility. # auth,authpriv.* /var/log/auth.log *.*;auth,authpriv.none -/var/log/syslog #cron.* /var/log/cron.log #daemon.* -/var/log/daemon.log kern.* -/var/log/kern.log #lpr.* -/var/log/lpr.log mail.* -/var/log/mail.log #user.* -/var/log/user.log These rules to log files are denoted by the selector on the left column and the action on the right column. The action tells us where to send the log information, in a file, console, etc. Remember not every application and service uses rsyslog to manage their logs, so if you want to know specifically what is logged you'll have to look inside this directory. Let's actually see logging in action, you can manually send a log with the logger command: logger -s Hello Now look inside your /var/log/syslog and you should see this entry in your logs!","title":"syslog"},{"location":"logging/syslog/#exercise","text":"Look at your /etc/rsyslog.d configuration file and see what else is being logged via the system logger.","title":"Exercise"},{"location":"logging/syslog/#quiz-questions","text":"Click the right arrow to view the answers What command can you use to manually log a message? logger","title":"Quiz Questions"},{"location":"logging/system-logging/","text":"System Logging The services, kernel, daemons, etc on your system are constantly doing something, this data is actually sent to be saved on your system in the form of logs. This allows us to have a human readable journal of the events that are happening on our system. This data is usually kept in the /var directory, the /var directory is where we keep our variable data, such as logs! How are these messages even getting received on your system? There is a service called syslog that sends this information to the system logger. Syslog actually contains many components, one of the important ones is a daemon running called syslogd (newer Linux distributions use rsyslogd), that waits for event messages to occur and filter the ones it wants to know about, and depending on what it's supposed to do with that message, it will send it to a file, your console or do nothing with it. You would think that this system logger is the centralized place to manage logs, but unfortunately it's not. You'll see many applications that write their own logging rules and generate different log files, however in general the format of logs should include a timestamp and the event details. Here is an example of a line from syslog: mo:~$ less /var/log/syslog Jan 27 07:41:32 icebox anacron[4650]: Job `cron.weekly' started Here we can see that at Jan 27 07:41:32 our cron service ran the cron.weekly job. You can view all the event messages that syslog collects with in the /var/log/syslog file. Exercise Look at your /var/log/syslog file and see what else is happening on your machine. Quiz Questions Click the right arrow to view the answers What is the daemon that manages log on newer Linux systems? rsyslogd","title":"System Logging"},{"location":"logging/system-logging/#system-logging","text":"The services, kernel, daemons, etc on your system are constantly doing something, this data is actually sent to be saved on your system in the form of logs. This allows us to have a human readable journal of the events that are happening on our system. This data is usually kept in the /var directory, the /var directory is where we keep our variable data, such as logs! How are these messages even getting received on your system? There is a service called syslog that sends this information to the system logger. Syslog actually contains many components, one of the important ones is a daemon running called syslogd (newer Linux distributions use rsyslogd), that waits for event messages to occur and filter the ones it wants to know about, and depending on what it's supposed to do with that message, it will send it to a file, your console or do nothing with it. You would think that this system logger is the centralized place to manage logs, but unfortunately it's not. You'll see many applications that write their own logging rules and generate different log files, however in general the format of logs should include a timestamp and the event details. Here is an example of a line from syslog: mo:~$ less /var/log/syslog Jan 27 07:41:32 icebox anacron[4650]: Job `cron.weekly' started Here we can see that at Jan 27 07:41:32 our cron service ran the cron.weekly job. You can view all the event messages that syslog collects with in the /var/log/syslog file.","title":"System Logging"},{"location":"logging/system-logging/#exercise","text":"Look at your /var/log/syslog file and see what else is happening on your machine.","title":"Exercise"},{"location":"logging/system-logging/#quiz-questions","text":"Click the right arrow to view the answers What is the daemon that manages log on newer Linux systems? rsyslogd","title":"Quiz Questions"},{"location":"network-configuration/arp-command/","text":"ARP Remember when we lookup a MAC address with ARP, it first checks the locally stored ARP cache on our system, you can actually view this cache: mo:~$ arp Address HWtype HWaddress Flags Mask Iface 192.168.22.1 ether 00:12:24:fc:12:cc C eth0 192.168.22.254 ether 00:12:45:f2:84:64 C eth0 The ARP cache is actually empty when a machine boots up, it gets populated as packets are being sent to other hosts. If we send a packet to a destination that isn't in the ARP cache, the following happens: The source host creates the Ethernet frame with an ARP request packet The source host broadcasts this frame to the entire network If one of the hosts on the network knows the correct MAC address, it will send a reply packet and frame containing the MAC address The source host adds the IP to MAC address mapping to the ARP cache and then proceeds with sending the packet You can also view your arp cache via the ip command: $ ip neighbour show Exercise Observe what happens to your ARP cache when you reboot your machine and then do something on the network. Quiz Questions Click the right arrow to view the answers What command can you use to view your ARP cache? arp","title":"ARP"},{"location":"network-configuration/arp-command/#arp","text":"Remember when we lookup a MAC address with ARP, it first checks the locally stored ARP cache on our system, you can actually view this cache: mo:~$ arp Address HWtype HWaddress Flags Mask Iface 192.168.22.1 ether 00:12:24:fc:12:cc C eth0 192.168.22.254 ether 00:12:45:f2:84:64 C eth0 The ARP cache is actually empty when a machine boots up, it gets populated as packets are being sent to other hosts. If we send a packet to a destination that isn't in the ARP cache, the following happens: The source host creates the Ethernet frame with an ARP request packet The source host broadcasts this frame to the entire network If one of the hosts on the network knows the correct MAC address, it will send a reply packet and frame containing the MAC address The source host adds the IP to MAC address mapping to the ARP cache and then proceeds with sending the packet You can also view your arp cache via the ip command: $ ip neighbour show","title":"ARP"},{"location":"network-configuration/arp-command/#exercise","text":"Observe what happens to your ARP cache when you reboot your machine and then do something on the network.","title":"Exercise"},{"location":"network-configuration/arp-command/#quiz-questions","text":"Click the right arrow to view the answers What command can you use to view your ARP cache? arp","title":"Quiz Questions"},{"location":"network-configuration/dhclient/","text":"dhclient We've discussed DHCP before and most often you will never need to statically set your IP addresses, subnet masks, etc. Instead you'll be using DHCP! The dhclient starts up on boot and gets a list of network interfaces from the dhclient.conf file. For each interface listed it tries to configure the interface using the DHCP protocol. In the dhclient.leases file, dhclient keeps track of a list of leases across system reboots, after reading dhclient.conf, the dhclient.leases file is read to let it know what leases it's already assigned. To obtain a fresh IP $ sudo dhclient Quiz Questions Click the right arrow to view the answers What tries to assign IP addresses with the DHCP protocol? dhclient","title":"dhclient"},{"location":"network-configuration/dhclient/#dhclient","text":"We've discussed DHCP before and most often you will never need to statically set your IP addresses, subnet masks, etc. Instead you'll be using DHCP! The dhclient starts up on boot and gets a list of network interfaces from the dhclient.conf file. For each interface listed it tries to configure the interface using the DHCP protocol. In the dhclient.leases file, dhclient keeps track of a list of leases across system reboots, after reading dhclient.conf, the dhclient.leases file is read to let it know what leases it's already assigned. To obtain a fresh IP $ sudo dhclient","title":"dhclient"},{"location":"network-configuration/dhclient/#quiz-questions","text":"Click the right arrow to view the answers What tries to assign IP addresses with the DHCP protocol? dhclient","title":"Quiz Questions"},{"location":"network-configuration/network-interfaces/","text":"Network Interfaces A network interface is how the kernel links up the software side of networking to the hardware side. We've already seen an example of this: mo:~$ ifconfig -a eth0 Link encap:Ethernet HWaddr 1d:3a:32:24:4d:ce inet addr:192.168.1.129 Bcast:192.168.1.255 Mask:255.255.255.0 inet6 addr: fd60::21c:29ff:fe63:5cdc/64 Scope:Link The ifconfig command The ifconfig tool allows us to configure our network interfaces, if we don't have any network interfaces set up, the kernel's device drivers and the network won't know how to talk to each other. Ifconfig runs on bootup and configures our interfaces through config files, but we can also manually modify them. The output of ifconfig shows the interface name on the left side and the right side shows detailed information. You'll most commonly see interfaces named eth0 (first Ethernet card in the machine), wlan0 (wireless interface), lo (loopback interface). The loopback interface is used to represent your computer, it just loops you back to yourself. This is good for debugging or connecting to servers running locally. The status of interfaces, can be up or down, as you can guess if you wanted to \"turn off\" an interface you can set it to go down. The fields you'll probably look at the most in the ifconfig output is the HWaddr (MAC address of the interface), inet address (IPv4 address) and inet6 (IPv6 address). Of course you can see that the subnet mask and broadcast address are there as well. You can also view interface information at /etc/network/interfaces. To create an interface and bring it up $ ifconfig eth0 192.168.2.1 netmask 255.255.255.0 up This assigns an IP address and netmask to the eth0 interface and also turns it up. To bring up or down an interface $ ifup eth0 $ ifdown eth0 The ip command The ip command also allows us to manipulate the networking stack of a system. Depending on the distribution you are using it may be the preferred method of manipulating your network settings. Here are some examples of its use: To show interface information for all interfaces $ ip link show To show the statistics of an interface $ ip -s link show eth0 To show ip addresses allocated to interfaces $ ip address show To bring interfaces up and down $ ip link set eth0 up $ ip link set eth0 down To add an IP address to an interface $ ip address add 192.168.1.1/24 dev eth0 Exercise Try changing the state of your network interfaces to either up or down and observe what happens. Can you change your network interface's with both the ifconfig and ip commands ? Quiz Questions Click the right arrow to view the answers What is the command to configure our network interfaces? ifconfig","title":"Network Interfaces"},{"location":"network-configuration/network-interfaces/#network-interfaces","text":"A network interface is how the kernel links up the software side of networking to the hardware side. We've already seen an example of this: mo:~$ ifconfig -a eth0 Link encap:Ethernet HWaddr 1d:3a:32:24:4d:ce inet addr:192.168.1.129 Bcast:192.168.1.255 Mask:255.255.255.0 inet6 addr: fd60::21c:29ff:fe63:5cdc/64 Scope:Link The ifconfig command The ifconfig tool allows us to configure our network interfaces, if we don't have any network interfaces set up, the kernel's device drivers and the network won't know how to talk to each other. Ifconfig runs on bootup and configures our interfaces through config files, but we can also manually modify them. The output of ifconfig shows the interface name on the left side and the right side shows detailed information. You'll most commonly see interfaces named eth0 (first Ethernet card in the machine), wlan0 (wireless interface), lo (loopback interface). The loopback interface is used to represent your computer, it just loops you back to yourself. This is good for debugging or connecting to servers running locally. The status of interfaces, can be up or down, as you can guess if you wanted to \"turn off\" an interface you can set it to go down. The fields you'll probably look at the most in the ifconfig output is the HWaddr (MAC address of the interface), inet address (IPv4 address) and inet6 (IPv6 address). Of course you can see that the subnet mask and broadcast address are there as well. You can also view interface information at /etc/network/interfaces. To create an interface and bring it up $ ifconfig eth0 192.168.2.1 netmask 255.255.255.0 up This assigns an IP address and netmask to the eth0 interface and also turns it up. To bring up or down an interface $ ifup eth0 $ ifdown eth0 The ip command The ip command also allows us to manipulate the networking stack of a system. Depending on the distribution you are using it may be the preferred method of manipulating your network settings. Here are some examples of its use: To show interface information for all interfaces $ ip link show To show the statistics of an interface $ ip -s link show eth0 To show ip addresses allocated to interfaces $ ip address show To bring interfaces up and down $ ip link set eth0 up $ ip link set eth0 down To add an IP address to an interface $ ip address add 192.168.1.1/24 dev eth0","title":"Network Interfaces"},{"location":"network-configuration/network-interfaces/#exercise","text":"Try changing the state of your network interfaces to either up or down and observe what happens. Can you change your network interface's with both the ifconfig and ip commands ?","title":"Exercise"},{"location":"network-configuration/network-interfaces/#quiz-questions","text":"Click the right arrow to view the answers What is the command to configure our network interfaces? ifconfig","title":"Quiz Questions"},{"location":"network-configuration/network-manager/","text":"Network Manager Of course if you wanted to have your system's networking up and running automatically there is something already in place for that. Most distributions utilize the NetworkManager daemon to configure their networks automatically. You'll notice NetworkManager in the form of an applet somewhere on your desktop taskbar if you are using a GUI. As you can see it manages your network's hardware and connection information. For instance on startup, NetworkManager will gather network hardware information, search for connections to wireless, wired, etc. and then activates it. There are also command-line tools to interact with NetworkManager: nm-tool nm-tools reports NetworkManager's state and it's devices mo:/$ nm-tool NetworkManager Tool State: connected (global) - Device: eth0 [Wired connection 1] ------------------------------------------- Type: Wired Driver: pcnet32 State: connected Default: yes HW Address: 12:3D:45:56:7D:CC Capabilities: Carrier Detect: yes Wired Properties Carrier: on IPv4 Settings: Address: 192.168.22.1 Prefix: 24 (255.255.255.0) Gateway: 192.168.22.2 DNS: 192.168.22.2 nmcli The nmcli command allows you to control and modify NetworkManager, see the manpage for more details. Quiz Questions Click the right arrow to view the answers What is the command to view NetworkManager information? nm-tool","title":"Network Manager"},{"location":"network-configuration/network-manager/#network-manager","text":"Of course if you wanted to have your system's networking up and running automatically there is something already in place for that. Most distributions utilize the NetworkManager daemon to configure their networks automatically. You'll notice NetworkManager in the form of an applet somewhere on your desktop taskbar if you are using a GUI. As you can see it manages your network's hardware and connection information. For instance on startup, NetworkManager will gather network hardware information, search for connections to wireless, wired, etc. and then activates it. There are also command-line tools to interact with NetworkManager: nm-tool nm-tools reports NetworkManager's state and it's devices mo:/$ nm-tool NetworkManager Tool State: connected (global) - Device: eth0 [Wired connection 1] ------------------------------------------- Type: Wired Driver: pcnet32 State: connected Default: yes HW Address: 12:3D:45:56:7D:CC Capabilities: Carrier Detect: yes Wired Properties Carrier: on IPv4 Settings: Address: 192.168.22.1 Prefix: 24 (255.255.255.0) Gateway: 192.168.22.2 DNS: 192.168.22.2 nmcli The nmcli command allows you to control and modify NetworkManager, see the manpage for more details.","title":"Network Manager"},{"location":"network-configuration/network-manager/#quiz-questions","text":"Click the right arrow to view the answers What is the command to view NetworkManager information? nm-tool","title":"Quiz Questions"},{"location":"network-configuration/route/","text":"Route We've already discussed viewing our routing tables with the route command, if you wanted to add or remove routes you can do so manually. Add a new route $ sudo route add -net 192.168.2.1/23 gw 10.11.12.3 Delete a route $ sudo route del -net 192.168.2.1/23 You can also perform these changes with the ip command: To add a route $ ip route add 192.168.2.1/23 via 10.11.12.3 To delete a route $ ip route delete 192.168.2.1/23 via 10.11.12.3 or $ ip route delete 192.168.2.1/23 Exercise There are no exercises for this lesson but you can read more information on commands discussed here in the man pages $ man route $ man ip-route Quiz Questions Click the right arrow to view the answers What is the command flag to delete a route? del","title":"Route"},{"location":"network-configuration/route/#route","text":"We've already discussed viewing our routing tables with the route command, if you wanted to add or remove routes you can do so manually. Add a new route $ sudo route add -net 192.168.2.1/23 gw 10.11.12.3 Delete a route $ sudo route del -net 192.168.2.1/23 You can also perform these changes with the ip command: To add a route $ ip route add 192.168.2.1/23 via 10.11.12.3 To delete a route $ ip route delete 192.168.2.1/23 via 10.11.12.3 or $ ip route delete 192.168.2.1/23","title":"Route"},{"location":"network-configuration/route/#exercise","text":"There are no exercises for this lesson but you can read more information on commands discussed here in the man pages $ man route $ man ip-route","title":"Exercise"},{"location":"network-configuration/route/#quiz-questions","text":"Click the right arrow to view the answers What is the command flag to delete a route? del","title":"Quiz Questions"},{"location":"network-fundamentals/application-layer/","text":"Application Layer (Layer 7) Let's say I wanted to send an email to Patty. We'll go through each of the TCP/IP layers to see this in action. Remember that packets are used to transmit data across networks, a packet consists of a header and payload. The header contains information about where the packet is going and where it came from. The payload is the actual data that is being transferred. As our packet traverses the network, each layer adds a bit of information to the header of the packet. Also keep in mind that different layers use a different term for our \"packet\". In the transport layer we essentially encapsulate our data in a segment and in the link layer we refer to this as a frame, but just know that packet can be used in regards to the same thing. First we start off in the application layer. When we send our email through our email client, the application layer will encapsulate this data. The application layer talks to the transport layer through a specified port and through this port it sends its data. We want to send an email through the application layer protocol SMTP (simple mail transfer protocol). The data is sent through our transport protocol which opens a connection to this port (port 25 is used for SMTP), so we get this data sent through this port and that data is sent to the Transport layer to be encapsulated into segments. Quiz Questions Click the right arrow to view the answers What layer is used to present the packet data in a user friendly format? Layer 7 - Application","title":"Application Layer"},{"location":"network-fundamentals/application-layer/#application-layer-layer-7","text":"Let's say I wanted to send an email to Patty. We'll go through each of the TCP/IP layers to see this in action. Remember that packets are used to transmit data across networks, a packet consists of a header and payload. The header contains information about where the packet is going and where it came from. The payload is the actual data that is being transferred. As our packet traverses the network, each layer adds a bit of information to the header of the packet. Also keep in mind that different layers use a different term for our \"packet\". In the transport layer we essentially encapsulate our data in a segment and in the link layer we refer to this as a frame, but just know that packet can be used in regards to the same thing. First we start off in the application layer. When we send our email through our email client, the application layer will encapsulate this data. The application layer talks to the transport layer through a specified port and through this port it sends its data. We want to send an email through the application layer protocol SMTP (simple mail transfer protocol). The data is sent through our transport protocol which opens a connection to this port (port 25 is used for SMTP), so we get this data sent through this port and that data is sent to the Transport layer to be encapsulated into segments.","title":"Application Layer (Layer 7)"},{"location":"network-fundamentals/application-layer/#quiz-questions","text":"Click the right arrow to view the answers What layer is used to present the packet data in a user friendly format? Layer 7 - Application","title":"Quiz Questions"},{"location":"network-fundamentals/dhcp-overview/","text":"DHCP Overview An important networking concept that we did not go over yet is DHCP (Dynamic Host Configuration Protocol) DHCP assigns IP addresses, subnet masks and gateways to our machines. For example, let's say you have a cell phone and you want to get a cell phone number to start talking to people. You have to call up your phone carrier and they will give you a number. As long as your pay your bills you can keep using your phone. DHCP is the phone carrier in this case, it gives you an IP address so that you can talk to other IP addresses. You are also leased an IP address, these last for a certain period of time, then will get renewed depending on how you have your lease settings. DHCP is great for many reasons, it allows a network administrator to not worry about assigning IP addresses and it also prevents them from setting up duplicate IP addresses. Every physical network should have its own DHCP server so that a host can request an IP address. In a regular home setting, the router usually acts as the DHCP server. The way DHCP gets all your dynamic host information is: DHCP DISCOVER - This message is broadcasted to search for a DHCP server. DHCP OFFER - The DHCP server in the network replies with an offer message. The offer contains a packet with DHCP lease time, subnet mask, IP address, etc. DHCP REQUEST - The client sends out another broadcast to let all DHCP servers know which offer it accepted. DHCP ACK - Acknowledgement is sent by the server. DHCP gets more involved than this, but this is the gist of it. Quiz Questions Click the right arrow to view the answers What are the steps in a DHCP request? DISCOVER, OFFER, REQUEST, ACK","title":"DHCP Overview"},{"location":"network-fundamentals/dhcp-overview/#dhcp-overview","text":"An important networking concept that we did not go over yet is DHCP (Dynamic Host Configuration Protocol) DHCP assigns IP addresses, subnet masks and gateways to our machines. For example, let's say you have a cell phone and you want to get a cell phone number to start talking to people. You have to call up your phone carrier and they will give you a number. As long as your pay your bills you can keep using your phone. DHCP is the phone carrier in this case, it gives you an IP address so that you can talk to other IP addresses. You are also leased an IP address, these last for a certain period of time, then will get renewed depending on how you have your lease settings. DHCP is great for many reasons, it allows a network administrator to not worry about assigning IP addresses and it also prevents them from setting up duplicate IP addresses. Every physical network should have its own DHCP server so that a host can request an IP address. In a regular home setting, the router usually acts as the DHCP server. The way DHCP gets all your dynamic host information is: DHCP DISCOVER - This message is broadcasted to search for a DHCP server. DHCP OFFER - The DHCP server in the network replies with an offer message. The offer contains a packet with DHCP lease time, subnet mask, IP address, etc. DHCP REQUEST - The client sends out another broadcast to let all DHCP servers know which offer it accepted. DHCP ACK - Acknowledgement is sent by the server. DHCP gets more involved than this, but this is the gist of it.","title":"DHCP Overview"},{"location":"network-fundamentals/dhcp-overview/#quiz-questions","text":"Click the right arrow to view the answers What are the steps in a DHCP request? DISCOVER, OFFER, REQUEST, ACK","title":"Quiz Questions"},{"location":"network-fundamentals/dns/","text":"DNS DNS is a distributed huge database which converts DNS names to IP addresses and vice versa. Why do we need loads of DNS servers? Risk problem of attackers attacking one server and prevent requests Scaling problem: Almost everone using DNS globally. This represents a massive and growing load on the system. A single server or a small group of servers can only get so big and it cannot scale properly. DNS is a huge database and current estimates of domain names are around 341 million. This is a huge database and it is distributed across the world. 340+ million domains like google.com, amazon.com etc and each one of those domains have many records >> and this is a huge data volume problem DNS Zone a database e.g. google.com containing records that zone is stored on a disk somewhere and it\u2019s called a Zonefile Nameservers (NS) - a DNS server which hosts 1 or more zones and stores 1 or more Zonefiles Authoritative - contains real/genuine records (boss of the domain) - single source of truth for the particular zone Non-authoritative/cached - copies of records/zones stored elsewhere to speed things up. For e.g. your local router or ISP might for instance be able to provide non-authoritative or cached answer for google.com or youtube.com because you visited the sites before. Only the nameservers of YT can give an authoritative answer DNS Architecture DNS Root : the boss. This zone is hoted on DNS nameservers. So the DNS root zone runs on the DNS root servers. It\u2019s the point that every DNS client knows about and trusts. It\u2019s where queries start and at the root of DNS. There are 13 root server IPs which host the root zone. These IPs are distributed geographically and the hardware is managed by independent orgs. The root zone is just a database and it\u2019s managed by the internet assigned numbers authority aka IANA Root zone only stores high level info on top level domains aka TLDs and no other details. 2 types of TLDs: generic TLD such as .com and country code specific such as .uk or .au. IANA delegate the management of these TLDs to other orgs known as registries. The job of the root zone is to just point at these TLD registries. So IANA delegate mgmt of .com TLD to Verisign. meaning Verisign is the .com registry. A summary is that: The Root zone is pointing at the nameservers hosting the TLD zones run by the registries which are the orgs who managed these TLDs. So Verisign will operate some nameservers hosting the .com TLD zone and the root zone will have records for the .com TLD which point at these .com NS. TLDs point at the nameservers which host the google.com and twitter.com zones. This 2nd level being pointed are known as authoritative nameservers These nameservers host the zone for a given domain for e.g. google.com . This means the server host the Zonefile which stores the data for that zone. At this 3rd level, the zone contains records within google.com. so www.google.com points at a set of IP addresses. Summary: The root zone knows which nameservers the .com zone is on, the .com zone knows which nameservers google.com is on. and the google.com zone contains records for the google.com domain and can answer queries. How DNS works What do we want from DNS? So in simple, we have a client and it wants to access google.com . and we need the IP address or addresses which we can connect to in order to access google. Somewhere in the world there is a DNS zone for google.com which has these and contains the records, which links www.google.com to 1 or more IPs .How do we find this zone That\u2019s what DNS does. It\u2019s the job of DNS which allows you to locate the specific DNS zone and get a query response from the authoritative zone which hosts the DNS records you need DNS is huge global distributed database containing lots of DNS records and the function of DNS is to allow you to locate the specific zone which can give you an authoritative answer. Example of a query within DNS: >> like the Google.com question Imagine we are querying www.google.com. First thing to check is the local DNS cache and hostsfile on the local machine. The hosts file is a static mapping of names to IPs and overrides DNS. Assuming the local client isn\u2019t aware of the DNS name, then next step: A resolver comes in here. A resolver is a type of DNS server often running on a home router or within an ISP and it will do the query on our behalf. So we send the query to the DNS resolve and it will query for you. The resolver also has a local cache which is used to speed up DNS queries. So if someone has queried google.com before, it might be able to return a non-authoritative answer aka local cached response. Assume now there is no cached entry for google.com, then the resolve queries the root zone via one of the root servers. Every DNS server will have these IPs hardcoded and this list is maintained by the OS vendor. The DNS root won\u2019t be able to answer us coz it isn\u2019t aware of google.com but it can help us get closer The root zone contains the records of a .com specifically nameserver records which point at the nameservers for the .com TLD and it returns .com NS So now the DNS resolver can now query one of the .com TLD NS for www.google.com . Assuming that the google.com domain has been registered, the .com zone will contain entries for google.com. Then the details of google.com NS are returned to the DNS resolver. The resolver can now move on: The DNS resolve now queries the google.com NS for www.google.com and because these NS are authoritative for this domains as they host the zone and zonefile for this domain and they\u2019re pointed at by the .com TLD zone, they can return an authoritative response back to the resolver. Now the DNS resolver caches the result in order to improve performance Now the DNS resolver caches the result in order to improve performance for future queries. And this DNS resolver returns the result to our local machine. This is how every DNS query works. Note: No one single Nameserver has all the answers, not even the root NS. But, every query gives you the next step and takes you closer to your query. The root gives you the .com NS, the .com NS gives you the netfli x.com NS, and the google.com NS can give you an authoritative answer This DNS process is also known as \u201cWalking the (\u201dDNS\u201d) tree\u201d This process is on a high level. A bit deeper Start with root zone when the DNS resolver is querying the root zone. The root zone doesn\u2019t have the info needed but it does know which NS handles .com NS so it can provide this. These NS are run by Verisign which manages the .com TLD. These NS host the .com zone file. We can now query the .com zone. We can\u2019t get answer directly from here but it does know which NS are authoritative for google.com . These are the network addresses of the servers which host the google.com zone and this is authoritative. This gives us what we need (they look like [ns-81.awsdns-10.com](http://ns-81.awsdns-10.com) , [ns-659.awsdns-18.net](http://ns-659.awsdns-18.net) etc The above are not IPs, they are another DNS name. This is a CNAME record. To get the IP address for this, you follow the same process again.","title":"DNS"},{"location":"network-fundamentals/dns/#dns","text":"DNS is a distributed huge database which converts DNS names to IP addresses and vice versa. Why do we need loads of DNS servers? Risk problem of attackers attacking one server and prevent requests Scaling problem: Almost everone using DNS globally. This represents a massive and growing load on the system. A single server or a small group of servers can only get so big and it cannot scale properly. DNS is a huge database and current estimates of domain names are around 341 million. This is a huge database and it is distributed across the world. 340+ million domains like google.com, amazon.com etc and each one of those domains have many records >> and this is a huge data volume problem DNS Zone a database e.g. google.com containing records that zone is stored on a disk somewhere and it\u2019s called a Zonefile Nameservers (NS) - a DNS server which hosts 1 or more zones and stores 1 or more Zonefiles Authoritative - contains real/genuine records (boss of the domain) - single source of truth for the particular zone Non-authoritative/cached - copies of records/zones stored elsewhere to speed things up. For e.g. your local router or ISP might for instance be able to provide non-authoritative or cached answer for google.com or youtube.com because you visited the sites before. Only the nameservers of YT can give an authoritative answer DNS Architecture DNS Root : the boss. This zone is hoted on DNS nameservers. So the DNS root zone runs on the DNS root servers. It\u2019s the point that every DNS client knows about and trusts. It\u2019s where queries start and at the root of DNS. There are 13 root server IPs which host the root zone. These IPs are distributed geographically and the hardware is managed by independent orgs. The root zone is just a database and it\u2019s managed by the internet assigned numbers authority aka IANA Root zone only stores high level info on top level domains aka TLDs and no other details. 2 types of TLDs: generic TLD such as .com and country code specific such as .uk or .au. IANA delegate the management of these TLDs to other orgs known as registries. The job of the root zone is to just point at these TLD registries. So IANA delegate mgmt of .com TLD to Verisign. meaning Verisign is the .com registry. A summary is that: The Root zone is pointing at the nameservers hosting the TLD zones run by the registries which are the orgs who managed these TLDs. So Verisign will operate some nameservers hosting the .com TLD zone and the root zone will have records for the .com TLD which point at these .com NS. TLDs point at the nameservers which host the google.com and twitter.com zones. This 2nd level being pointed are known as authoritative nameservers These nameservers host the zone for a given domain for e.g. google.com . This means the server host the Zonefile which stores the data for that zone. At this 3rd level, the zone contains records within google.com. so www.google.com points at a set of IP addresses. Summary: The root zone knows which nameservers the .com zone is on, the .com zone knows which nameservers google.com is on. and the google.com zone contains records for the google.com domain and can answer queries.","title":"DNS"},{"location":"network-fundamentals/dns/#how-dns-works","text":"What do we want from DNS? So in simple, we have a client and it wants to access google.com . and we need the IP address or addresses which we can connect to in order to access google. Somewhere in the world there is a DNS zone for google.com which has these and contains the records, which links www.google.com to 1 or more IPs .How do we find this zone That\u2019s what DNS does. It\u2019s the job of DNS which allows you to locate the specific DNS zone and get a query response from the authoritative zone which hosts the DNS records you need DNS is huge global distributed database containing lots of DNS records and the function of DNS is to allow you to locate the specific zone which can give you an authoritative answer. Example of a query within DNS: >> like the Google.com question Imagine we are querying www.google.com. First thing to check is the local DNS cache and hostsfile on the local machine. The hosts file is a static mapping of names to IPs and overrides DNS. Assuming the local client isn\u2019t aware of the DNS name, then next step: A resolver comes in here. A resolver is a type of DNS server often running on a home router or within an ISP and it will do the query on our behalf. So we send the query to the DNS resolve and it will query for you. The resolver also has a local cache which is used to speed up DNS queries. So if someone has queried google.com before, it might be able to return a non-authoritative answer aka local cached response. Assume now there is no cached entry for google.com, then the resolve queries the root zone via one of the root servers. Every DNS server will have these IPs hardcoded and this list is maintained by the OS vendor. The DNS root won\u2019t be able to answer us coz it isn\u2019t aware of google.com but it can help us get closer The root zone contains the records of a .com specifically nameserver records which point at the nameservers for the .com TLD and it returns .com NS So now the DNS resolver can now query one of the .com TLD NS for www.google.com . Assuming that the google.com domain has been registered, the .com zone will contain entries for google.com. Then the details of google.com NS are returned to the DNS resolver. The resolver can now move on: The DNS resolve now queries the google.com NS for www.google.com and because these NS are authoritative for this domains as they host the zone and zonefile for this domain and they\u2019re pointed at by the .com TLD zone, they can return an authoritative response back to the resolver. Now the DNS resolver caches the result in order to improve performance Now the DNS resolver caches the result in order to improve performance for future queries. And this DNS resolver returns the result to our local machine. This is how every DNS query works. Note: No one single Nameserver has all the answers, not even the root NS. But, every query gives you the next step and takes you closer to your query. The root gives you the .com NS, the .com NS gives you the netfli x.com NS, and the google.com NS can give you an authoritative answer This DNS process is also known as \u201cWalking the (\u201dDNS\u201d) tree\u201d This process is on a high level. A bit deeper Start with root zone when the DNS resolver is querying the root zone. The root zone doesn\u2019t have the info needed but it does know which NS handles .com NS so it can provide this. These NS are run by Verisign which manages the .com TLD. These NS host the .com zone file. We can now query the .com zone. We can\u2019t get answer directly from here but it does know which NS are authoritative for google.com . These are the network addresses of the servers which host the google.com zone and this is authoritative. This gives us what we need (they look like [ns-81.awsdns-10.com](http://ns-81.awsdns-10.com) , [ns-659.awsdns-18.net](http://ns-659.awsdns-18.net) etc The above are not IPs, they are another DNS name. This is a CNAME record. To get the IP address for this, you follow the same process again.","title":"How DNS works"},{"location":"network-fundamentals/http/","text":"HTTP Till this point we have only got the IP address of google.com. The HTML page of google.com is served by HTTP protocol which the browser renders. Browser sends a HTTP request to the IP of the server determined above. Request has a verb GET, PUT, POST followed by a path and query parameters and lines of key value pair which gives information about the client and capabilities of the client like contents it can accept and a body (usually in POST or PUT) # Eg run the following in your machine and have a look at the headers curl google.com -v \u276f curl google.com -v * Trying [ 2a00:1450:4009:815::200e ] :80... * Connected to google.com ( 2a00:1450:4009:815::200e ) port 80 ( #0) > GET / HTTP/1.1 > Host: google.com > User-Agent: curl/8.1.2 > Accept: */* > < HTTP/1.1 301 Moved Permanently < Location: http://www.google.com/ < Content-Type: text/html ; charset = UTF-8 < Content-Security-Policy-Report-Only: object-src 'none' ; base-uri 'self' ; script-src 'nonce-FTv-58qMVTd49N-ysFjcQA' 'strict-dynamic' 'report-sample' 'unsafe-eval' 'unsafe-inline' https: http: ; report-uri https://csp.withgoogle.com/csp/gws/other-hp < Date: Mon, 04 Dec 2023 19 :36:43 GMT < Expires: Wed, 03 Jan 2024 19 :36:43 GMT < Cache-Control: public, max-age = 2592000 < Server: gws < Content-Length: 219 < X-XSS-Protection: 0 < X-Frame-Options: SAMEORIGIN < <HTML><HEAD><meta http-equiv = \"content-type\" content = \"text/html;charset=utf-8\" > <TITLE>301 Moved</TITLE></HEAD><BODY> <H1>301 Moved</H1> The document has moved <A HREF = \"http://www.google.com/\" >here</A>. </BODY></HTML> * Connection #0 to host google.com left intact Here, in the first line GET is the verb, / is the path and 1.1 is the HTTP protocol version. Then there are key value pairs which give client capabilities and some details to the server. The server responds back with HTTP version, Status Code & Status Message. Status codes 2xx means success, 3xx denotes redirection, 4xx denotes client side errors and 5xx server side errors. We will now jump in to see the difference between HTTP/1.0 and HTTP/1.1. #On the terminal type telnet www.google.com 80 #Copy and paste the following with an empty new line by pressing enter at last in the telnet STDIN GET / HTTP/1.1 HOST:google.com USER-AGENT: curl # then press enter ---- Output: \u276f telnet www.google.com 80 Trying 2a00:1450:4009:820::2004... Connected to www.google.com. Escape character is '^]' . GET / HTTP/1.1 HOST:google.com USER-AGENT: curl HTTP/1.1 301 Moved Permanently Location: http://www.google.com/ Content-Type: text/html ; charset = UTF-8 Content-Security-Policy-Report-Only: object-src 'none' ; base-uri 'self' ; script-src 'nonce-T1jINmYahlhXaA-iSQDRMw' 'strict-dynamic' 'report-sample' 'unsafe-eval' 'unsafe-inline' https: http: ; report-uri https://csp.withgoogle.com/csp/gws/other-hp Date: Mon, 04 Dec 2023 19 :40:14 GMT Expires: Wed, 03 Jan 2024 19 :40:14 GMT Cache-Control: public, max-age = 2592000 Server: gws Content-Length: 219 X-XSS-Protection: 0 X-Frame-Options: SAMEORIGIN <HTML><HEAD><meta http-equiv = \"content-type\" content = \"text/html;charset=utf-8\" > <TITLE>301 Moved</TITLE></HEAD><BODY> <H1>301 Moved</H1> The document has moved <A HREF = \"http://www.google.com/\" >here</A>. </BODY></HTML> This would get server response and waits for next input as the underlying connection to www.google.com can be reused for further queries. While going through TCP, we can understand the benefits of this. But in HTTP/1.0 this connection will be immediately closed after the response meaning new connection has to be opened for each query. HTTP/1.1 can have only one inflight request in an open connection but connection can be reused for multiple requests one after another. One of the benefits of HTTP/2.0 over HTTP/1.1 is we can have multiple inflight requests on the same connection. We are restricting our scope to generic HTTP and not jumping to the intricacies of each protocol version but they should be straight forward to understand post the course. HTTP is called stateless protocol . This section we will try to understand what stateless means. Say we logged in to google.com, each request to google.com from the client will have no context of the user and it makes no sense to prompt user to login for each page/resource. This problem of HTTP is solved by COOKIE . A user is created a session when a user logs in. This session identifier is sent to the browser via SET-COOKIE header. The browser stores the COOKIE till the expiry set by the server and sends the cookie for each request from hereon for google.com. More details on cookies are available here . Cookies are a critical piece of information like password and since HTTP is a plain text protocol, any man in the middle can capture either password or cookies and can breach the privacy of the user. Similarly as discussed during DNS a spoofed IP of google.com can cause a phishing attack on users where an user can give google\u2019s password to login on the malicious site. To solve both problems HTTPs came in place and HTTPs has to be mandated. HTTPS has to provide server identification and encryption of data between client and server. The server administrator has to generate a private public key pair and certificate request. This certificate request has to be signed by a certificate authority which converts the certificate request to a certificate. The server administrator has to update the certificate and private key to the webserver. The certificate has details about the server (like domain name for which it serves, expiry date), public key of the server. The private key is a secret to the server and losing the private key loses the trust the server provides. When clients connect, the client sends a HELLO. The server sends its certificate to the client. The client checks the validity of the cert by seeing if it is within its expiry time, if it is signed by a trusted authority and the hostname in the cert is the same as the server. This validation makes sure the server is the right server and there is no phishing. Once that is validated, the client negotiates a symmetrical key and cipher with the server by encrypting the negotiation with the public key of the server. Nobody else other than the server who has the private key can understand this data. Once negotiation is complete, that symmetric key and algorithm is used for further encryption which can be decrypted only by client and server from thereon as they only know the symmetric key and algorithm. The switch to symmetric algorithm from asymmetric encryption algorithm is to not strain the resources of client devices as symmetric encryption is generally less resource intensive than asymmetric. #Try the following on your terminal to see the cert details like Subject Name(domain name), Issuer details, Expiry date curl https://www.google.com -v * Trying [ 2a00:1450:4009:820::2004 ] :443... * Connected to www.google.com ( 2a00:1450:4009:820::2004 ) port 443 ( #0) * ALPN: offers h2,http/1.1 * ( 304 ) ( OUT ) , TLS handshake, Client hello ( 1 ) : * CAfile: /etc/ssl/cert.pem * CApath: none * ( 304 ) ( IN ) , TLS handshake, Server hello ( 2 ) : * ( 304 ) ( IN ) , TLS handshake, Unknown ( 8 ) : * ( 304 ) ( IN ) , TLS handshake, Certificate ( 11 ) : * ( 304 ) ( IN ) , TLS handshake, CERT verify ( 15 ) : * ( 304 ) ( IN ) , TLS handshake, Finished ( 20 ) : * ( 304 ) ( OUT ) , TLS handshake, Finished ( 20 ) : * SSL connection using TLSv1.3 / AEAD-CHACHA20-POLY1305-SHA256 * ALPN: server accepted h2 * Server certificate: * subject: CN = www.google.com * start date: Oct 23 11 :24:57 2023 GMT * expire date: Jan 15 11 :24:56 2024 GMT * subjectAltName: host \"www.google.com\" matched cert 's \"www.google.com\" * issuer: C=US; O=Google Trust Services LLC; CN=GTS CA 1C3 * SSL certificate verify ok. * using HTTP/2 * h2 [:method: GET] * h2 [:scheme: https] * h2 [:authority: www.google.com] * h2 [:path: /] * h2 [user-agent: curl/8.1.2] * h2 [accept: */*] * Using Stream ID: 1 (easy handle 0x141812e00) > GET / HTTP/2 > Host: www.google.com > User-Agent: curl/8.1.2 > Accept: */* > < HTTP/2 200 < date: Mon, 04 Dec 2023 19:42:48 GMT < expires: -1 < cache-control: private, max-age=0 < content-type: text/html; charset=ISO-8859-1 < content-security-policy-report-only: object-src ' none ';base-uri ' self ';script-src ' nonce-_C5r_wmr6-1XyYckXKee2A ' ' strict-dynamic ' ' report-sample ' ' unsafe-eval ' ' unsafe-inline ' https: http: ; report-uri https://csp.withgoogle.com/csp/gws/other-hp < p3p: CP = \"This is not a P3P policy! See g.co/p3phelp for more info.\" < server: gws < x-xss-protection: 0 < x-frame-options: SAMEORIGIN < set-cookie: SOCS = CAAaBgiArbSrBg ; expires = Thu, 02 -Jan-2025 19 :42:48 GMT ; path = / ; domain = .google.com ; Secure ; SameSite = lax < set-cookie: AEC = Ackid1RiFR-Q29PANCR-68dY5VmhSq-zMoXpMnL-oZtSAvcXXhfTlSCd2lk ; expires = Sat, 01 -Jun-2024 19 :42:48 GMT ; path = / ; domain = .google.com ; Secure ; HttpOnly ; SameSite = lax < set-cookie: __Secure-ENID = 16 .SE = AMen4HvAgOZLjmCBwEqVt59PxlCr5qh_7lodjFuSo67JBEjjIff9YK9rvet25lsW-E_Vh-ZJurnQQYpzrkBQHCM31JAiZNEp6cILxzPo1u8WmODpg2THMMMjFxBzhLTdih7zgUQbGlg_xZxIwK6S0ypWsQxFnTGsVShkcCoRD58 ; expires = Fri, 03 -Jan-2025 12 :01:06 GMT ; path = / ; domain = .google.com ; Secure ; HttpOnly ; SameSite = lax < set-cookie: CONSENT = PENDING+497 ; expires = Wed, 03 -Dec-2025 19 :42:48 GMT ; path = / ; domain = .google.com ; Secure < alt-svc: h3 = \":443\" ; ma = 2592000 ,h3-29 = \":443\" ; ma = 2592000 < accept-ranges: none < vary: Accept-Encoding Here my system has a list of certificate authorities it trusts in this file /etc/ssl/cert.pem. Curl validates the certificate is for www.google.com by seeing the CN section of the subject part of the certificate. It also makes sure the certificate is not expired by seeing the expire date. It also validates the signature on the certificate by using the public key of issuer Digicert in /etc/ssl/cert.pem. Once this is done, using the public key of www.google.com it negotiates cipher TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 with a symmetric key. Subsequent data transfer including first HTTP request uses the same cipher and symmetric key.","title":"HTTP"},{"location":"network-fundamentals/http/#http","text":"Till this point we have only got the IP address of google.com. The HTML page of google.com is served by HTTP protocol which the browser renders. Browser sends a HTTP request to the IP of the server determined above. Request has a verb GET, PUT, POST followed by a path and query parameters and lines of key value pair which gives information about the client and capabilities of the client like contents it can accept and a body (usually in POST or PUT) # Eg run the following in your machine and have a look at the headers curl google.com -v \u276f curl google.com -v * Trying [ 2a00:1450:4009:815::200e ] :80... * Connected to google.com ( 2a00:1450:4009:815::200e ) port 80 ( #0) > GET / HTTP/1.1 > Host: google.com > User-Agent: curl/8.1.2 > Accept: */* > < HTTP/1.1 301 Moved Permanently < Location: http://www.google.com/ < Content-Type: text/html ; charset = UTF-8 < Content-Security-Policy-Report-Only: object-src 'none' ; base-uri 'self' ; script-src 'nonce-FTv-58qMVTd49N-ysFjcQA' 'strict-dynamic' 'report-sample' 'unsafe-eval' 'unsafe-inline' https: http: ; report-uri https://csp.withgoogle.com/csp/gws/other-hp < Date: Mon, 04 Dec 2023 19 :36:43 GMT < Expires: Wed, 03 Jan 2024 19 :36:43 GMT < Cache-Control: public, max-age = 2592000 < Server: gws < Content-Length: 219 < X-XSS-Protection: 0 < X-Frame-Options: SAMEORIGIN < <HTML><HEAD><meta http-equiv = \"content-type\" content = \"text/html;charset=utf-8\" > <TITLE>301 Moved</TITLE></HEAD><BODY> <H1>301 Moved</H1> The document has moved <A HREF = \"http://www.google.com/\" >here</A>. </BODY></HTML> * Connection #0 to host google.com left intact Here, in the first line GET is the verb, / is the path and 1.1 is the HTTP protocol version. Then there are key value pairs which give client capabilities and some details to the server. The server responds back with HTTP version, Status Code & Status Message. Status codes 2xx means success, 3xx denotes redirection, 4xx denotes client side errors and 5xx server side errors. We will now jump in to see the difference between HTTP/1.0 and HTTP/1.1. #On the terminal type telnet www.google.com 80 #Copy and paste the following with an empty new line by pressing enter at last in the telnet STDIN GET / HTTP/1.1 HOST:google.com USER-AGENT: curl # then press enter ---- Output: \u276f telnet www.google.com 80 Trying 2a00:1450:4009:820::2004... Connected to www.google.com. Escape character is '^]' . GET / HTTP/1.1 HOST:google.com USER-AGENT: curl HTTP/1.1 301 Moved Permanently Location: http://www.google.com/ Content-Type: text/html ; charset = UTF-8 Content-Security-Policy-Report-Only: object-src 'none' ; base-uri 'self' ; script-src 'nonce-T1jINmYahlhXaA-iSQDRMw' 'strict-dynamic' 'report-sample' 'unsafe-eval' 'unsafe-inline' https: http: ; report-uri https://csp.withgoogle.com/csp/gws/other-hp Date: Mon, 04 Dec 2023 19 :40:14 GMT Expires: Wed, 03 Jan 2024 19 :40:14 GMT Cache-Control: public, max-age = 2592000 Server: gws Content-Length: 219 X-XSS-Protection: 0 X-Frame-Options: SAMEORIGIN <HTML><HEAD><meta http-equiv = \"content-type\" content = \"text/html;charset=utf-8\" > <TITLE>301 Moved</TITLE></HEAD><BODY> <H1>301 Moved</H1> The document has moved <A HREF = \"http://www.google.com/\" >here</A>. </BODY></HTML> This would get server response and waits for next input as the underlying connection to www.google.com can be reused for further queries. While going through TCP, we can understand the benefits of this. But in HTTP/1.0 this connection will be immediately closed after the response meaning new connection has to be opened for each query. HTTP/1.1 can have only one inflight request in an open connection but connection can be reused for multiple requests one after another. One of the benefits of HTTP/2.0 over HTTP/1.1 is we can have multiple inflight requests on the same connection. We are restricting our scope to generic HTTP and not jumping to the intricacies of each protocol version but they should be straight forward to understand post the course. HTTP is called stateless protocol . This section we will try to understand what stateless means. Say we logged in to google.com, each request to google.com from the client will have no context of the user and it makes no sense to prompt user to login for each page/resource. This problem of HTTP is solved by COOKIE . A user is created a session when a user logs in. This session identifier is sent to the browser via SET-COOKIE header. The browser stores the COOKIE till the expiry set by the server and sends the cookie for each request from hereon for google.com. More details on cookies are available here . Cookies are a critical piece of information like password and since HTTP is a plain text protocol, any man in the middle can capture either password or cookies and can breach the privacy of the user. Similarly as discussed during DNS a spoofed IP of google.com can cause a phishing attack on users where an user can give google\u2019s password to login on the malicious site. To solve both problems HTTPs came in place and HTTPs has to be mandated. HTTPS has to provide server identification and encryption of data between client and server. The server administrator has to generate a private public key pair and certificate request. This certificate request has to be signed by a certificate authority which converts the certificate request to a certificate. The server administrator has to update the certificate and private key to the webserver. The certificate has details about the server (like domain name for which it serves, expiry date), public key of the server. The private key is a secret to the server and losing the private key loses the trust the server provides. When clients connect, the client sends a HELLO. The server sends its certificate to the client. The client checks the validity of the cert by seeing if it is within its expiry time, if it is signed by a trusted authority and the hostname in the cert is the same as the server. This validation makes sure the server is the right server and there is no phishing. Once that is validated, the client negotiates a symmetrical key and cipher with the server by encrypting the negotiation with the public key of the server. Nobody else other than the server who has the private key can understand this data. Once negotiation is complete, that symmetric key and algorithm is used for further encryption which can be decrypted only by client and server from thereon as they only know the symmetric key and algorithm. The switch to symmetric algorithm from asymmetric encryption algorithm is to not strain the resources of client devices as symmetric encryption is generally less resource intensive than asymmetric. #Try the following on your terminal to see the cert details like Subject Name(domain name), Issuer details, Expiry date curl https://www.google.com -v * Trying [ 2a00:1450:4009:820::2004 ] :443... * Connected to www.google.com ( 2a00:1450:4009:820::2004 ) port 443 ( #0) * ALPN: offers h2,http/1.1 * ( 304 ) ( OUT ) , TLS handshake, Client hello ( 1 ) : * CAfile: /etc/ssl/cert.pem * CApath: none * ( 304 ) ( IN ) , TLS handshake, Server hello ( 2 ) : * ( 304 ) ( IN ) , TLS handshake, Unknown ( 8 ) : * ( 304 ) ( IN ) , TLS handshake, Certificate ( 11 ) : * ( 304 ) ( IN ) , TLS handshake, CERT verify ( 15 ) : * ( 304 ) ( IN ) , TLS handshake, Finished ( 20 ) : * ( 304 ) ( OUT ) , TLS handshake, Finished ( 20 ) : * SSL connection using TLSv1.3 / AEAD-CHACHA20-POLY1305-SHA256 * ALPN: server accepted h2 * Server certificate: * subject: CN = www.google.com * start date: Oct 23 11 :24:57 2023 GMT * expire date: Jan 15 11 :24:56 2024 GMT * subjectAltName: host \"www.google.com\" matched cert 's \"www.google.com\" * issuer: C=US; O=Google Trust Services LLC; CN=GTS CA 1C3 * SSL certificate verify ok. * using HTTP/2 * h2 [:method: GET] * h2 [:scheme: https] * h2 [:authority: www.google.com] * h2 [:path: /] * h2 [user-agent: curl/8.1.2] * h2 [accept: */*] * Using Stream ID: 1 (easy handle 0x141812e00) > GET / HTTP/2 > Host: www.google.com > User-Agent: curl/8.1.2 > Accept: */* > < HTTP/2 200 < date: Mon, 04 Dec 2023 19:42:48 GMT < expires: -1 < cache-control: private, max-age=0 < content-type: text/html; charset=ISO-8859-1 < content-security-policy-report-only: object-src ' none ';base-uri ' self ';script-src ' nonce-_C5r_wmr6-1XyYckXKee2A ' ' strict-dynamic ' ' report-sample ' ' unsafe-eval ' ' unsafe-inline ' https: http: ; report-uri https://csp.withgoogle.com/csp/gws/other-hp < p3p: CP = \"This is not a P3P policy! See g.co/p3phelp for more info.\" < server: gws < x-xss-protection: 0 < x-frame-options: SAMEORIGIN < set-cookie: SOCS = CAAaBgiArbSrBg ; expires = Thu, 02 -Jan-2025 19 :42:48 GMT ; path = / ; domain = .google.com ; Secure ; SameSite = lax < set-cookie: AEC = Ackid1RiFR-Q29PANCR-68dY5VmhSq-zMoXpMnL-oZtSAvcXXhfTlSCd2lk ; expires = Sat, 01 -Jun-2024 19 :42:48 GMT ; path = / ; domain = .google.com ; Secure ; HttpOnly ; SameSite = lax < set-cookie: __Secure-ENID = 16 .SE = AMen4HvAgOZLjmCBwEqVt59PxlCr5qh_7lodjFuSo67JBEjjIff9YK9rvet25lsW-E_Vh-ZJurnQQYpzrkBQHCM31JAiZNEp6cILxzPo1u8WmODpg2THMMMjFxBzhLTdih7zgUQbGlg_xZxIwK6S0ypWsQxFnTGsVShkcCoRD58 ; expires = Fri, 03 -Jan-2025 12 :01:06 GMT ; path = / ; domain = .google.com ; Secure ; HttpOnly ; SameSite = lax < set-cookie: CONSENT = PENDING+497 ; expires = Wed, 03 -Dec-2025 19 :42:48 GMT ; path = / ; domain = .google.com ; Secure < alt-svc: h3 = \":443\" ; ma = 2592000 ,h3-29 = \":443\" ; ma = 2592000 < accept-ranges: none < vary: Accept-Encoding Here my system has a list of certificate authorities it trusts in this file /etc/ssl/cert.pem. Curl validates the certificate is for www.google.com by seeing the CN section of the subject part of the certificate. It also makes sure the certificate is not expired by seeing the expire date. It also validates the signature on the certificate by using the public key of issuer Digicert in /etc/ssl/cert.pem. Once this is done, using the public key of www.google.com it negotiates cipher TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 with a symmetric key. Subsequent data transfer including first HTTP request uses the same cipher and symmetric key.","title":"HTTP"},{"location":"network-fundamentals/link-layer/","text":"Link Layer (Layer 2) At the bottom of the TCP/IP model sits the Link Layer. This layer is the hardware specific layer. In the link layer, our packet is encapsulated once more into something called a frame. The frame header attaches the source and destination MAC addresses of our hosts, checksums and packet separators so that the receiver can tell when a packet ends. Fortunately we are on the same network, so our packet won't have to travel too far. First, the link layer attaches my source MAC address to the frame header, but it needs to know Abz's MAC address as well. How does it know that and how do I find it since it's not on the Internet? We use ARP! ARP (Address Resolution Protocol) ARP finds the MAC address associated with an IP address. ARP is used within the same network. If Abz was not on the same network, we would use a routing system to determine the next router that would receive the packet and once we were on the same network, we could use ARP. Once we are on the same network, systems first use the ARP look-up table that stores information about what IP addresses are associated with what MAC address. If the value is not there, then ARP is used. Then the system will send a broadcast message to the network using the ARP protocol to find out which host has IP 10.10.1.4. A broadcast message is a special message that is sent to all hosts on a network (aptly named for sending a broadcast). Any machine with the requested IP address will reply with an ARP packet containing the IP address and the MAC address. Now that we have all the necessary data we need, IP address and MAC addresses, our link layer forwards this frame through our network interface card, out to the next device and finds Abz's network. This step is a little more complex than how I just explained it, but we will discuss more details in the Routing course. And there it is a simple (or not so simple) packet traversal down the TCP/IP layer. Keep in mind that packets don't travel in a one way fashion like this. We haven't even gotten to Abz's network yet! When travelling through networks, it requires going through the TCP/IP model at least twice before any data is sent or received. In reality, the way this packet looks would be something like this: Packet Traversal mo sends Abz an email: this data gets sent to the transport layer. The transport layer encapsulates the data into a TCP or UDP header to form a segment, the segment attaches the destination and source TCP or UDP port, then the segment is sent to the network layer. The network layer encapsulates the TCP segment inside an IP packet, it attaches the source and destination IP address. Then routes the packet to the link layer. The packet then reaches mo's physical hardware and gets encapsulated in a frame. The source and destination MAC address get added to the frame. Abz's receives this data frame through her physical layer and checks each frame for data integrity, then de-encapsulates the frame contents and sends the IP packet to the network layer. The network layer reads the packet to find the source and destination IP that was previously attached. It checks if its IP is the same as the destination IP, which it is! It de-encapsulates the packet and sends the segment to the transport layer. The transport layer de-encapsulates the segments, checks the TCP or UDP port numbers and makes a connection to the application layer based on those port numbers. The application layer receives the data from the transport layer on the port that was specified and presents it to Abz in the form of the final email message Quiz Questions Click the right arrow to view the answers What is used to find the MAC address on the same network? ARP","title":"Link Layer"},{"location":"network-fundamentals/link-layer/#link-layer-layer-2","text":"At the bottom of the TCP/IP model sits the Link Layer. This layer is the hardware specific layer. In the link layer, our packet is encapsulated once more into something called a frame. The frame header attaches the source and destination MAC addresses of our hosts, checksums and packet separators so that the receiver can tell when a packet ends. Fortunately we are on the same network, so our packet won't have to travel too far. First, the link layer attaches my source MAC address to the frame header, but it needs to know Abz's MAC address as well. How does it know that and how do I find it since it's not on the Internet? We use ARP! ARP (Address Resolution Protocol) ARP finds the MAC address associated with an IP address. ARP is used within the same network. If Abz was not on the same network, we would use a routing system to determine the next router that would receive the packet and once we were on the same network, we could use ARP. Once we are on the same network, systems first use the ARP look-up table that stores information about what IP addresses are associated with what MAC address. If the value is not there, then ARP is used. Then the system will send a broadcast message to the network using the ARP protocol to find out which host has IP 10.10.1.4. A broadcast message is a special message that is sent to all hosts on a network (aptly named for sending a broadcast). Any machine with the requested IP address will reply with an ARP packet containing the IP address and the MAC address. Now that we have all the necessary data we need, IP address and MAC addresses, our link layer forwards this frame through our network interface card, out to the next device and finds Abz's network. This step is a little more complex than how I just explained it, but we will discuss more details in the Routing course. And there it is a simple (or not so simple) packet traversal down the TCP/IP layer. Keep in mind that packets don't travel in a one way fashion like this. We haven't even gotten to Abz's network yet! When travelling through networks, it requires going through the TCP/IP model at least twice before any data is sent or received. In reality, the way this packet looks would be something like this: Packet Traversal mo sends Abz an email: this data gets sent to the transport layer. The transport layer encapsulates the data into a TCP or UDP header to form a segment, the segment attaches the destination and source TCP or UDP port, then the segment is sent to the network layer. The network layer encapsulates the TCP segment inside an IP packet, it attaches the source and destination IP address. Then routes the packet to the link layer. The packet then reaches mo's physical hardware and gets encapsulated in a frame. The source and destination MAC address get added to the frame. Abz's receives this data frame through her physical layer and checks each frame for data integrity, then de-encapsulates the frame contents and sends the IP packet to the network layer. The network layer reads the packet to find the source and destination IP that was previously attached. It checks if its IP is the same as the destination IP, which it is! It de-encapsulates the packet and sends the segment to the transport layer. The transport layer de-encapsulates the segments, checks the TCP or UDP port numbers and makes a connection to the application layer based on those port numbers. The application layer receives the data from the transport layer on the port that was specified and presents it to Abz in the form of the final email message","title":"Link Layer (Layer 2)"},{"location":"network-fundamentals/link-layer/#quiz-questions","text":"Click the right arrow to view the answers What is used to find the MAC address on the same network? ARP","title":"Quiz Questions"},{"location":"network-fundamentals/network-addressing/","text":"Network Addressing Before we jump into seeing how a packet moves across a network, we have to familiarize ourselves with some terminology. When you mail a letter, you must know who it is being sent to and where it is coming from. Packets need the same information, our hosts and other hosts are identified using MAC (media access control) addresses and IP addresses, to make it easier on us humans we use hostnames to identify a host. MAC Addresses A MAC address is a unique identifier used as a hardware address. This address will never change. When you want to get access to the Internet, your machine needs to have a device called a network interface card. This network adapter has its own hardware address that's used to identify your machine. A MAC address for an Ethernet device looks something like this 00:C4:B5:45:B2:43. MAC addresses are given to network adapters when they are manufactured. Each manufacturer has an organizationally unique identifier (OUI) to identify them as the manufacturer. This OUI is denoted by the first 3 bytes of the MAC address. For example, Dell has 00-14-22, so a network adapter from Dell could have a MAC address like: 00-14-22-34-B2-C2. IP Addresses An IP Address is used to identify a device on a network, they are hardware independent and can vary in syntax depending on if you are using IPv4 or IPv6 (more on this later). For now we'll assume you are using IPv4, so a typical IP address would look like: 10.24.12.4. IP addresses are used with the software side of networking. Anytime a system is connected to the Internet it should have an IP address. They can also change if your network changes and are unique to the entire Internet (this isn't always the case once we learn about NAT). Remember it takes both software and hardware to move packets across networks, so we have two identifiers for each, MAC (hardware) and IP (software). Hostnames One last way to identify your machines is through hostname. Hostnames take your IP address and allow you to tie that address to a human readable name. Instead of remembering 192.12.41.4 you can just remember myhost.com. Quiz Questions Click the right arrow to view the answers How many bytes are in an IPv4 address? 4 How many bytes are in an IPv6 address? 16","title":"Network Addressing"},{"location":"network-fundamentals/network-addressing/#network-addressing","text":"Before we jump into seeing how a packet moves across a network, we have to familiarize ourselves with some terminology. When you mail a letter, you must know who it is being sent to and where it is coming from. Packets need the same information, our hosts and other hosts are identified using MAC (media access control) addresses and IP addresses, to make it easier on us humans we use hostnames to identify a host. MAC Addresses A MAC address is a unique identifier used as a hardware address. This address will never change. When you want to get access to the Internet, your machine needs to have a device called a network interface card. This network adapter has its own hardware address that's used to identify your machine. A MAC address for an Ethernet device looks something like this 00:C4:B5:45:B2:43. MAC addresses are given to network adapters when they are manufactured. Each manufacturer has an organizationally unique identifier (OUI) to identify them as the manufacturer. This OUI is denoted by the first 3 bytes of the MAC address. For example, Dell has 00-14-22, so a network adapter from Dell could have a MAC address like: 00-14-22-34-B2-C2. IP Addresses An IP Address is used to identify a device on a network, they are hardware independent and can vary in syntax depending on if you are using IPv4 or IPv6 (more on this later). For now we'll assume you are using IPv4, so a typical IP address would look like: 10.24.12.4. IP addresses are used with the software side of networking. Anytime a system is connected to the Internet it should have an IP address. They can also change if your network changes and are unique to the entire Internet (this isn't always the case once we learn about NAT). Remember it takes both software and hardware to move packets across networks, so we have two identifiers for each, MAC (hardware) and IP (software). Hostnames One last way to identify your machines is through hostname. Hostnames take your IP address and allow you to tie that address to a human readable name. Instead of remembering 192.12.41.4 you can just remember myhost.com.","title":"Network Addressing"},{"location":"network-fundamentals/network-addressing/#quiz-questions","text":"Click the right arrow to view the answers How many bytes are in an IPv4 address? 4 How many bytes are in an IPv6 address? 16","title":"Quiz Questions"},{"location":"network-fundamentals/network-basics/","text":"Network Basics Let's look at a typical home network, you have a few different components. ISP - Your internet service provider, the company you pay to get Internet at your house. Router - The router allows each machine on your network to connect to the Internet. In most modern routers, you can connect via wireless or an Ethernet cable. WAN - Wide Area Network, this is what we call the network that encompasses everything between your router and a wider network such the Internet. WLAN - Wireless Local Area Network, this is the network between your router and any wireless devices you may have such as laptops. LAN - Local Area Network, this is the network between your router and any wired devices such as Desktop PCs. Hosts - Each machine on a network is known as a host. The data and information that gets transmitted through networks are known as packets and by the end of the Networking Nomad section, you'll understand in detail how a packet travels to and from hosts. Quiz Questions Click the right arrow to view the answers What is the local area network known as? LAN","title":"Network Basics"},{"location":"network-fundamentals/network-basics/#network-basics","text":"Let's look at a typical home network, you have a few different components. ISP - Your internet service provider, the company you pay to get Internet at your house. Router - The router allows each machine on your network to connect to the Internet. In most modern routers, you can connect via wireless or an Ethernet cable. WAN - Wide Area Network, this is what we call the network that encompasses everything between your router and a wider network such the Internet. WLAN - Wireless Local Area Network, this is the network between your router and any wireless devices you may have such as laptops. LAN - Local Area Network, this is the network between your router and any wired devices such as Desktop PCs. Hosts - Each machine on a network is known as a host. The data and information that gets transmitted through networks are known as packets and by the end of the Networking Nomad section, you'll understand in detail how a packet travels to and from hosts.","title":"Network Basics"},{"location":"network-fundamentals/network-basics/#quiz-questions","text":"Click the right arrow to view the answers What is the local area network known as? LAN","title":"Quiz Questions"},{"location":"network-fundamentals/network-layer/","text":"Network Layer The Network layer determines the routing of our packets from our source host to a destination host. Fortunately in our example, our packet is only traveling within the same network, but the Internet is made up of many networks. These smaller networks that make up the Internet are known as subnets. All subnets connect to each other in some way, which is why we are able to get to www.google.com even though it's on its own network. I won't go into detail as we have a whole course dedicated to subnets, but for now in regards to our Network layer, know that the IP addresses define the rules to travel to different subnets. In the network layer, it receives the segment coming from the transport layer and encapsulates this segment in an IP packet then attaches the IP address of the source host and the IP address of the destination host to the packet header. So at this point, our packet has information about where it is going and where it came from. Now it sends our packet to the physical hardware layer. Quiz Questions Click the right arrow to view the answers What are smaller networks that make up the Internet called? subnets","title":"Network layer"},{"location":"network-fundamentals/network-layer/#network-layer","text":"The Network layer determines the routing of our packets from our source host to a destination host. Fortunately in our example, our packet is only traveling within the same network, but the Internet is made up of many networks. These smaller networks that make up the Internet are known as subnets. All subnets connect to each other in some way, which is why we are able to get to www.google.com even though it's on its own network. I won't go into detail as we have a whole course dedicated to subnets, but for now in regards to our Network layer, know that the IP addresses define the rules to travel to different subnets. In the network layer, it receives the segment coming from the transport layer and encapsulates this segment in an IP packet then attaches the IP address of the source host and the IP address of the destination host to the packet header. So at this point, our packet has information about where it is going and where it came from. Now it sends our packet to the physical hardware layer.","title":"Network Layer"},{"location":"network-fundamentals/network-layer/#quiz-questions","text":"Click the right arrow to view the answers What are smaller networks that make up the Internet called? subnets","title":"Quiz Questions"},{"location":"network-fundamentals/osi-detailed/","text":"OSI Layer 1 - Physical Layer 1 specifications define the transmission and reception of raw BIT STREAMS between a device and a shared physical medium. Physical medium can be copper (electrical signals), fibre (light), wifi (radio frequencies or waves) Like a physical hub used to connect multiple devices together No device addressing, all data is processed by all devices. It's liek shouting in a room without saying any names and everyone hears it. This is a limitation and it's solved by layer 2. No media access control Layer 2 - Data Link Runs over layer 1 and it requires a functional layer 1 to operate Higher layers build on lower layers Frames are a format used in layer 2 to send information over a layer 2 network Layer 2 also introduces a new unique hardware address aka a MAC address. This address is uniquely assigned to a specific hardware. MAC address is formed of 2 parts: OUI (Organizationally Unique Identifier) - first 3 bytes of the MAC address (assigned to companies who manufacture network devices) NIC (Network Interface Controller) - last 3 bytes of the MAC address Layer 2 uses layer 1: This means that a layer 2 or ethernet frame can be transmitted onto the shared physical medium by layer 1. These are converted to voltages, RF or light Layer 2 provides frames & Layer 1 handles the physical transmission and reception onto and from the physical medium So when layer 1 is transmitting a frame onto the physical medium, layer 1 doesn't understand the frame. Layer 1 simply transmits raw data onto the physical medium. Layer 2 has different parts: Preamble bits & start frame delimiter (the function of this is to allow devices to know that it's the start of a frame) Next is the destination and source MAC address. All devices on a layer 2 network have a unique MAC address And a frame can be sent to a specific device by putting its MAC address destination. Or you can put all Fs if you want to send the frame to every device on the local network. This is called a broadcast. Next is Ethertype which is a layer 3 protocol. Layer 3 uses layer 2 frames for device to device communication on a local network. So when recieving a frame at the other side, you need to know which layer 3 protocol originally put data into that frame. A common example is IP or Internet Protocol. And this is what the ethertype field is for. It tells the receiving device which layer 3 protocol put data into the frame. These 3 fields (Dest MAC address, Source MAC address, Ethertype) are called the MAC header of the frame. After the header, it's the payload. It contains the data that the frame is sending. The data is generally provided by the layer 3 protocol. This process is called encapsulation. You have something which layer 3 generates, often this is an IP packet and it's put inside an ethernet frame. It's encapsulated in that frame. The frame delivers that data to a different layer 2 destination. At the end of the frame is the frame check sequence which is used to identify any errors in the frame. Using a HUB (let's say we have 4 devices connected to a HUB) - a hub is a layer 1 device. The data can have collisions. What you need is a switch. A switch is a layer 2 device. Works the same way physically as a HUB but it understands layer 2. It maintains a MAC address table. Switches over tie learn what's connected to each port. When a switch sees frames, it can interpret frames, it can intercept them and see the source and destination MAC addresses. So over time, with this network, the MAC address table will be populated with each of the devices. So the switch will store the MAC addresses it sees on a port and the port itself. Switches are intelligent. They don't just repeat the physical level. They interpret the frames and they can make decisions based on the source and destination MAC address table. So switches store and forward frames. It doesn't repeat like a dumb layer 1 device. It means it wont forward collisions. In fact, each port on the switch is a separate collision domain. So if there's a collision on one port, it won't affect the other ports. The switch will not forward that corrupted data to the other ports. Layer 2 is the foundation for all networks which we use day to day. It's how our wired networks work. It's how our wifi networks work. It's how the internt works which is a huge collection of interconnected layer 2 networks. The name itself stands for an inter-network of networks. Summary of when adding layer 2 Identifiable devices using MAC addresses. Allows for device to device comms Media access control (sharing) - devices can share media in a nice way - avoiding collisions and cross talk Collision detection (when using switches) Unicase 1:1, Broadcast 1:All, Multicast 1:Many We have switches - basically like hubs but with super powers (layer 2) which are more intelligent and can make better decisions compared to layer 1 - ability to scale and avoid collisions Layer 3 - Network Let's say you have LAN 1 and LAN 2 which are isolated networks. Devices on each local network can communicate with each other but not outside of that layer 2 network Ethernet is a layer 2 protocol. Generally used for local networks. Long distance point to point connections are not possible with ethernet and will use more suitable protocols like PPP (Point to Point Protocol), MPLS (Multi Protocol Label Switching), Frame Relay, ATM (Asynchronous Transfer Mode) Layer 2 is the layer of the OSI stack which moves frames. Moving frames from a local source to a local destination. So to move data between different local networks, which is known as inter-networking, this is where the internet comes from, we need layer 3 Layer 3 adds the internet protcol or IP. You get IP addresses which across networking addresses which you can assign to devices and these can be used to communicate between different local networks using routing. IP packets are moved source to destination across the internet through many intermediate networks. Devices called routers which are layer 3 devices are used to move IP packets across different networks. They encapsulate IP packets into layer 2 ethernet frames. So they take the IP packet and put it into a layer 2 frame. Encapsulaton here means that an IP packet is put inside an ethernet frame for that part of the journey. IP & Packets Packets in many ways are similar to frames. They contain data to be moved and they have a source and dest address. With frames, both the source and dest address are moved across a LAN. With IP packets, the source and dest address are moved across the internet and could be on opposite sides of the planet. Packet structure of IPv4 vs IPv6 IPv4 Every packet has a source and destination IP address Protocol field (which is layer 4) like ICMP, TCP, UDP If you're storing TCP data inside a packet, this value will be 6 If you're storing UDP data inside a packet, this value will be 17 If you're storing ICMP data inside a packet, this value will be 1 Bulk of the field within a packet is taken up by the data. A field called TTL And other stuff too.. IPv6 Source & IP (Bigger & therefore, larger addresses) Data Hop limit (like TTL) IP addressing (v4) Example: 133.33.3.7 133.33 is the 'network' part 3.7 is the 'host' part which represents hosts on that network In this case, 3.7 is laptop on the network 133.33 Note: If the network part of the IP address match between 2 different IP addresses, they are on the same IP network. If they don't match, they are on different IP networks. Each part is 8 bits. So 4 parts = 32 bits. This is why IPv4 is 32 bits. Each 8 bit part is called an octet. So for example: 133.33.3.7 and 133.33.33.37 They are on the same network because the first 2 octets match They are different hosts because the last 2 octets are different Now IP addresses are either statically assigned by huamns which is known as static IP addressing or they are assigned dynamically/automatically by a service called DHCP (Dynamic Host Configuration Protocol). So the servers on your network running DHCP server software will automatically assign IP addresses to devices on your network. This is known as dynamic IP addressing. Subnet Masks A subnet mask is configured on a host device in addition to an IP address e.g. 255.255.0.0 & this is the same as a /16 prefix. Subnet masks are used to identify the network & host part of an IP address. Route Tables & Routes Example of packet moving between routers Home > ISP > AWS/Upstream ISP/Netflix (Remote networks) Create a packet on our local device which has our IP and the source IP address Default route 0.0.0.0/0 sends all packets to ISP Your packet that was generated is now in the router that has multiple network interface cards connecting to all of the remote networks (AWS/Netflix/Upstream ISP) The ISP uses route tables to forward packets/data to remote networks. Every router will have at least 1 route table A route table is a collection of routes: Destination to Next hop/target Packets are routed, hop by hop across the internet. From source to destination. Router compares packet destination IP and route table for matching destinations. The more specific prefixes are preferred (0 lowest, 32 higher). Packet is forwarded to next hop/target. This process is repeated until the packet reaches the destination. Routers can be statically populate or there are protocols such as BGP (border gateway protocol) which allow routers to communicate with each other to exchange which networks they know about and this is how the core of the internet functions Important note: when our ISP router is forwarding the packet through to the AWS router, it's forwarding at layer 2 It wraps the packet in a frame. The packet doesn't change. The frame though, it has the AWS router's MAC address as its destination. But how do we determine the MAC address of the AWS router here? We use something called the ARP (Address Resolution Protocol) Continued below! ARP (Address Resolution Protocol) The ARP is used when you have a layer 3 packet and you want to encapsulate it inside a frame and send that frame to a MAC address. We don't initially know the MAC address and we need a protocol which can find the MAC address for a given IP address For example if you communicate with AWS, AWS will be the destination of the IP packets but we will forward via our home router which is the default gateway and so we will need the MAC address of that default gateway to send the frame to containing the packet. This is where ARP comes in ARP will give you the MAC address for a given IP address Example of ARP: 2 laptops: Laptop A (133.33.3.7) wants to send data to Laptop B (133.33.3.10). THey are both on the same network since the IPs have same subnet masks Laptop A takes the data and passes it to layer 3 which creates packet. The packet has its IP address as the source and laptop B as the destination IP Now we need a way of being able to create a frame to put that packet in for a transmission. We need the MAC address of laptop B This is what ARP does for us. It\u2019s a process which runs between layer 2 and layer 3. Because both IPs have same subnet mask and it knows they are on the same local network, this is a direct connection. Routers aren\u2019t required here. We don\u2019t use routers for this type of comms ARP broadcasts on layer 2. It sends an ARP frame to all Fs as a MAC address and it asks who has the IP address 133.33.3.10. Laptop B is also running ARP. The ARP software sees this broadcast and it responds by saying im that IP address and here is my MAC address Now Laptop A has the destination MAC address of laptop B, it can use it to build a frame, encapsulate the packet in this frame and once frame is ready, it can be given to layer 1 and sent across the physical network. Layer 1 receives the physical raw bit stream and hands it off to layer 2 of the laptop. Layer 2 software of the laptop B reviews the dest MAC address and knows it meant for it. So it strips off the frame and sends the packet to its layer 3 software. Layer 3 sees the packet and sees it is the intended destination and it de-encapsulates the data and hands it to the game. Layer 3 - IP routing Example of a packet moving from multiple routers ARP is used to obtain a MAC address of another target. If a packet is going from another network, it uses a router. If it\u2019s leaving a router to another one. ARP is used to find the MAC address of the default gateway of the router. The router picks it up in a frame and strips it but realises it\u2019s not meant for it. It encapsulates it ina frame and knows the next hop for another router. The next router picks it up and strips it but finds the destination on the same network. So it uses ARP to find the MAC address of the destination. The destination picks it up and takes the data. Layer 3 Summary IP addresses (IPv4/6) - cross network addressing ARP - find the MAC address for a certain IP Routes: where to forward packets Route tables: containing multiple routes Router: moves packets from source to destination (encapsulating in L2 frames on the way) This allows for device to device comms over the internet IP doesn\u2019t provide method for channels of comms (SRC IP to DST IP only) Layer 3 provides packets and packets only have source and dest IP. So if we have 2 devices, you can only have one stream of comms. So you can\u2019t have different apps on the devices communicating at the same time. And this limitation is solved by layer 4. In theory, packets can be delivered out of order. No guarantee it will take the same route Layer 4 - Transport Layer Layer 3 problems Each IP packet on layer 3 is routed independently and isolated from each packet you might think that all IP packets arrive in proper order and good conditions but no: you\u2019re going to have intermittent network conditions packets can arrive in diff conditions and they can be out of order Layer 3, specifically IP, providers no method to ensure the ordering of packet arrival and packets can go missing. This can be due to network outages or network conditions which cause temporary routing loops. This is the negative of layer and it is solved by Layer 4. With IP only, there is no reliable method of ensuring packet delivery Another issue with layer 3 is that if you think back to the structure of IP packets, they have a source and destination field and nothing beyond that to distinguish channels of communication like ports which are solved in layer 4. Packets have only source IP and destination IP, theres is no method of splitting by APP or CHANNEL like ports. You can\u2019t have 2 apps running on the source IP communicating with 2 apps on the destination IP as there is no method of distinguishing between the apps. You could have an SSH connection open as well as a HTTP request running in the background. IP also has no flow control: if the source transmits faster than the destinaition can receive, it can sautrate the destination causing packet loss. Layer 4 - how does this solve the problem? In layer 3, we had IP address and routing. Routed packets across a network of networks Layer 4 builds on top of this: It adds 2 new protocols which are TCP & UDP Both of these run on top of IP. If you have heard TCP/IP - this means TCP running on top of IP. At a high level, you would pick TCP when you want reliability and error correction and ordering of data (slower and reliable) It\u2019s used for most of the important application layer protocols such as HTTP, HTTPS, SSH etc TCP is a connection-oriented protocol which means you set up a connection between 2 devices and once set up, it creates a bidirectional channel of communication UDP, on the other hand, is faster, because it doesn\u2019t have the TCP overhead required for the reliable delivery of data. It\u2019s less reliable than TCP There\u2019s a great joke about UDP: I\u2019d tell you about it\u2026. but you might not get it \ud83d\ude01 Both TCP and UDP run on top of IP. They use IP as transit. TCP just offers a more reliable connection oriented architecture whereas UDP is all about performance TCP introduces something called TCP segments. Segments are encapsulated within IP packets. TCP segments are placed inside IP packets. And the packets carry the segments. Segments dont have SRC and DST IP - the packets provide device addressing Inside a TCP segment, you now have SRC port and DST port in addition to SRC IP and DST IP. And this gives the combined TCP/IP protocol. Giving the ability to have multiple streams of conversation or apps running in 1 IP or machine at the same time between 2 devices Inside segments you also have sequence number and is a way of uniquely identifying a particular segment and for ordering purposes You also have acknowledgements. It is a way that one side can indicate it\u2019s received. Every segment transmitted needs to be acknowledged. You also have windows: this defines the number of bytes that indicate that you\u2019re willing to receive between acknowledgements. Once reached, the sender will pause until you acknowledge that amount of data and this is how flow control is implemented. It allows the receive to control the rate at which the sender sends the data. If you use a smaller window, it provides additional levels of control over how quickly you\u2019re sent data Larger windows are more efficient because the header of a TCP segment takes up an amount of space, and the smaller the window, the more headers are involved. Checksums are used for error checking: it means that the TCP layer is able to detect errors and can arrange for retransmission of the data as required There are more fields inside a TCP segment but the above mentioned are the most important All these field together are known as the TCP header. The capacity of the TCP segment remaining is used for data. TCP Architecture TCP, like IP, is used to allow communications between 2 devices. TCP is a connection based protocol. A connection is established between two devices using random port on a client and a known port on the server. Once established the connection is bi-directional. The \u201cconnection\u201d is a reliable connection, provided via the segments encapsulated in IP packets. You have L3 packets which have no error checking, no ordering, no association. Now you have a game laptop and a game server. The game server (the client) uses tcp port 23060 and communicates with the server on tcp port 443 This is a communication channel. TCP connections are bidirectional and this means the server will send data back to the client. To do this, it just flips the ports: so the SRC port is TCP 443 on the server and the destination port on the client is 23060. And it\u2019s why you need two sets of rules on a NACL with in AWS. One set for the initiating part (laptop to server) and one set for the response part (server to laptop) This can be conceptually viewed as a channel. These channels aren\u2019t real, they are created using segments. When you hear the term ephemeral ports or high ports, this means the port range that the client picks as the source port. Often you need to add firewall rules allowing all of this range back to the client. TCP 3 way handshake In the TCP segment structure, there\u2019s something called \u201cFlags n things\u201d Flags which can be used to set to alter the connection. e.g. FIN can be used to close, ACK for acknowledgements, syn to sync between sequence numbers So you have a client and a server: Before any data can be transferred through TCP, a connection needs to be established and this uses a 3 way handshake So in step 1, the client needs to send a segment to the server. This segment contains a random sequence number. Send a segment with SYN The server responds back with another random sequence number and sends a segment called SYN & ACK. The server then sends back a segment with ACK for acknowledge Now a connection is established and client and server can both send data","title":"OSI Model Detailed"},{"location":"network-fundamentals/osi-detailed/#osi","text":"","title":"OSI"},{"location":"network-fundamentals/osi-detailed/#layer-1-physical","text":"Layer 1 specifications define the transmission and reception of raw BIT STREAMS between a device and a shared physical medium. Physical medium can be copper (electrical signals), fibre (light), wifi (radio frequencies or waves) Like a physical hub used to connect multiple devices together No device addressing, all data is processed by all devices. It's liek shouting in a room without saying any names and everyone hears it. This is a limitation and it's solved by layer 2. No media access control","title":"Layer 1 - Physical"},{"location":"network-fundamentals/osi-detailed/#layer-2-data-link","text":"Runs over layer 1 and it requires a functional layer 1 to operate Higher layers build on lower layers Frames are a format used in layer 2 to send information over a layer 2 network Layer 2 also introduces a new unique hardware address aka a MAC address. This address is uniquely assigned to a specific hardware. MAC address is formed of 2 parts: OUI (Organizationally Unique Identifier) - first 3 bytes of the MAC address (assigned to companies who manufacture network devices) NIC (Network Interface Controller) - last 3 bytes of the MAC address Layer 2 uses layer 1: This means that a layer 2 or ethernet frame can be transmitted onto the shared physical medium by layer 1. These are converted to voltages, RF or light Layer 2 provides frames & Layer 1 handles the physical transmission and reception onto and from the physical medium So when layer 1 is transmitting a frame onto the physical medium, layer 1 doesn't understand the frame. Layer 1 simply transmits raw data onto the physical medium. Layer 2 has different parts: Preamble bits & start frame delimiter (the function of this is to allow devices to know that it's the start of a frame) Next is the destination and source MAC address. All devices on a layer 2 network have a unique MAC address And a frame can be sent to a specific device by putting its MAC address destination. Or you can put all Fs if you want to send the frame to every device on the local network. This is called a broadcast. Next is Ethertype which is a layer 3 protocol. Layer 3 uses layer 2 frames for device to device communication on a local network. So when recieving a frame at the other side, you need to know which layer 3 protocol originally put data into that frame. A common example is IP or Internet Protocol. And this is what the ethertype field is for. It tells the receiving device which layer 3 protocol put data into the frame. These 3 fields (Dest MAC address, Source MAC address, Ethertype) are called the MAC header of the frame. After the header, it's the payload. It contains the data that the frame is sending. The data is generally provided by the layer 3 protocol. This process is called encapsulation. You have something which layer 3 generates, often this is an IP packet and it's put inside an ethernet frame. It's encapsulated in that frame. The frame delivers that data to a different layer 2 destination. At the end of the frame is the frame check sequence which is used to identify any errors in the frame. Using a HUB (let's say we have 4 devices connected to a HUB) - a hub is a layer 1 device. The data can have collisions. What you need is a switch. A switch is a layer 2 device. Works the same way physically as a HUB but it understands layer 2. It maintains a MAC address table. Switches over tie learn what's connected to each port. When a switch sees frames, it can interpret frames, it can intercept them and see the source and destination MAC addresses. So over time, with this network, the MAC address table will be populated with each of the devices. So the switch will store the MAC addresses it sees on a port and the port itself. Switches are intelligent. They don't just repeat the physical level. They interpret the frames and they can make decisions based on the source and destination MAC address table. So switches store and forward frames. It doesn't repeat like a dumb layer 1 device. It means it wont forward collisions. In fact, each port on the switch is a separate collision domain. So if there's a collision on one port, it won't affect the other ports. The switch will not forward that corrupted data to the other ports. Layer 2 is the foundation for all networks which we use day to day. It's how our wired networks work. It's how our wifi networks work. It's how the internt works which is a huge collection of interconnected layer 2 networks. The name itself stands for an inter-network of networks.","title":"Layer 2 - Data Link"},{"location":"network-fundamentals/osi-detailed/#summary-of-when-adding-layer-2","text":"Identifiable devices using MAC addresses. Allows for device to device comms Media access control (sharing) - devices can share media in a nice way - avoiding collisions and cross talk Collision detection (when using switches) Unicase 1:1, Broadcast 1:All, Multicast 1:Many We have switches - basically like hubs but with super powers (layer 2) which are more intelligent and can make better decisions compared to layer 1 - ability to scale and avoid collisions","title":"Summary of when adding layer 2"},{"location":"network-fundamentals/osi-detailed/#layer-3-network","text":"Let's say you have LAN 1 and LAN 2 which are isolated networks. Devices on each local network can communicate with each other but not outside of that layer 2 network Ethernet is a layer 2 protocol. Generally used for local networks. Long distance point to point connections are not possible with ethernet and will use more suitable protocols like PPP (Point to Point Protocol), MPLS (Multi Protocol Label Switching), Frame Relay, ATM (Asynchronous Transfer Mode) Layer 2 is the layer of the OSI stack which moves frames. Moving frames from a local source to a local destination. So to move data between different local networks, which is known as inter-networking, this is where the internet comes from, we need layer 3 Layer 3 adds the internet protcol or IP. You get IP addresses which across networking addresses which you can assign to devices and these can be used to communicate between different local networks using routing. IP packets are moved source to destination across the internet through many intermediate networks. Devices called routers which are layer 3 devices are used to move IP packets across different networks. They encapsulate IP packets into layer 2 ethernet frames. So they take the IP packet and put it into a layer 2 frame. Encapsulaton here means that an IP packet is put inside an ethernet frame for that part of the journey.","title":"Layer 3 - Network"},{"location":"network-fundamentals/osi-detailed/#ip-packets","text":"Packets in many ways are similar to frames. They contain data to be moved and they have a source and dest address. With frames, both the source and dest address are moved across a LAN. With IP packets, the source and dest address are moved across the internet and could be on opposite sides of the planet.","title":"IP &amp; Packets"},{"location":"network-fundamentals/osi-detailed/#packet-structure-of-ipv4-vs-ipv6","text":"","title":"Packet structure of IPv4 vs IPv6"},{"location":"network-fundamentals/osi-detailed/#ipv4","text":"Every packet has a source and destination IP address Protocol field (which is layer 4) like ICMP, TCP, UDP If you're storing TCP data inside a packet, this value will be 6 If you're storing UDP data inside a packet, this value will be 17 If you're storing ICMP data inside a packet, this value will be 1 Bulk of the field within a packet is taken up by the data. A field called TTL And other stuff too..","title":"IPv4"},{"location":"network-fundamentals/osi-detailed/#ipv6","text":"Source & IP (Bigger & therefore, larger addresses) Data Hop limit (like TTL)","title":"IPv6"},{"location":"network-fundamentals/osi-detailed/#ip-addressing-v4","text":"Example: 133.33.3.7 133.33 is the 'network' part 3.7 is the 'host' part which represents hosts on that network In this case, 3.7 is laptop on the network 133.33 Note: If the network part of the IP address match between 2 different IP addresses, they are on the same IP network. If they don't match, they are on different IP networks. Each part is 8 bits. So 4 parts = 32 bits. This is why IPv4 is 32 bits. Each 8 bit part is called an octet. So for example: 133.33.3.7 and 133.33.33.37 They are on the same network because the first 2 octets match They are different hosts because the last 2 octets are different Now IP addresses are either statically assigned by huamns which is known as static IP addressing or they are assigned dynamically/automatically by a service called DHCP (Dynamic Host Configuration Protocol). So the servers on your network running DHCP server software will automatically assign IP addresses to devices on your network. This is known as dynamic IP addressing.","title":"IP addressing (v4)"},{"location":"network-fundamentals/osi-detailed/#subnet-masks","text":"A subnet mask is configured on a host device in addition to an IP address e.g. 255.255.0.0 & this is the same as a /16 prefix. Subnet masks are used to identify the network & host part of an IP address.","title":"Subnet Masks"},{"location":"network-fundamentals/osi-detailed/#route-tables-routes","text":"Example of packet moving between routers Home > ISP > AWS/Upstream ISP/Netflix (Remote networks) Create a packet on our local device which has our IP and the source IP address Default route 0.0.0.0/0 sends all packets to ISP Your packet that was generated is now in the router that has multiple network interface cards connecting to all of the remote networks (AWS/Netflix/Upstream ISP) The ISP uses route tables to forward packets/data to remote networks. Every router will have at least 1 route table A route table is a collection of routes: Destination to Next hop/target Packets are routed, hop by hop across the internet. From source to destination. Router compares packet destination IP and route table for matching destinations. The more specific prefixes are preferred (0 lowest, 32 higher). Packet is forwarded to next hop/target. This process is repeated until the packet reaches the destination. Routers can be statically populate or there are protocols such as BGP (border gateway protocol) which allow routers to communicate with each other to exchange which networks they know about and this is how the core of the internet functions Important note: when our ISP router is forwarding the packet through to the AWS router, it's forwarding at layer 2 It wraps the packet in a frame. The packet doesn't change. The frame though, it has the AWS router's MAC address as its destination. But how do we determine the MAC address of the AWS router here? We use something called the ARP (Address Resolution Protocol) Continued below!","title":"Route Tables &amp; Routes"},{"location":"network-fundamentals/osi-detailed/#arp-address-resolution-protocol","text":"The ARP is used when you have a layer 3 packet and you want to encapsulate it inside a frame and send that frame to a MAC address. We don't initially know the MAC address and we need a protocol which can find the MAC address for a given IP address For example if you communicate with AWS, AWS will be the destination of the IP packets but we will forward via our home router which is the default gateway and so we will need the MAC address of that default gateway to send the frame to containing the packet. This is where ARP comes in ARP will give you the MAC address for a given IP address Example of ARP: 2 laptops: Laptop A (133.33.3.7) wants to send data to Laptop B (133.33.3.10). THey are both on the same network since the IPs have same subnet masks Laptop A takes the data and passes it to layer 3 which creates packet. The packet has its IP address as the source and laptop B as the destination IP Now we need a way of being able to create a frame to put that packet in for a transmission. We need the MAC address of laptop B This is what ARP does for us. It\u2019s a process which runs between layer 2 and layer 3. Because both IPs have same subnet mask and it knows they are on the same local network, this is a direct connection. Routers aren\u2019t required here. We don\u2019t use routers for this type of comms ARP broadcasts on layer 2. It sends an ARP frame to all Fs as a MAC address and it asks who has the IP address 133.33.3.10. Laptop B is also running ARP. The ARP software sees this broadcast and it responds by saying im that IP address and here is my MAC address Now Laptop A has the destination MAC address of laptop B, it can use it to build a frame, encapsulate the packet in this frame and once frame is ready, it can be given to layer 1 and sent across the physical network. Layer 1 receives the physical raw bit stream and hands it off to layer 2 of the laptop. Layer 2 software of the laptop B reviews the dest MAC address and knows it meant for it. So it strips off the frame and sends the packet to its layer 3 software. Layer 3 sees the packet and sees it is the intended destination and it de-encapsulates the data and hands it to the game.","title":"ARP (Address Resolution Protocol)"},{"location":"network-fundamentals/osi-detailed/#layer-3-ip-routing","text":"Example of a packet moving from multiple routers ARP is used to obtain a MAC address of another target. If a packet is going from another network, it uses a router. If it\u2019s leaving a router to another one. ARP is used to find the MAC address of the default gateway of the router. The router picks it up in a frame and strips it but realises it\u2019s not meant for it. It encapsulates it ina frame and knows the next hop for another router. The next router picks it up and strips it but finds the destination on the same network. So it uses ARP to find the MAC address of the destination. The destination picks it up and takes the data.","title":"Layer 3 - IP routing"},{"location":"network-fundamentals/osi-detailed/#layer-3-summary","text":"IP addresses (IPv4/6) - cross network addressing ARP - find the MAC address for a certain IP Routes: where to forward packets Route tables: containing multiple routes Router: moves packets from source to destination (encapsulating in L2 frames on the way) This allows for device to device comms over the internet IP doesn\u2019t provide method for channels of comms (SRC IP to DST IP only) Layer 3 provides packets and packets only have source and dest IP. So if we have 2 devices, you can only have one stream of comms. So you can\u2019t have different apps on the devices communicating at the same time. And this limitation is solved by layer 4. In theory, packets can be delivered out of order. No guarantee it will take the same route","title":"Layer 3 Summary"},{"location":"network-fundamentals/osi-detailed/#layer-4-transport-layer","text":"","title":"Layer 4 - Transport Layer"},{"location":"network-fundamentals/osi-detailed/#layer-3-problems","text":"Each IP packet on layer 3 is routed independently and isolated from each packet you might think that all IP packets arrive in proper order and good conditions but no: you\u2019re going to have intermittent network conditions packets can arrive in diff conditions and they can be out of order Layer 3, specifically IP, providers no method to ensure the ordering of packet arrival and packets can go missing. This can be due to network outages or network conditions which cause temporary routing loops. This is the negative of layer and it is solved by Layer 4. With IP only, there is no reliable method of ensuring packet delivery Another issue with layer 3 is that if you think back to the structure of IP packets, they have a source and destination field and nothing beyond that to distinguish channels of communication like ports which are solved in layer 4. Packets have only source IP and destination IP, theres is no method of splitting by APP or CHANNEL like ports. You can\u2019t have 2 apps running on the source IP communicating with 2 apps on the destination IP as there is no method of distinguishing between the apps. You could have an SSH connection open as well as a HTTP request running in the background. IP also has no flow control: if the source transmits faster than the destinaition can receive, it can sautrate the destination causing packet loss.","title":"Layer 3 problems"},{"location":"network-fundamentals/osi-detailed/#layer-4-how-does-this-solve-the-problem","text":"In layer 3, we had IP address and routing. Routed packets across a network of networks Layer 4 builds on top of this: It adds 2 new protocols which are TCP & UDP Both of these run on top of IP. If you have heard TCP/IP - this means TCP running on top of IP. At a high level, you would pick TCP when you want reliability and error correction and ordering of data (slower and reliable) It\u2019s used for most of the important application layer protocols such as HTTP, HTTPS, SSH etc TCP is a connection-oriented protocol which means you set up a connection between 2 devices and once set up, it creates a bidirectional channel of communication UDP, on the other hand, is faster, because it doesn\u2019t have the TCP overhead required for the reliable delivery of data. It\u2019s less reliable than TCP There\u2019s a great joke about UDP: I\u2019d tell you about it\u2026. but you might not get it \ud83d\ude01 Both TCP and UDP run on top of IP. They use IP as transit. TCP just offers a more reliable connection oriented architecture whereas UDP is all about performance TCP introduces something called TCP segments. Segments are encapsulated within IP packets. TCP segments are placed inside IP packets. And the packets carry the segments. Segments dont have SRC and DST IP - the packets provide device addressing Inside a TCP segment, you now have SRC port and DST port in addition to SRC IP and DST IP. And this gives the combined TCP/IP protocol. Giving the ability to have multiple streams of conversation or apps running in 1 IP or machine at the same time between 2 devices Inside segments you also have sequence number and is a way of uniquely identifying a particular segment and for ordering purposes You also have acknowledgements. It is a way that one side can indicate it\u2019s received. Every segment transmitted needs to be acknowledged. You also have windows: this defines the number of bytes that indicate that you\u2019re willing to receive between acknowledgements. Once reached, the sender will pause until you acknowledge that amount of data and this is how flow control is implemented. It allows the receive to control the rate at which the sender sends the data. If you use a smaller window, it provides additional levels of control over how quickly you\u2019re sent data Larger windows are more efficient because the header of a TCP segment takes up an amount of space, and the smaller the window, the more headers are involved. Checksums are used for error checking: it means that the TCP layer is able to detect errors and can arrange for retransmission of the data as required There are more fields inside a TCP segment but the above mentioned are the most important All these field together are known as the TCP header. The capacity of the TCP segment remaining is used for data.","title":"Layer 4 - how does this solve the problem?"},{"location":"network-fundamentals/osi-detailed/#tcp-architecture","text":"TCP, like IP, is used to allow communications between 2 devices. TCP is a connection based protocol. A connection is established between two devices using random port on a client and a known port on the server. Once established the connection is bi-directional. The \u201cconnection\u201d is a reliable connection, provided via the segments encapsulated in IP packets. You have L3 packets which have no error checking, no ordering, no association. Now you have a game laptop and a game server. The game server (the client) uses tcp port 23060 and communicates with the server on tcp port 443 This is a communication channel. TCP connections are bidirectional and this means the server will send data back to the client. To do this, it just flips the ports: so the SRC port is TCP 443 on the server and the destination port on the client is 23060. And it\u2019s why you need two sets of rules on a NACL with in AWS. One set for the initiating part (laptop to server) and one set for the response part (server to laptop) This can be conceptually viewed as a channel. These channels aren\u2019t real, they are created using segments. When you hear the term ephemeral ports or high ports, this means the port range that the client picks as the source port. Often you need to add firewall rules allowing all of this range back to the client.","title":"TCP Architecture"},{"location":"network-fundamentals/osi-detailed/#tcp-3-way-handshake","text":"In the TCP segment structure, there\u2019s something called \u201cFlags n things\u201d Flags which can be used to set to alter the connection. e.g. FIN can be used to close, ACK for acknowledgements, syn to sync between sequence numbers So you have a client and a server: Before any data can be transferred through TCP, a connection needs to be established and this uses a 3 way handshake So in step 1, the client needs to send a segment to the server. This segment contains a random sequence number. Send a segment with SYN The server responds back with another random sequence number and sends a segment called SYN & ACK. The server then sends back a segment with ACK for acknowledge Now a connection is established and client and server can both send data","title":"TCP 3 way handshake"},{"location":"network-fundamentals/osi-model/","text":"OSI Model Before we can look at some practical networking stuff, we have to go over some boring jargon that you've probably heard of before. The OSI (Open Systems Interconnection) model is a theoretical model of networking. This model shows us how a packet traverses through a network in seven different layers. I won't get into specifics of this model, since most of these networking courses will be focused on the TCP/IP model, but it should be mentioned that such a theoretical networking model exists and has actually played a large part in the TCP/IP networking model that we use today. OSI \u2705 Abstraction or Concept of the Internet Layer 1 to Layer 7 Layer 1 is physical Layer 2 is data frames etc Layer 3 is IP Layer 4 is TCP/UDP. ports Layer 5 - connection/session layer (linkerD?) Layer 6 - Presentation Layer 7 - App layer, HTTP, HTTPS etc TCP/IP model This model is another version that focusses on these layers Layer 3/4 & 7 Exercise Read more about the OSI model: https://en.wikipedia.org/wiki/OSI_model Quiz Questions Click the right arrow to view the answers What is used as the theoretical model of networking? OSI","title":"OSI Model"},{"location":"network-fundamentals/osi-model/#osi-model","text":"Before we can look at some practical networking stuff, we have to go over some boring jargon that you've probably heard of before. The OSI (Open Systems Interconnection) model is a theoretical model of networking. This model shows us how a packet traverses through a network in seven different layers. I won't get into specifics of this model, since most of these networking courses will be focused on the TCP/IP model, but it should be mentioned that such a theoretical networking model exists and has actually played a large part in the TCP/IP networking model that we use today.","title":"OSI Model"},{"location":"network-fundamentals/osi-model/#osi","text":"Abstraction or Concept of the Internet Layer 1 to Layer 7 Layer 1 is physical Layer 2 is data frames etc Layer 3 is IP Layer 4 is TCP/UDP. ports Layer 5 - connection/session layer (linkerD?) Layer 6 - Presentation Layer 7 - App layer, HTTP, HTTPS etc TCP/IP model This model is another version that focusses on these layers Layer 3/4 & 7","title":"OSI \u2705"},{"location":"network-fundamentals/osi-model/#exercise","text":"Read more about the OSI model: https://en.wikipedia.org/wiki/OSI_model","title":"Exercise"},{"location":"network-fundamentals/osi-model/#quiz-questions","text":"Click the right arrow to view the answers What is used as the theoretical model of networking? OSI","title":"Quiz Questions"},{"location":"network-fundamentals/tcp-ip-model/","text":"TCP/IP Model The OSI model gave birth to what eventually became the TCP/IP model and this model is actually what the Internet is based off of. It is the actual implementation of networking. The TCP/IP model uses the TCP/IP protocol suite, which we just commonly refer to as TCP/IP. These protocols work together to specify how data should be gathered, addressed, transmitted and routed through a network. Using the TCP/IP model, we can see how these protocols are used to show the breakdown of how a packet travels through the network. Application Layer The top layer of the TCP/IP model. It determines how your computer's programs (such as your web browser) interface with the transport layer services to view the data that gets sent or received. This layer uses: HTTP (Hypertext Transfer Protocol) - used for the webpages on the Internet. SMTP (Simple Mail Transfer Protocol) - electronic mail (email) transmission Transport Layer How data will be transmitted, includes checking the correct ports, the integrity of the data, and basically delivering our packets. This layer uses: TCP (Transmission Control Protocol) - reliable data delivery UDP (User Datagram Protocol) - unreliable data delivery Network Layer This layers specifies how to move packets between hosts and across networks. This layer uses: IP (Internet Protocol) - Helps route packets from one machine to another. ICMP (Internet Control Message Protocol) - Helps tell us what is going on, such as error messages and debugging information. Link Layer This layer specifies how to send data across a physical piece of hardware. Such as data travelling through Ethernet, fiber, etc. The lists above of protocols each layer uses is not extensive and you'll encounter many other protocols that come into play. In the following lessons, we will dive through each of these layers and discuss how our packet traverses through the network in the eyes of the TCP/IP model (there are many perspectives on how a packet travels across networks, we won't look at them all, but be aware that they exist). Quiz Questions Click the right arrow to view the answers What is the top layer of the TCP/IP model? Application What are the bottom layers of the TCP/IP model? Link & Network layers","title":"TCP/IP Model"},{"location":"network-fundamentals/tcp-ip-model/#tcpip-model","text":"The OSI model gave birth to what eventually became the TCP/IP model and this model is actually what the Internet is based off of. It is the actual implementation of networking. The TCP/IP model uses the TCP/IP protocol suite, which we just commonly refer to as TCP/IP. These protocols work together to specify how data should be gathered, addressed, transmitted and routed through a network. Using the TCP/IP model, we can see how these protocols are used to show the breakdown of how a packet travels through the network. Application Layer The top layer of the TCP/IP model. It determines how your computer's programs (such as your web browser) interface with the transport layer services to view the data that gets sent or received. This layer uses: HTTP (Hypertext Transfer Protocol) - used for the webpages on the Internet. SMTP (Simple Mail Transfer Protocol) - electronic mail (email) transmission Transport Layer How data will be transmitted, includes checking the correct ports, the integrity of the data, and basically delivering our packets. This layer uses: TCP (Transmission Control Protocol) - reliable data delivery UDP (User Datagram Protocol) - unreliable data delivery Network Layer This layers specifies how to move packets between hosts and across networks. This layer uses: IP (Internet Protocol) - Helps route packets from one machine to another. ICMP (Internet Control Message Protocol) - Helps tell us what is going on, such as error messages and debugging information. Link Layer This layer specifies how to send data across a physical piece of hardware. Such as data travelling through Ethernet, fiber, etc. The lists above of protocols each layer uses is not extensive and you'll encounter many other protocols that come into play. In the following lessons, we will dive through each of these layers and discuss how our packet traverses through the network in the eyes of the TCP/IP model (there are many perspectives on how a packet travels across networks, we won't look at them all, but be aware that they exist).","title":"TCP/IP Model"},{"location":"network-fundamentals/tcp-ip-model/#quiz-questions","text":"Click the right arrow to view the answers What is the top layer of the TCP/IP model? Application What are the bottom layers of the TCP/IP model? Link & Network layers","title":"Quiz Questions"},{"location":"network-fundamentals/tcp/","text":"TCP TCP \u2705 (Layer 4) Transmission control protocol \u201cControls\u201d the transmission unlike UDP which is a firehose Connection Requires handshake 20 bytes headers segment Stateful TCP >> Reliable comms, Remote shell (SSH), database connections, web comms, any bidirectional comms TCP Connection Connection is layer (because its a session) Connection is an AGREEMENT between client and server Must create connection to send data Connection is identified by 4 properties SourceIP-SourcePort DestinationIP-DestinationPort Can\u2019t send data outside connection Sometimes called socket or file descriptor Requires 3 way TCP handshake (ACK. SYN-ACK, ACK) Segments are sequenced and ordered Segments are acknowledge Lost segments are retransmitted Multiplexing and demultiplexing Sender multiplexes all its apps into TCP connections R eceiver demultiplex TCP segments to each app based on connection pairs Connection Establishment App1 on 10.0.0.1 want to send data to AppX on 10.0.0.2 App1 sends SYN to AppX to synchronous sequence numbers AppX sends SYN/ACK to synchronous its sequence number App1 ACKs AppX SYN. Three way handshake Sending data App1 sends data to App 2 App1 encapsulates the data in a segment and send it App 2 acknowledges the segment Hint: : Can App1 send new segment before ack of old segment arrives? Lost data >> App1 sends segment 1,2 and 3 to App 2, Seg 3 is lost, App 2 acknowledge 3, App1 resend seq 3 Closing connection App 1 wants to close the connection App1 sends FIN, App2 ACK App2 sends FIN, App1 ACK 4 way handshake > >FIN, ACK, FIN, ACK Summary Layer 4 \u201cControls\u201d the transmission unlike UDP which is a firehose Introduces connection concept Retransmission, acknowledgement, guaranteed delivery Stateful, connection has a state Pros & Cons of TCP Pros Guaranteed delivery No one can send data without prior knowledge Flow control and congestion control Ordered packets, no corruption or app level work More secure than UDP and can\u2019t easily be spoofed Cons large overhead compared to UDO more bandwith stateful: consumes memory on server and client considered high latecny for certain workloads (slow start/congestion/acks) Does too much at a low level (hence QUIC protocol intro) Single connection to send multiple streams of data (HTTP reqs) Stream 1 has nothing to do with stream 2 Both steam 1 and steam 2 packets must arrive) TCP meltdown Not a good candidate for VPN Summary TCP is a transport layer protocol like UDP but it guarantees reliability, flow control and congestion control. TCP guarantees reliable delivery by using sequence numbers. A TCP connection is established by a three way handshake. Initiation: The client begins by sending a SYN (synchronize) packet with a sequence number to the server. Response: The server acknowledges (ACK) this packet, sends back its SYN packet with a different sequence number. Final Acknowledgment: The client sends an ACK for the server's SYN, completing the handshake and establishing the connection. After this, data transfer is reliable. Each packet sent is tracked with sequence numbers and acknowledgments. Missing packets trigger retransmissions, ensuring reliability. #To understand handshake run packet capture on one bash session tcpdump -S -i any port 80 #Run curl on one bash session curl www.google.com TCP Architecture TCP, like IP, is used to allow communications between 2 devices. TCP is a connection based protocol. A connection is established between two devices using random port on a client and a known port on the server. Once established the connection is bi-directional. The \u201cconnection\u201d is a reliable connection, provided via the segments encapsulated in IP packets. You have L3 packets which have no error checking, no ordering, no association. Now you have a game laptop and a game server. The game server (the client) uses tcp port 23060 and communicates with the server on tcp port 443 This is a communication channel. TCP connections are bidirectional and this means the server will send data back to the client. To do this, it just flips the ports: so the SRC port is TCP 443 on the server and the destination port on the client is 23060. And it\u2019s why you need two sets of rules on a NACL with in AWS. One set for the initiating part (laptop to server) and one set for the response part (server to laptop) This can be conceptually viewed as a channel. These channels aren\u2019t real, they are created using segments. When you hear the term ephemeral ports or high ports, this means the port range that the client picks as the source port. Often you need to add firewall rules allowing all of this range back to the client. TCP 3 way handshake In the TCP segment structure, there\u2019s something called \u201cFlags n things\u201d Flags which can be used to set to alter the connection. e.g. FIN can be used to close, ACK for acknowledgements, syn to sync between sequence numbers So you have a client and a server: Before any data can be transferred through TCP, a connection needs to be established and this uses a 3 way handshake So in step 1, the client needs to send a segment to the server. This segment contains a random sequence number. Send a segment with SYN The server responds back with another random sequence number and sends a segment called SYN & ACK. The server then sends back a segment with ACK for acknowledge Now a connection is established and client and server can both send data Flow Control and Congestion Control: Flow Control: Managed through the 'win size' field in each TCP segment, indicating the available buffer size for incoming data. It prevents issues where the sender is faster than the receiver. Congestion Control: Governs the number of unacknowledged segments in transit to avoid network congestion. Armed with our TCP and HTTP knowledge lets see how this is used by SREs in their role Connection Termination: Closing a TCP connection involves: The client or server initiates closure with a FIN (finish) packet. The recipient acknowledges with an ACK, sends its FIN packet. The initiator responds with an ACK, entering a 'time-wait' state to avoid confusion from delayed packets. This state lasts for a period like 2*MSS (120 seconds). Applications in DevOps & Software Engineering Load Balancing: Knowledge of TCP and HTTP is crucial for implementing load balancers, which can vary in method (like L4 or L7 load balancing). Throughput Optimization: Adjusting sysctl variables for rmem and wmem can enhance throughput. Connection Handling: Variables like tcp_max_syn_backlog and somax_conn influence how many connections can be processed before acceptance by an application, crucial for single-threaded apps. Managing Connections: Avoiding file descriptor exhaustion involves strategies like tweaking tcp_reuse and tcp_recycle, or using connection pools. Performance Analysis: Differentiating between application and network issues, like identifying socket states (e.g., Close_wait) or retransmissions, is essential for pinpointing performance bottlenecks.","title":"TCP"},{"location":"network-fundamentals/tcp/#tcp","text":"","title":"TCP"},{"location":"network-fundamentals/tcp/#tcp-layer-4","text":"Transmission control protocol \u201cControls\u201d the transmission unlike UDP which is a firehose Connection Requires handshake 20 bytes headers segment Stateful TCP >> Reliable comms, Remote shell (SSH), database connections, web comms, any bidirectional comms TCP Connection Connection is layer (because its a session) Connection is an AGREEMENT between client and server Must create connection to send data Connection is identified by 4 properties SourceIP-SourcePort DestinationIP-DestinationPort Can\u2019t send data outside connection Sometimes called socket or file descriptor Requires 3 way TCP handshake (ACK. SYN-ACK, ACK) Segments are sequenced and ordered Segments are acknowledge Lost segments are retransmitted Multiplexing and demultiplexing Sender multiplexes all its apps into TCP connections R eceiver demultiplex TCP segments to each app based on connection pairs Connection Establishment App1 on 10.0.0.1 want to send data to AppX on 10.0.0.2 App1 sends SYN to AppX to synchronous sequence numbers AppX sends SYN/ACK to synchronous its sequence number App1 ACKs AppX SYN. Three way handshake Sending data App1 sends data to App 2 App1 encapsulates the data in a segment and send it App 2 acknowledges the segment Hint: : Can App1 send new segment before ack of old segment arrives? Lost data >> App1 sends segment 1,2 and 3 to App 2, Seg 3 is lost, App 2 acknowledge 3, App1 resend seq 3 Closing connection App 1 wants to close the connection App1 sends FIN, App2 ACK App2 sends FIN, App1 ACK 4 way handshake > >FIN, ACK, FIN, ACK Summary Layer 4 \u201cControls\u201d the transmission unlike UDP which is a firehose Introduces connection concept Retransmission, acknowledgement, guaranteed delivery Stateful, connection has a state Pros & Cons of TCP Pros Guaranteed delivery No one can send data without prior knowledge Flow control and congestion control Ordered packets, no corruption or app level work More secure than UDP and can\u2019t easily be spoofed Cons large overhead compared to UDO more bandwith stateful: consumes memory on server and client considered high latecny for certain workloads (slow start/congestion/acks) Does too much at a low level (hence QUIC protocol intro) Single connection to send multiple streams of data (HTTP reqs) Stream 1 has nothing to do with stream 2 Both steam 1 and steam 2 packets must arrive) TCP meltdown Not a good candidate for VPN","title":"TCP \u2705\u00a0(Layer 4)"},{"location":"network-fundamentals/tcp/#summary","text":"TCP is a transport layer protocol like UDP but it guarantees reliability, flow control and congestion control. TCP guarantees reliable delivery by using sequence numbers. A TCP connection is established by a three way handshake. Initiation: The client begins by sending a SYN (synchronize) packet with a sequence number to the server. Response: The server acknowledges (ACK) this packet, sends back its SYN packet with a different sequence number. Final Acknowledgment: The client sends an ACK for the server's SYN, completing the handshake and establishing the connection. After this, data transfer is reliable. Each packet sent is tracked with sequence numbers and acknowledgments. Missing packets trigger retransmissions, ensuring reliability. #To understand handshake run packet capture on one bash session tcpdump -S -i any port 80 #Run curl on one bash session curl www.google.com","title":"Summary"},{"location":"network-fundamentals/tcp/#tcp-architecture","text":"TCP, like IP, is used to allow communications between 2 devices. TCP is a connection based protocol. A connection is established between two devices using random port on a client and a known port on the server. Once established the connection is bi-directional. The \u201cconnection\u201d is a reliable connection, provided via the segments encapsulated in IP packets. You have L3 packets which have no error checking, no ordering, no association. Now you have a game laptop and a game server. The game server (the client) uses tcp port 23060 and communicates with the server on tcp port 443 This is a communication channel. TCP connections are bidirectional and this means the server will send data back to the client. To do this, it just flips the ports: so the SRC port is TCP 443 on the server and the destination port on the client is 23060. And it\u2019s why you need two sets of rules on a NACL with in AWS. One set for the initiating part (laptop to server) and one set for the response part (server to laptop) This can be conceptually viewed as a channel. These channels aren\u2019t real, they are created using segments. When you hear the term ephemeral ports or high ports, this means the port range that the client picks as the source port. Often you need to add firewall rules allowing all of this range back to the client.","title":"TCP Architecture"},{"location":"network-fundamentals/tcp/#tcp-3-way-handshake","text":"In the TCP segment structure, there\u2019s something called \u201cFlags n things\u201d Flags which can be used to set to alter the connection. e.g. FIN can be used to close, ACK for acknowledgements, syn to sync between sequence numbers So you have a client and a server: Before any data can be transferred through TCP, a connection needs to be established and this uses a 3 way handshake So in step 1, the client needs to send a segment to the server. This segment contains a random sequence number. Send a segment with SYN The server responds back with another random sequence number and sends a segment called SYN & ACK. The server then sends back a segment with ACK for acknowledge Now a connection is established and client and server can both send data","title":"TCP 3 way handshake"},{"location":"network-fundamentals/tcp/#flow-control-and-congestion-control","text":"Flow Control: Managed through the 'win size' field in each TCP segment, indicating the available buffer size for incoming data. It prevents issues where the sender is faster than the receiver. Congestion Control: Governs the number of unacknowledged segments in transit to avoid network congestion. Armed with our TCP and HTTP knowledge lets see how this is used by SREs in their role","title":"Flow Control and Congestion Control:"},{"location":"network-fundamentals/tcp/#connection-termination","text":"Closing a TCP connection involves: The client or server initiates closure with a FIN (finish) packet. The recipient acknowledges with an ACK, sends its FIN packet. The initiator responds with an ACK, entering a 'time-wait' state to avoid confusion from delayed packets. This state lasts for a period like 2*MSS (120 seconds).","title":"Connection Termination:"},{"location":"network-fundamentals/tcp/#applications-in-devops-software-engineering","text":"Load Balancing: Knowledge of TCP and HTTP is crucial for implementing load balancers, which can vary in method (like L4 or L7 load balancing). Throughput Optimization: Adjusting sysctl variables for rmem and wmem can enhance throughput. Connection Handling: Variables like tcp_max_syn_backlog and somax_conn influence how many connections can be processed before acceptance by an application, crucial for single-threaded apps. Managing Connections: Avoiding file descriptor exhaustion involves strategies like tweaking tcp_reuse and tcp_recycle, or using connection pools. Performance Analysis: Differentiating between application and network issues, like identifying socket states (e.g., Close_wait) or retransmissions, is essential for pinpointing performance bottlenecks.","title":"Applications in DevOps &amp; Software Engineering"},{"location":"network-fundamentals/transport-layer/","text":"Transport Layer The transports layer helps us transfer our data in a way networks can read it. It breaks our data into chunks that will be transported and put back together in the correct order. These chunks are known as segments. Segments make it easier to transport data across networks. Ports Even though we know where we are sending our data via IP addresses, they aren't specific enough to send our data to a certain processes or services. Services such as HTTP use a communication channel via ports. If we want to send webpage data, we need to send it over the HTTP port (port 80). In addition to forming segments, the transport layer will also attach the source and destination ports to the segment, so when the receiver gets the final packet it will know what port to use. UDP There are two popular transport protocols UDP and TCP. We'll briefly discuss UDP and spend most of our time on TCP, since it's the most commonly used. UDP is not a reliable method of transporting data, in fact it doesn't really care if you get all of your original data. This may sound terrible, but it does have its uses, such as for media streaming, it's ok if you lose some frames in return you get your data a little faster. TCP TCP provides a reliable connection-oriented stream of data. TCP uses ports to send data to and from hosts. An application opens up a connection from one port on its host to another port on a remote host. In order to establish the connection, we use the TCP handshake. The client (connecting process) sends a SYN segment to the server to request a connection Server sends the client a SYN-ACK segment to acknowledge the client's connection request Client sends an ACK to the server to acknowledge the server's connection request Once this connection is established, data can be exchanged over a TCP connection. The data is sent over in different segments and are tracked with TCP sequence numbers so they can be arranged in the correct order when they are delivered. In our email example, the transport layer attaches the destination port (25) to the source port of the source host. Quiz Questions Click the right arrow to view the answers What is a reliable transport protocol? TCP","title":"Transport Layer"},{"location":"network-fundamentals/transport-layer/#transport-layer","text":"The transports layer helps us transfer our data in a way networks can read it. It breaks our data into chunks that will be transported and put back together in the correct order. These chunks are known as segments. Segments make it easier to transport data across networks. Ports Even though we know where we are sending our data via IP addresses, they aren't specific enough to send our data to a certain processes or services. Services such as HTTP use a communication channel via ports. If we want to send webpage data, we need to send it over the HTTP port (port 80). In addition to forming segments, the transport layer will also attach the source and destination ports to the segment, so when the receiver gets the final packet it will know what port to use. UDP There are two popular transport protocols UDP and TCP. We'll briefly discuss UDP and spend most of our time on TCP, since it's the most commonly used. UDP is not a reliable method of transporting data, in fact it doesn't really care if you get all of your original data. This may sound terrible, but it does have its uses, such as for media streaming, it's ok if you lose some frames in return you get your data a little faster. TCP TCP provides a reliable connection-oriented stream of data. TCP uses ports to send data to and from hosts. An application opens up a connection from one port on its host to another port on a remote host. In order to establish the connection, we use the TCP handshake. The client (connecting process) sends a SYN segment to the server to request a connection Server sends the client a SYN-ACK segment to acknowledge the client's connection request Client sends an ACK to the server to acknowledge the server's connection request Once this connection is established, data can be exchanged over a TCP connection. The data is sent over in different segments and are tracked with TCP sequence numbers so they can be arranged in the correct order when they are delivered. In our email example, the transport layer attaches the destination port (25) to the source port of the source host.","title":"Transport Layer"},{"location":"network-fundamentals/transport-layer/#quiz-questions","text":"Click the right arrow to view the answers What is a reliable transport protocol? TCP","title":"Quiz Questions"},{"location":"network-fundamentals/udp/","text":"UDP UDP \u2705 (Layer 4) User Diagram Protocol Simple protocol to send and recieve data Prior communication not required (yes it can be easy but also a double edged sword due to security) Stateless - no knowledge is stored on the host 8 byte header datagram Use cases >> video streaming, VPN, DNS, webRTC Mutliplexing & demultiplexing sender multiplexes all its app into UDP receiever demultideplx UDP datagrams to each app Source & Dest port App1 on 10.0.0.1 sends data to AppX on 10.0.0.2 Destination Port = 53 AppX responds back to App1 We need Source Port so we know how to send back data Source Port = 5555 UDP Pros & Cons Pros: Simple protocol header size is small so datagrams are small uses less bandwith stateless consumes less memory (non state stored in server/client) Cons: No Ack (acknowledgement) No guaranteed delivery Connection-less - anyone can send data without prior knowledge No flow control No congestion control No ordered packets Security - can be easily spoofed Summary UDP is layer 4 protocol uses ports to address processes Stateless UDP is a transport layer protocol. DNS is an application layer protocol that runs on top of UDP (most of the times). Before jumping into UDP, let's try to understand what an application and transport layer is. Here's how they interact with each other: Application and Transport Layers: The transport layer (UDP, in this case) ensures that data from the application layer (like a DNS request) reaches the intended destination. Port Usage: DNS servers typically listen on port 53. Clients send DNS requests using a random source port number above 1024, targeting port 53 on the server. Kernel's Role: The client's kernel sends the request using the sendto system call. The server's kernel receives it, checks the port number, and forwards it to the DNS server process using recvfrom. This process is known as multiplexing and demultiplexing. Characteristics of UDP UDP is designed for simplicity and low overhead, performing only multiplexing and demultiplexing. Unlike TCP, UDP does not provide reliable communication, flow control, or congestion control. Any additional requirements must be implemented at the application level. Example: A basic example involves a UDP client/server where the client sends a \"Hello World\" message to a server listening on port 5005. The server receives and prints this message. Applications in DevOps & Software Engineering Buffer Management in Slow Networks: In scenarios where the underlying network is slow, the sendto system call might hang if the UDP layer can't queue packets efficiently. Increasing sysctl variables like net.core.wmem_max and net.core.wmem_default can help manage this by providing a larger buffer, which can accommodate more data during network slowdowns, thus maintaining throughput. Managing Fast Senders and Slow Receivers: If the receiving process is slower than the sending rate, the kernel may need to drop packets if its buffer gets full, since UDP doesn\u2019t manage flow control. To mitigate this, increasing the rmem_default and rmem_max sysctl variables can provide a larger buffer on the receiving end, reducing the likelihood of packet loss in such scenarios.","title":"UDP"},{"location":"network-fundamentals/udp/#udp","text":"","title":"UDP"},{"location":"network-fundamentals/udp/#udp-layer-4","text":"User Diagram Protocol Simple protocol to send and recieve data Prior communication not required (yes it can be easy but also a double edged sword due to security) Stateless - no knowledge is stored on the host 8 byte header datagram Use cases >> video streaming, VPN, DNS, webRTC Mutliplexing & demultiplexing sender multiplexes all its app into UDP receiever demultideplx UDP datagrams to each app Source & Dest port App1 on 10.0.0.1 sends data to AppX on 10.0.0.2 Destination Port = 53 AppX responds back to App1 We need Source Port so we know how to send back data Source Port = 5555 UDP Pros & Cons Pros: Simple protocol header size is small so datagrams are small uses less bandwith stateless consumes less memory (non state stored in server/client) Cons: No Ack (acknowledgement) No guaranteed delivery Connection-less - anyone can send data without prior knowledge No flow control No congestion control No ordered packets Security - can be easily spoofed Summary UDP is layer 4 protocol uses ports to address processes Stateless UDP is a transport layer protocol. DNS is an application layer protocol that runs on top of UDP (most of the times). Before jumping into UDP, let's try to understand what an application and transport layer is. Here's how they interact with each other: Application and Transport Layers: The transport layer (UDP, in this case) ensures that data from the application layer (like a DNS request) reaches the intended destination. Port Usage: DNS servers typically listen on port 53. Clients send DNS requests using a random source port number above 1024, targeting port 53 on the server. Kernel's Role: The client's kernel sends the request using the sendto system call. The server's kernel receives it, checks the port number, and forwards it to the DNS server process using recvfrom. This process is known as multiplexing and demultiplexing.","title":"UDP \u2705\u00a0(Layer 4)"},{"location":"network-fundamentals/udp/#characteristics-of-udp","text":"UDP is designed for simplicity and low overhead, performing only multiplexing and demultiplexing. Unlike TCP, UDP does not provide reliable communication, flow control, or congestion control. Any additional requirements must be implemented at the application level.","title":"Characteristics of UDP"},{"location":"network-fundamentals/udp/#example","text":"A basic example involves a UDP client/server where the client sends a \"Hello World\" message to a server listening on port 5005. The server receives and prints this message.","title":"Example:"},{"location":"network-fundamentals/udp/#applications-in-devops-software-engineering","text":"Buffer Management in Slow Networks: In scenarios where the underlying network is slow, the sendto system call might hang if the UDP layer can't queue packets efficiently. Increasing sysctl variables like net.core.wmem_max and net.core.wmem_default can help manage this by providing a larger buffer, which can accommodate more data during network slowdowns, thus maintaining throughput. Managing Fast Senders and Slow Receivers: If the receiving process is slower than the sending rate, the kernel may need to drop packets if its buffer gets full, since UDP doesn\u2019t manage flow control. To mitigate this, increasing the rmem_default and rmem_max sysctl variables can provide a larger buffer on the receiving end, reducing the likelihood of packet loss in such scenarios.","title":"Applications in DevOps &amp; Software Engineering"},{"location":"network-sharing/network-file-sharing/","text":"File Sharing Overview You usually are not the only computer on your network, this is especially the case if you're working in a commercial environment. When we want to transfer data from one machine to another, sometimes it maybe easier to connect a USB drive and manually copy them. But for the most part, if you're working with machines on the same network, the way to transfer data is through network file sharing. In this course we'll go over a couple of different methods to copy data to and from different machines on your network. We'll discuss some simple file copies, then we'll talk about mounting entire directories on your machine that act as a separate drive. One simple file sharing tool is the scp command. The scp command stands for secure copy, it works exactly the way the cp command does, but allows you to copy from one host over to another host on the same network. It works via ssh so all your actions are using the same authentication and security as ssh. To copy a file over from local host to a remote host $ scp myfile.txt username@remotehost.com:/remote/directory To copy a file from a remote host to your local host $ scp username@remotehost.com:/remote/directory/myfile.txt /local/directory To copy over a directory from your local host to a remote host $ scp -r mydir username@remotehost.com:/remote/directory Exercise Try to copy a file over with scp from one machine to another. Quiz Questions Click the right arrow to view the answers What command can you use to securely copy files from one host to another? scp","title":"Network File Sharing"},{"location":"network-sharing/network-file-sharing/#file-sharing-overview","text":"You usually are not the only computer on your network, this is especially the case if you're working in a commercial environment. When we want to transfer data from one machine to another, sometimes it maybe easier to connect a USB drive and manually copy them. But for the most part, if you're working with machines on the same network, the way to transfer data is through network file sharing. In this course we'll go over a couple of different methods to copy data to and from different machines on your network. We'll discuss some simple file copies, then we'll talk about mounting entire directories on your machine that act as a separate drive. One simple file sharing tool is the scp command. The scp command stands for secure copy, it works exactly the way the cp command does, but allows you to copy from one host over to another host on the same network. It works via ssh so all your actions are using the same authentication and security as ssh. To copy a file over from local host to a remote host $ scp myfile.txt username@remotehost.com:/remote/directory To copy a file from a remote host to your local host $ scp username@remotehost.com:/remote/directory/myfile.txt /local/directory To copy over a directory from your local host to a remote host $ scp -r mydir username@remotehost.com:/remote/directory","title":"File Sharing Overview"},{"location":"network-sharing/network-file-sharing/#exercise","text":"Try to copy a file over with scp from one machine to another.","title":"Exercise"},{"location":"network-sharing/network-file-sharing/#quiz-questions","text":"Click the right arrow to view the answers What command can you use to securely copy files from one host to another? scp","title":"Quiz Questions"},{"location":"network-sharing/nfs/","text":"NFS The most standard network file share for Linux is NFS (Network File System), NFS allows a server to share directories and files with one or more clients over the network. We won't get into the details of how to create an NFS server as it can get complex, however we will discuss setting up NFS clients. Setting up NFS client $ sudo service nfsclient start $ sudo mount server:/directory /mount_directory Automounting Let's say you use the NFS server quite often and you want to keep it permanently mounted, normally you think you'd edit the /etc/fstab file, but you may not always get a connection to the server and that can cause issues on bootup. Instead what you want to do is setup automounting so that you can connect to the NFS server when you need to. This is done with the automount tool or in recent versions of Linux amd . When a file is accessed in a specified directory, automount will look up the remote server and automatically mount it. Exercise Read the manpage for NFS to learn more. Quiz Questions Click the right arrow to view the answers What tool is used to manage mount points automatically? automount","title":"Network File Share (NFS)"},{"location":"network-sharing/nfs/#nfs","text":"The most standard network file share for Linux is NFS (Network File System), NFS allows a server to share directories and files with one or more clients over the network. We won't get into the details of how to create an NFS server as it can get complex, however we will discuss setting up NFS clients. Setting up NFS client $ sudo service nfsclient start $ sudo mount server:/directory /mount_directory Automounting Let's say you use the NFS server quite often and you want to keep it permanently mounted, normally you think you'd edit the /etc/fstab file, but you may not always get a connection to the server and that can cause issues on bootup. Instead what you want to do is setup automounting so that you can connect to the NFS server when you need to. This is done with the automount tool or in recent versions of Linux amd . When a file is accessed in a specified directory, automount will look up the remote server and automatically mount it.","title":"NFS"},{"location":"network-sharing/nfs/#exercise","text":"Read the manpage for NFS to learn more.","title":"Exercise"},{"location":"network-sharing/nfs/#quiz-questions","text":"Click the right arrow to view the answers What tool is used to manage mount points automatically? automount","title":"Quiz Questions"},{"location":"network-sharing/rsync/","text":"Rsync Another tool used to copy data from different hosts is rsync (short for remote synchronization). Rsync is very similar to scp, but it does have a major difference. Rsync uses a special algorithm that checks in advanced if there is already data that you are copying to and will only copy over the differences. For example, let's say that you were copying over a file and your network got interrupted, therefore your copy stopped midway. Instead of re-copying everything from the beginning, rsync will only copy over the parts that didn't get copied. It also verifies the integrity of a file you are copying over with checksums. These small optimizations allow greater file transfer flexibility and makes rsync ideal for directory synchronization remotely and locally, data backups, large data transfers and more. Some commonly-used rsync options: v - verbose output r - recursive into directories h - human readable output z - compressed for easier transfer, great for slow connections Copy/sync files on the same host $ rsync -zvr /my/local/directory/one /my/local/directory/two Copy/sync files to local host from a remote host $ rsync /local/directory username@remotehost.com:/remote/directory Copy/sync files to a remote host from a local host $ rsync username@remotehost.com:/remote/directory /local/directory Exercise Use rsync to sync a directory to another directory, be sure not to overwrite an important directory! Quiz Questions Click the right arrow to view the answers What command would be useful for data backups? rsync","title":"Rsync"},{"location":"network-sharing/rsync/#rsync","text":"Another tool used to copy data from different hosts is rsync (short for remote synchronization). Rsync is very similar to scp, but it does have a major difference. Rsync uses a special algorithm that checks in advanced if there is already data that you are copying to and will only copy over the differences. For example, let's say that you were copying over a file and your network got interrupted, therefore your copy stopped midway. Instead of re-copying everything from the beginning, rsync will only copy over the parts that didn't get copied. It also verifies the integrity of a file you are copying over with checksums. These small optimizations allow greater file transfer flexibility and makes rsync ideal for directory synchronization remotely and locally, data backups, large data transfers and more. Some commonly-used rsync options: v - verbose output r - recursive into directories h - human readable output z - compressed for easier transfer, great for slow connections Copy/sync files on the same host $ rsync -zvr /my/local/directory/one /my/local/directory/two Copy/sync files to local host from a remote host $ rsync /local/directory username@remotehost.com:/remote/directory Copy/sync files to a remote host from a local host $ rsync username@remotehost.com:/remote/directory /local/directory","title":"Rsync"},{"location":"network-sharing/rsync/#exercise","text":"Use rsync to sync a directory to another directory, be sure not to overwrite an important directory!","title":"Exercise"},{"location":"network-sharing/rsync/#quiz-questions","text":"Click the right arrow to view the answers What command would be useful for data backups? rsync","title":"Quiz Questions"},{"location":"network-sharing/samba/","text":"Samba In the early days of computing, it became necessary for Windows machines to share files with Linux machines, thus the Server Message Block (SMB) protocol was born. SMB was used for sharing files between Windows operating systems (Mac also has file sharing with SMB) and then it was later cleaned up and optimized in the form of the Common Internet File System (CIFS) protocol. Samba is what we call the Linux utilities to work with CIFS on Linux. In addition to file sharing, you can also share resources like printers. Create a network share with Samba Let's go through the basic steps to create a network share that a Windows machine can access: Install Samba $ sudo apt update $ sudo apt install samba Setup smb.conf The configuration file for Samba is found at /etc/samba/smb.conf, this file should tell the system what directories should be shared, their access permissions, and more options. The default smb.conf comes with lots of commented code already and you can use those as an example to write your own configurations. $ sudo vi /etc/samba/smb.conf Setup up a password for Samba $ sudo smbpasswd -a [username] Create a shared directory $ mkdir /my/directory/to/share Restart the Samba service $ sudo service smbd restart Accessing a Samba share via Windows In Windows, just type in the network connection in the run prompt: \\HOST\\sharename. Accessing a Samba/Windows share via Linux $ smbclient //HOST/directory -U user The Samba package includes a command line tool called smbclient that you can use to access any Windows or Samba server. Once you're connected to the share you can navigate and transfer files. Attach a Samba share to your system Instead of transferring files one by one, you can just mount the network share on your system. $ sudo mount -t cifs servername:directory mountpount -o user=username,pass=password Exercise Setup a Samba share, if you don't have one, open up smb.conf and familiarize yourself with the options in the config file. Quiz Questions Click the right arrow to view the answers What is the latest protocol used for file transfer between Windows and Linux? CIFS","title":"Samba"},{"location":"network-sharing/samba/#samba","text":"In the early days of computing, it became necessary for Windows machines to share files with Linux machines, thus the Server Message Block (SMB) protocol was born. SMB was used for sharing files between Windows operating systems (Mac also has file sharing with SMB) and then it was later cleaned up and optimized in the form of the Common Internet File System (CIFS) protocol. Samba is what we call the Linux utilities to work with CIFS on Linux. In addition to file sharing, you can also share resources like printers. Create a network share with Samba Let's go through the basic steps to create a network share that a Windows machine can access: Install Samba $ sudo apt update $ sudo apt install samba Setup smb.conf The configuration file for Samba is found at /etc/samba/smb.conf, this file should tell the system what directories should be shared, their access permissions, and more options. The default smb.conf comes with lots of commented code already and you can use those as an example to write your own configurations. $ sudo vi /etc/samba/smb.conf Setup up a password for Samba $ sudo smbpasswd -a [username] Create a shared directory $ mkdir /my/directory/to/share Restart the Samba service $ sudo service smbd restart Accessing a Samba share via Windows In Windows, just type in the network connection in the run prompt: \\HOST\\sharename. Accessing a Samba/Windows share via Linux $ smbclient //HOST/directory -U user The Samba package includes a command line tool called smbclient that you can use to access any Windows or Samba server. Once you're connected to the share you can navigate and transfer files. Attach a Samba share to your system Instead of transferring files one by one, you can just mount the network share on your system. $ sudo mount -t cifs servername:directory mountpount -o user=username,pass=password","title":"Samba"},{"location":"network-sharing/samba/#exercise","text":"Setup a Samba share, if you don't have one, open up smb.conf and familiarize yourself with the options in the config file.","title":"Exercise"},{"location":"network-sharing/samba/#quiz-questions","text":"Click the right arrow to view the answers What is the latest protocol used for file transfer between Windows and Linux? CIFS","title":"Quiz Questions"},{"location":"network-sharing/simple-http-server/","text":"Simple HTTP Server Python has a super useful tool for serving files over HTTP. This is great if you just want to create a quick network share that other machines on your network can access. To do that just go to the directory you want to share and run: $ python -m SimpleHTTPServer This sets up a basic webserver that you can access via the localhost address. So grab the IP address of the machine you ran this on and then on another machine access it in the browser with: http://IP_ADDRESS:8000. On your own machine, you can view the files available by typing: http://localhost:8000 in your web browser. You can also do this with node or if you are running Python 3, the syntax will be a little bit different. Exercise Try setting up a SimpleHTTPServer! Quiz Questions Click the right arrow to view the answers What tool can you use to create a simple http server with python? SimpleHTTPServer","title":"Simple HTTP Server"},{"location":"network-sharing/simple-http-server/#simple-http-server","text":"Python has a super useful tool for serving files over HTTP. This is great if you just want to create a quick network share that other machines on your network can access. To do that just go to the directory you want to share and run: $ python -m SimpleHTTPServer This sets up a basic webserver that you can access via the localhost address. So grab the IP address of the machine you ran this on and then on another machine access it in the browser with: http://IP_ADDRESS:8000. On your own machine, you can view the files available by typing: http://localhost:8000 in your web browser. You can also do this with node or if you are running Python 3, the syntax will be a little bit different.","title":"Simple HTTP Server"},{"location":"network-sharing/simple-http-server/#exercise","text":"Try setting up a SimpleHTTPServer!","title":"Exercise"},{"location":"network-sharing/simple-http-server/#quiz-questions","text":"Click the right arrow to view the answers What tool can you use to create a simple http server with python? SimpleHTTPServer","title":"Quiz Questions"},{"location":"network-troubleshooting/icmp/","text":"ICMP The Internet Control Message Protocol (ICMP) is part of the TCP/IP protocol suite, it used to send updates and error messages and is an extremely useful protocol used for debugging network issues such as a failed packet delivery. Each ICMP message contains a type, code and checksum field. The type field is the type of ICMP message, the code is a sub-type and describes more information about the message and the checksum is used to detect any issues with the integrity of the message. Let's look at some common ICMP Types: Type 0 - Echo Reply Type 3 - Destination Unreachable Type 8 - Echo Request Type 11 - Time Exceeded When a packet can't get to a destination, Type 3 ICMP message is generated, within Type 3 there are 16 code values that will further describe why it can't get to the destination: Code 0 - Network Unreachable Code 1 - Host Unreachable etc..etc.. These messages will make more sense as we use some network troubleshooting tools. Quiz Questions Click the right arrow to view the answers What is the ICMP type for echo request? 8","title":"ICMP"},{"location":"network-troubleshooting/icmp/#icmp","text":"The Internet Control Message Protocol (ICMP) is part of the TCP/IP protocol suite, it used to send updates and error messages and is an extremely useful protocol used for debugging network issues such as a failed packet delivery. Each ICMP message contains a type, code and checksum field. The type field is the type of ICMP message, the code is a sub-type and describes more information about the message and the checksum is used to detect any issues with the integrity of the message. Let's look at some common ICMP Types: Type 0 - Echo Reply Type 3 - Destination Unreachable Type 8 - Echo Request Type 11 - Time Exceeded When a packet can't get to a destination, Type 3 ICMP message is generated, within Type 3 there are 16 code values that will further describe why it can't get to the destination: Code 0 - Network Unreachable Code 1 - Host Unreachable etc..etc.. These messages will make more sense as we use some network troubleshooting tools.","title":"ICMP"},{"location":"network-troubleshooting/icmp/#quiz-questions","text":"Click the right arrow to view the answers What is the ICMP type for echo request? 8","title":"Quiz Questions"},{"location":"network-troubleshooting/netstat/","text":"Netstat Well Known Ports We've discussed data transmission through ports on our machine, let's look at some well known ports. You can get a list of well-known ports by looking at the file /etc/services : ftp 21/tcp ssh 22/tcp smtp 25/tcp domain 53/tcp # DNS http 80/tcp https 443/tcp ..etc.. The first column is the name of the service, then the port number and the transport layer protocol it uses. netstat An extremely useful tool to get detailed information about your network is netstat . Netstat displays various network related information such network connections, routing tables, information about network interfaces and more, it's the swiss army knife of networking tools. We will focus mostly on one feature netstat has and that's the status of network connections. Before we look at an example, let's talk about sockets and ports first. A socket is an interface that allows programs to send and receive data while a port is used to identify which application should send or receive data. The socket address is the combination of the IP address and port. Every connection between a host and destination requires a unique socket. For example, HTTP is a service that runs on port 80, however we can have many HTTP connections and to maintain each connection a socket gets created per connection. mo@icebox:~$ netstat -at Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 icebox:domain *:* LISTEN tcp 0 0 localhost:ipp *:* LISTEN tcp 0 0 icebox.lan:44468 124.28.28.50:http TIME_WAIT tcp 0 0 icebox.lan:34751 124.28.29.50:http TIME_WAIT tcp 0 0 icebox.lan:34604 economy.canonical.:http TIME_WAIT tcp6 0 0 ip6-localhost:ipp [::]:* LISTEN tcp6 1 0 ip6-localhost:35094 ip6-localhost:ipp CLOSE_WAIT tcp6 0 0 ip6-localhost:ipp ip6-localhost:35094 FIN_WAIT2 The netstat -a command shows the listening and non-listening sockets for network connections, the -t flag shows only tcp connections. The columns are as follows from left to right: Proto: Protocol used, TCP or UDP. Recv-Q: Data that is queued to be received Send-Q: Data that is queued to be sent Local Address: Locally connected host Foreign Address: Remotely connected host State: The state of the socket See the manpage for a list of socket states, but here are a few: LISTENING: The socket is listening for incoming connections, remember when we make a TCP connection our destination has to be listening for us before we can connect. SYN_SENT: The socket is actively attempting to establish a connection. ESTABLISHED: The socket has an established connection CLOSE_WAIT: The remote host has shutdown and we're waiting for the socket to close TIME_WAIT: The socket is waiting after close to handle packets still in the network Exercise Look at the manpage for netstat and learn all the features it has to offer. Quiz Questions Click the right arrow to view the answers What port is used for HTTPS? 443","title":"Netstat"},{"location":"network-troubleshooting/netstat/#netstat","text":"Well Known Ports We've discussed data transmission through ports on our machine, let's look at some well known ports. You can get a list of well-known ports by looking at the file /etc/services : ftp 21/tcp ssh 22/tcp smtp 25/tcp domain 53/tcp # DNS http 80/tcp https 443/tcp ..etc.. The first column is the name of the service, then the port number and the transport layer protocol it uses. netstat An extremely useful tool to get detailed information about your network is netstat . Netstat displays various network related information such network connections, routing tables, information about network interfaces and more, it's the swiss army knife of networking tools. We will focus mostly on one feature netstat has and that's the status of network connections. Before we look at an example, let's talk about sockets and ports first. A socket is an interface that allows programs to send and receive data while a port is used to identify which application should send or receive data. The socket address is the combination of the IP address and port. Every connection between a host and destination requires a unique socket. For example, HTTP is a service that runs on port 80, however we can have many HTTP connections and to maintain each connection a socket gets created per connection. mo@icebox:~$ netstat -at Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 icebox:domain *:* LISTEN tcp 0 0 localhost:ipp *:* LISTEN tcp 0 0 icebox.lan:44468 124.28.28.50:http TIME_WAIT tcp 0 0 icebox.lan:34751 124.28.29.50:http TIME_WAIT tcp 0 0 icebox.lan:34604 economy.canonical.:http TIME_WAIT tcp6 0 0 ip6-localhost:ipp [::]:* LISTEN tcp6 1 0 ip6-localhost:35094 ip6-localhost:ipp CLOSE_WAIT tcp6 0 0 ip6-localhost:ipp ip6-localhost:35094 FIN_WAIT2 The netstat -a command shows the listening and non-listening sockets for network connections, the -t flag shows only tcp connections. The columns are as follows from left to right: Proto: Protocol used, TCP or UDP. Recv-Q: Data that is queued to be received Send-Q: Data that is queued to be sent Local Address: Locally connected host Foreign Address: Remotely connected host State: The state of the socket See the manpage for a list of socket states, but here are a few: LISTENING: The socket is listening for incoming connections, remember when we make a TCP connection our destination has to be listening for us before we can connect. SYN_SENT: The socket is actively attempting to establish a connection. ESTABLISHED: The socket has an established connection CLOSE_WAIT: The remote host has shutdown and we're waiting for the socket to close TIME_WAIT: The socket is waiting after close to handle packets still in the network","title":"Netstat"},{"location":"network-troubleshooting/netstat/#exercise","text":"Look at the manpage for netstat and learn all the features it has to offer.","title":"Exercise"},{"location":"network-troubleshooting/netstat/#quiz-questions","text":"Click the right arrow to view the answers What port is used for HTTPS? 443","title":"Quiz Questions"},{"location":"network-troubleshooting/packet-analysis/","text":"Packet Analysis The subject of packet analysis could fill an entire course of its own and there are many books written just on packet analysis. However, today we will just learn the basics. There are two extremely popular packet analyzers, Wireshark and tcpdump. These tools scan your network interfaces, capture the packet activity, parse the packages and output the information for us to see. They allows us to get into the nitty gritty of network analysis and get into the low level stuff. We'll be using tcpdump since it has a simpler interface, however if you were to pick up packet analysis for your toolbelt, I would recommend looking into Wireshark. Install tcpdump $ sudo apt install tcpdump Capture packet data on an interface mo@icebox:~$ sudo tcpdump -i wlan0 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on wlan0, link-type EN10MB (Ethernet), capture size 65535 bytes 11:28:23.958840 IP icebox.lan > nuq04s29-in-f4.1e100.net: ICMP echo request, id 1901, seq 2, length 64 11:28:23.970928 IP nuq04s29-in-f4.1e100.net > icebox.lan: ICMP echo reply, id 1901, seq 2, length 64 11:28:24.960464 IP icebox.lan > nuq04s29-in-f4.1e100.net: ICMP echo request, id 1901, seq 3, length 64 11:28:24.979299 IP nuq04s29-in-f4.1e100.net > icebox.lan: ICMP echo reply, id 1901, seq 3, length 64 11:28:25.961869 IP icebox.lan > nuq04s29-in-f4.1e100.net: ICMP echo request, id 1901, seq 4, length 64 11:28:25.976176 IP nuq04s29-in-f4.1e100.net > icebox.lan: ICMP echo reply, id 1901, seq 4, length 64 11:28:26.963667 IP icebox.lan > nuq04s29-in-f4.1e100.net: ICMP echo request, id 1901, seq 5, length 64 11:28:26.976137 IP nuq04s29-in-f4.1e100.net > icebox.lan: ICMP echo reply, id 1901, seq 5, length 64 11:28:30.674953 ARP, Request who-has 172.254.1.0 tell ThePickleParty.lan, length 28 11:28:31.190665 IP ThePickleParty.lan.51056 > 192.168.86.255.rfe: UDP, length 306 You'll notice a lot of stuff happening when you run a packet capture, well that's to be expected there's a lot of network activity happening in the background. In my above example, I've taken only a snippet of my capture specifically the time when I decided to ping www.google.com. Understanding the output 11:28:23.958840 IP icebox.lan > nuq04s29-in-f4.1e100.net: ICMP echo request, id 1901, seq 2, length 64 11:28:23.970928 IP nuq04s29-in-f4.1e100.net > icebox.lan: ICMP echo reply, id 1901, seq 2, length 64 The first field is a timestamp of the network activity IP, this contains the protocol information Next, you'll see the source and destination address: icebox.lan > nuq04s29-in-f4.1e100.net seq, this is the TCP packets's starting and ending sequence number length, length in bytes As you can see from our tcpdump output, we are sending an ICMP echo request packet to www.google.com and getting an ICMP echo reply packet in return! Also note that different packets will output different information, refer to the manpage to see what those are. Writing tcpdump output to a file $ sudo tcpdump -w /some/file Some final thoughts: we only scraped the surface of the subject of packet analysis. There is so much you can look at and we haven't even touched upon going even deeper with Hex and ASCII output. There are plenty of resources online to help you learn more about packet analyzers and I urge you to find them! Exercise Download and install the Wireshark tool and play around with the interface. Quiz Questions Click the right arrow to view the answers What is the flag to capture a specific interface with tcpdump? -i","title":"Packet Analysis"},{"location":"network-troubleshooting/packet-analysis/#packet-analysis","text":"The subject of packet analysis could fill an entire course of its own and there are many books written just on packet analysis. However, today we will just learn the basics. There are two extremely popular packet analyzers, Wireshark and tcpdump. These tools scan your network interfaces, capture the packet activity, parse the packages and output the information for us to see. They allows us to get into the nitty gritty of network analysis and get into the low level stuff. We'll be using tcpdump since it has a simpler interface, however if you were to pick up packet analysis for your toolbelt, I would recommend looking into Wireshark. Install tcpdump $ sudo apt install tcpdump Capture packet data on an interface mo@icebox:~$ sudo tcpdump -i wlan0 tcpdump: verbose output suppressed, use -v or -vv for full protocol decode listening on wlan0, link-type EN10MB (Ethernet), capture size 65535 bytes 11:28:23.958840 IP icebox.lan > nuq04s29-in-f4.1e100.net: ICMP echo request, id 1901, seq 2, length 64 11:28:23.970928 IP nuq04s29-in-f4.1e100.net > icebox.lan: ICMP echo reply, id 1901, seq 2, length 64 11:28:24.960464 IP icebox.lan > nuq04s29-in-f4.1e100.net: ICMP echo request, id 1901, seq 3, length 64 11:28:24.979299 IP nuq04s29-in-f4.1e100.net > icebox.lan: ICMP echo reply, id 1901, seq 3, length 64 11:28:25.961869 IP icebox.lan > nuq04s29-in-f4.1e100.net: ICMP echo request, id 1901, seq 4, length 64 11:28:25.976176 IP nuq04s29-in-f4.1e100.net > icebox.lan: ICMP echo reply, id 1901, seq 4, length 64 11:28:26.963667 IP icebox.lan > nuq04s29-in-f4.1e100.net: ICMP echo request, id 1901, seq 5, length 64 11:28:26.976137 IP nuq04s29-in-f4.1e100.net > icebox.lan: ICMP echo reply, id 1901, seq 5, length 64 11:28:30.674953 ARP, Request who-has 172.254.1.0 tell ThePickleParty.lan, length 28 11:28:31.190665 IP ThePickleParty.lan.51056 > 192.168.86.255.rfe: UDP, length 306 You'll notice a lot of stuff happening when you run a packet capture, well that's to be expected there's a lot of network activity happening in the background. In my above example, I've taken only a snippet of my capture specifically the time when I decided to ping www.google.com. Understanding the output 11:28:23.958840 IP icebox.lan > nuq04s29-in-f4.1e100.net: ICMP echo request, id 1901, seq 2, length 64 11:28:23.970928 IP nuq04s29-in-f4.1e100.net > icebox.lan: ICMP echo reply, id 1901, seq 2, length 64 The first field is a timestamp of the network activity IP, this contains the protocol information Next, you'll see the source and destination address: icebox.lan > nuq04s29-in-f4.1e100.net seq, this is the TCP packets's starting and ending sequence number length, length in bytes As you can see from our tcpdump output, we are sending an ICMP echo request packet to www.google.com and getting an ICMP echo reply packet in return! Also note that different packets will output different information, refer to the manpage to see what those are. Writing tcpdump output to a file $ sudo tcpdump -w /some/file Some final thoughts: we only scraped the surface of the subject of packet analysis. There is so much you can look at and we haven't even touched upon going even deeper with Hex and ASCII output. There are plenty of resources online to help you learn more about packet analyzers and I urge you to find them!","title":"Packet Analysis"},{"location":"network-troubleshooting/packet-analysis/#exercise","text":"Download and install the Wireshark tool and play around with the interface.","title":"Exercise"},{"location":"network-troubleshooting/packet-analysis/#quiz-questions","text":"Click the right arrow to view the answers What is the flag to capture a specific interface with tcpdump? -i","title":"Quiz Questions"},{"location":"network-troubleshooting/ping/","text":"Ping One of the most simplest networking tools ping , it's used to test whether or not a packet can reach a host. It works by sending ICMP echo request (Type 8) packets to the destination host and waits for an ICMP echo reply (Type 0). Ping is successful when a host sends out the request packet and receives a response from the target. Let's look at an example: mo@icebox:~$ ping -c 3 www.google.com PING www.google.com (74.125.239.112) 56(84) bytes of data. 64 bytes from nuq05s01-in-f16.1e100.net (74.125.239.112): icmp_seq=1 ttl=128 time=29.0 ms 64 bytes from nuq05s01-in-f16.1e100.net (74.125.239.112): icmp_seq=2 ttl=128 time=23.7 ms 64 bytes from nuq05s01-in-f16.1e100.net (74.125.239.112): icmp_seq=3 ttl=128 time=15.1 ms In this example, we are using ping to check if we can get to www.google.com. The -c flag (count) is used to stop sending echo request packets after the count has been reached. The first part says that we are sending 64-byte packets to 74.125.239.112 (google.com) and the rest show us the details of the trip. By default it sends a packet per second. icmp_seq The icmp_seq field is used to show the sequence number of packets sent, so in this case, I sent out 3 packets and we can see that 3 packets made it back. If you do a ping and you get some sequence numbers missing, that means that some connectivity issue is happening and not all your packets are getting through. If the sequence number is out of order, your connection is probably very slow as your packets are exceeding the one second default. ttl The Time To Live (ttl) field is used as a hop counter, as you make hops, it decrements the counter by one and once the hop counter reaches 0, our packet dies. This is meant to give the packet a lifespan, we don't want our packets travelling around forever. time The roundtrip time it took from you sending the echo request packet to getting an echo reply. Exercise Do a ping on a website and look at the output you receive. Quiz Questions Click the right arrow to view the answers What is the roundtrip time unit of measurement? ms","title":"Ping"},{"location":"network-troubleshooting/ping/#ping","text":"One of the most simplest networking tools ping , it's used to test whether or not a packet can reach a host. It works by sending ICMP echo request (Type 8) packets to the destination host and waits for an ICMP echo reply (Type 0). Ping is successful when a host sends out the request packet and receives a response from the target. Let's look at an example: mo@icebox:~$ ping -c 3 www.google.com PING www.google.com (74.125.239.112) 56(84) bytes of data. 64 bytes from nuq05s01-in-f16.1e100.net (74.125.239.112): icmp_seq=1 ttl=128 time=29.0 ms 64 bytes from nuq05s01-in-f16.1e100.net (74.125.239.112): icmp_seq=2 ttl=128 time=23.7 ms 64 bytes from nuq05s01-in-f16.1e100.net (74.125.239.112): icmp_seq=3 ttl=128 time=15.1 ms In this example, we are using ping to check if we can get to www.google.com. The -c flag (count) is used to stop sending echo request packets after the count has been reached. The first part says that we are sending 64-byte packets to 74.125.239.112 (google.com) and the rest show us the details of the trip. By default it sends a packet per second. icmp_seq The icmp_seq field is used to show the sequence number of packets sent, so in this case, I sent out 3 packets and we can see that 3 packets made it back. If you do a ping and you get some sequence numbers missing, that means that some connectivity issue is happening and not all your packets are getting through. If the sequence number is out of order, your connection is probably very slow as your packets are exceeding the one second default. ttl The Time To Live (ttl) field is used as a hop counter, as you make hops, it decrements the counter by one and once the hop counter reaches 0, our packet dies. This is meant to give the packet a lifespan, we don't want our packets travelling around forever. time The roundtrip time it took from you sending the echo request packet to getting an echo reply.","title":"Ping"},{"location":"network-troubleshooting/ping/#exercise","text":"Do a ping on a website and look at the output you receive.","title":"Exercise"},{"location":"network-troubleshooting/ping/#quiz-questions","text":"Click the right arrow to view the answers What is the roundtrip time unit of measurement? ms","title":"Quiz Questions"},{"location":"network-troubleshooting/traceroute/","text":"Traceroute The traceroute command is used to see how packets are getting routed. It works by sending packets with increasing TTL values, starting with 1. So the first router gets the packet, and it decrements the TTL value by one, thus dropping the packet. The router sends back an ICMP Time Exceeded message back to us. And then the next packet gets a TTL of 2, so it makes it past the first router, but when it gets to the second router the TTL is 0 and it returns another ICMP Time Exceeded message. Traceroute works this way because as it sends and drops packets it is build a list of routers that the packets traverse, until it finally gets to its destination and gets an ICMP Echo Reply message. Here's a little snippet of a traceroute: $ traceroute google.com traceroute to google.com (216.58.216.174), 30 hops max, 60 byte packets 1 192.168.4.254 (192.168.4.254) 0.028 ms 0.009 ms 0.008 ms 2 100.64.1.113 (100.64.1.113) 1.227 ms 1.226 ms 0.920 ms 3 100.64.0.20 (100.64.0.20) 1.501 ms 1.556 ms 0.855 ms Each line is a router or machine that is between me and my target. It shows the name of the target and its IP address and the last three columns correspond to the round-trip time of a packet to get to that router. By default, we send three packets along the route. Exercise Run the traceroute command on your machine and observe the output. Quiz Questions Click the right arrow to view the answers What gets decremented by one when making hops across the network? ttl","title":"Traceroute"},{"location":"network-troubleshooting/traceroute/#traceroute","text":"The traceroute command is used to see how packets are getting routed. It works by sending packets with increasing TTL values, starting with 1. So the first router gets the packet, and it decrements the TTL value by one, thus dropping the packet. The router sends back an ICMP Time Exceeded message back to us. And then the next packet gets a TTL of 2, so it makes it past the first router, but when it gets to the second router the TTL is 0 and it returns another ICMP Time Exceeded message. Traceroute works this way because as it sends and drops packets it is build a list of routers that the packets traverse, until it finally gets to its destination and gets an ICMP Echo Reply message. Here's a little snippet of a traceroute: $ traceroute google.com traceroute to google.com (216.58.216.174), 30 hops max, 60 byte packets 1 192.168.4.254 (192.168.4.254) 0.028 ms 0.009 ms 0.008 ms 2 100.64.1.113 (100.64.1.113) 1.227 ms 1.226 ms 0.920 ms 3 100.64.0.20 (100.64.0.20) 1.501 ms 1.556 ms 0.855 ms Each line is a router or machine that is between me and my target. It shows the name of the target and its IP address and the last three columns correspond to the round-trip time of a packet to get to that router. By default, we send three packets along the route.","title":"Traceroute"},{"location":"network-troubleshooting/traceroute/#exercise","text":"Run the traceroute command on your machine and observe the output.","title":"Exercise"},{"location":"network-troubleshooting/traceroute/#quiz-questions","text":"Click the right arrow to view the answers What gets decremented by one when making hops across the network? ttl","title":"Quiz Questions"},{"location":"process-utilization/continuous-monitoring/","text":"Continuous Monitoring These monitoring tools are good to look at when your machine is having issues, but what about machines that are having issues when you aren't looking. For those, you'll need to use a continuous monitoring tool, something that will collect, report and save your system activity information. In this lesson we will go over a great tool to use sar . Installing sar Sar is a tool that is used to do historical analysis on your system, first make sure you have it installed by installing the sysstat package sudo apt install sysstat . Setting up data collection Usually once you install sysstat, your system will automatically start collecting data, if it doesn't you can enable it by modifying the ENABLED field in /etc/default/sysstat. Using sar $ sudo sar -q This command will list the details from the start of the day. $ sudo sar -r This will list the details of memory usage from the start of the day. $ sudo sar -P This will list the details of CPU usage. To see a view of a different day, you can go into /var/log/sysstat/saXX where XX is the day you want to view. $sar -q /var/log/sysstat/sa02 Exercise Install sar on your system and start collecting and analyzing your system resource utilization. Quiz Questions Click the right arrow to view the answers What is a good tool to use for monitoring system resources? sar","title":"Monitoring"},{"location":"process-utilization/continuous-monitoring/#continuous-monitoring","text":"These monitoring tools are good to look at when your machine is having issues, but what about machines that are having issues when you aren't looking. For those, you'll need to use a continuous monitoring tool, something that will collect, report and save your system activity information. In this lesson we will go over a great tool to use sar . Installing sar Sar is a tool that is used to do historical analysis on your system, first make sure you have it installed by installing the sysstat package sudo apt install sysstat . Setting up data collection Usually once you install sysstat, your system will automatically start collecting data, if it doesn't you can enable it by modifying the ENABLED field in /etc/default/sysstat. Using sar $ sudo sar -q This command will list the details from the start of the day. $ sudo sar -r This will list the details of memory usage from the start of the day. $ sudo sar -P This will list the details of CPU usage. To see a view of a different day, you can go into /var/log/sysstat/saXX where XX is the day you want to view. $sar -q /var/log/sysstat/sa02","title":"Continuous Monitoring"},{"location":"process-utilization/continuous-monitoring/#exercise","text":"Install sar on your system and start collecting and analyzing your system resource utilization.","title":"Exercise"},{"location":"process-utilization/continuous-monitoring/#quiz-questions","text":"Click the right arrow to view the answers What is a good tool to use for monitoring system resources? sar","title":"Quiz Questions"},{"location":"process-utilization/cpu-monitoring/","text":"CPU Monitoring Let's go over a useful command, uptime . mo@icebox:~$ uptime 17:23:35 up 1 day, 5:59, 2 users, load average: 0.00, 0.02, 0.05 We talked about uptime in the first lesson of this course, but we haven't gone over the load average field. Load averages are good way to see the CPU load on your system. These numbers represent the average CPU load in 1, 5, and 15 minute intervals. What do I mean by CPU load, the CPU load is the average number of processes that are waiting to be executed by the CPU. Let's say you have a single-core CPU, think of this core as a single lane in traffic. If it's rush hour on the freeway, this lane is gonna be really busy and traffic is gonna be at 100% or a load of 1. Now the traffic has become so bad, it's backing up the freeway and getting the regular roads busy by twice the amount of cars, we can say that your load is 200% or a load of 2. Now let's say it clears up a bit and there are only half as many cars on the freeway lane, we can say the load of the lane is 0.5. When traffic is non-existent and we can get home quicker, the load should ideally be very low, like 2am traffic low. The cars in this case are processes and these processes are just waiting to get off the freeway and get home. Now just because you have a load average of 1 doesn't mean your computer is slogging around. Most modern machines these days have multiple cores. If you had a quad core processor (4 cores) and your load average is 1, it's really just affecting 25% of your CPU. Think of each core as a lane in traffic. You can view the amount of cores you have on your system with cat /proc/cpuinfo . When observing load average, you have to take the number of cores into account, if you find that your machine is always using an above average load, there could something wrong going on. Exercise Check the load average of your system and see what it's doing. Quiz Questions Click the right arrow to view the answers What command can you use to see the load average? uptime","title":"CPU Monitoring"},{"location":"process-utilization/cpu-monitoring/#cpu-monitoring","text":"Let's go over a useful command, uptime . mo@icebox:~$ uptime 17:23:35 up 1 day, 5:59, 2 users, load average: 0.00, 0.02, 0.05 We talked about uptime in the first lesson of this course, but we haven't gone over the load average field. Load averages are good way to see the CPU load on your system. These numbers represent the average CPU load in 1, 5, and 15 minute intervals. What do I mean by CPU load, the CPU load is the average number of processes that are waiting to be executed by the CPU. Let's say you have a single-core CPU, think of this core as a single lane in traffic. If it's rush hour on the freeway, this lane is gonna be really busy and traffic is gonna be at 100% or a load of 1. Now the traffic has become so bad, it's backing up the freeway and getting the regular roads busy by twice the amount of cars, we can say that your load is 200% or a load of 2. Now let's say it clears up a bit and there are only half as many cars on the freeway lane, we can say the load of the lane is 0.5. When traffic is non-existent and we can get home quicker, the load should ideally be very low, like 2am traffic low. The cars in this case are processes and these processes are just waiting to get off the freeway and get home. Now just because you have a load average of 1 doesn't mean your computer is slogging around. Most modern machines these days have multiple cores. If you had a quad core processor (4 cores) and your load average is 1, it's really just affecting 25% of your CPU. Think of each core as a lane in traffic. You can view the amount of cores you have on your system with cat /proc/cpuinfo . When observing load average, you have to take the number of cores into account, if you find that your machine is always using an above average load, there could something wrong going on.","title":"CPU Monitoring"},{"location":"process-utilization/cpu-monitoring/#exercise","text":"Check the load average of your system and see what it's doing.","title":"Exercise"},{"location":"process-utilization/cpu-monitoring/#quiz-questions","text":"Click the right arrow to view the answers What command can you use to see the load average? uptime","title":"Quiz Questions"},{"location":"process-utilization/cron-jobs/","text":"Cron Jobs Although we have been talking about resource utilization, I think this would be a good point to mention a neat tool in Linux that is used to schedule tasks using cron. There is a service that runs programs for you at whatever time you schedule. This is a really useful if you have a script you want to run once a day that needs to execute something for you. For example, let's say I have a script located in /home/mo/scripts/change_wallpaper. I use this script every morning to change the picture I use for my wallpaper, but each morning I have to manually execute this script. Instead what I can do is create a cron job that executes my script through cron. I can specify the time I want this cron job to run and execute my script. 30 08 * * * /home/mo/scripts/change_wallpaper The fields are as follows from left to right: Minute - (0-59) Hour - (0-23) Day of the month - (1-31) Month - (1-12) Day of the week - (0-7). 0 and 7 are denoted as Sunday The asterisk in the field means to match every value. So in my above example, I want this to run every day in every month at 8:30am. To create a cronjob, just edit the crontab file: crontab -e Exercise Create a cronjob that you want to run at a scheduled time. Quiz Questions Click the right arrow to view the answers What is the command to edit your cronjobs? crontab -e What is the command to list your cronjobs? crontab -l","title":"Cron Jobs"},{"location":"process-utilization/cron-jobs/#cron-jobs","text":"Although we have been talking about resource utilization, I think this would be a good point to mention a neat tool in Linux that is used to schedule tasks using cron. There is a service that runs programs for you at whatever time you schedule. This is a really useful if you have a script you want to run once a day that needs to execute something for you. For example, let's say I have a script located in /home/mo/scripts/change_wallpaper. I use this script every morning to change the picture I use for my wallpaper, but each morning I have to manually execute this script. Instead what I can do is create a cron job that executes my script through cron. I can specify the time I want this cron job to run and execute my script. 30 08 * * * /home/mo/scripts/change_wallpaper The fields are as follows from left to right: Minute - (0-59) Hour - (0-23) Day of the month - (1-31) Month - (1-12) Day of the week - (0-7). 0 and 7 are denoted as Sunday The asterisk in the field means to match every value. So in my above example, I want this to run every day in every month at 8:30am. To create a cronjob, just edit the crontab file: crontab -e","title":"Cron Jobs"},{"location":"process-utilization/cron-jobs/#exercise","text":"Create a cronjob that you want to run at a scheduled time.","title":"Exercise"},{"location":"process-utilization/cron-jobs/#quiz-questions","text":"Click the right arrow to view the answers What is the command to edit your cronjobs? crontab -e What is the command to list your cronjobs? crontab -l","title":"Quiz Questions"},{"location":"process-utilization/io-monitoring/","text":"I/O Monitoring We can also monitor CPU usage as well as monitor disk usage with a handy tool known as iostat mo:~$ iostat Linux 3.13.0-39-lowlatency (icebox) 01/28/2016 _i686_ (1 CPU) avg-cpu: %user %nice %system %iowait %steal %idle 0.13 0.03 0.50 0.01 0.00 99.33 Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtn sda 0.17 3.49 1.92 385106 212417 The first part is the CPU information: %user - Show the percentage of CPU utilization that occurred while executing at the user level (application) %nice - Show the percentage of CPU utilization that occurred while executing at the user level with nice priority.user CPU utilization with nice priorities %system - Show the percentage of CPU utilization that occurred while executing at the system level (kernel). %iowait - Show the percentage of time that the CPU or CPUs were idle during which the system had an outstanding disk I/O request. %steal - Show the percentage of time spent in involuntary wait by the virtual CPU or CPUs while the hypervisor was servicing another virtual processor. %idle - Show the percentage of time that the CPU or CPUs were idle and the system did not have an outstanding disk I/O request. The second part is the disk utilization: tps - Indicate the number of transfers per second that were issued to the device. A transfer is an I/O request to the device. Multiple logical requests can be combined into a single I/O request to the device. A transfer is of indeterminate size. kB_read/s - Indicate the amount of data read from the device expressed in kilobytes per second. kB_wrtn/s - Indicate the amount of data written to the device expressed in kilobytes per second. kB_read - The total number of kilobytes read. kB_wrtn - The total number of kilobytes written. Exercise Use iostat to view your disk usage. Quiz Questions Click the right arrow to view the answers What command can be used to view I/O and CPU usage? iostat","title":"I/O Monitoring"},{"location":"process-utilization/io-monitoring/#io-monitoring","text":"We can also monitor CPU usage as well as monitor disk usage with a handy tool known as iostat mo:~$ iostat Linux 3.13.0-39-lowlatency (icebox) 01/28/2016 _i686_ (1 CPU) avg-cpu: %user %nice %system %iowait %steal %idle 0.13 0.03 0.50 0.01 0.00 99.33 Device: tps kB_read/s kB_wrtn/s kB_read kB_wrtn sda 0.17 3.49 1.92 385106 212417 The first part is the CPU information: %user - Show the percentage of CPU utilization that occurred while executing at the user level (application) %nice - Show the percentage of CPU utilization that occurred while executing at the user level with nice priority.user CPU utilization with nice priorities %system - Show the percentage of CPU utilization that occurred while executing at the system level (kernel). %iowait - Show the percentage of time that the CPU or CPUs were idle during which the system had an outstanding disk I/O request. %steal - Show the percentage of time spent in involuntary wait by the virtual CPU or CPUs while the hypervisor was servicing another virtual processor. %idle - Show the percentage of time that the CPU or CPUs were idle and the system did not have an outstanding disk I/O request. The second part is the disk utilization: tps - Indicate the number of transfers per second that were issued to the device. A transfer is an I/O request to the device. Multiple logical requests can be combined into a single I/O request to the device. A transfer is of indeterminate size. kB_read/s - Indicate the amount of data read from the device expressed in kilobytes per second. kB_wrtn/s - Indicate the amount of data written to the device expressed in kilobytes per second. kB_read - The total number of kilobytes read. kB_wrtn - The total number of kilobytes written.","title":"I/O Monitoring"},{"location":"process-utilization/io-monitoring/#exercise","text":"Use iostat to view your disk usage.","title":"Exercise"},{"location":"process-utilization/io-monitoring/#quiz-questions","text":"Click the right arrow to view the answers What command can be used to view I/O and CPU usage? iostat","title":"Quiz Questions"},{"location":"process-utilization/memory-monitoring/","text":"Memory Monitoring In addition to CPU monitoring and I/O monitoring you can monitor your memory usage with vmstat mo:~$ vmstat procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 0 396528 38816 384036 0 0 4 2 38 79 0 0 99 0 0 The fields are as follows: procs r - Number of processes for run time b - Number of processes in uninterruptible sleep memory swpd - Amount of virtual memory used free - Amount of free memory buff - Amount of memory used as buffers cache - Amount of memory used as cache swap si - Amount of memory swapped in from disk so - Amount of memory swapped out to disk io bi - Amount of blocks received in from a block device bo - Amount of blocks sent out to a block device system in - Number of interrupts per second cs - Number of context switches per second cpu us - Time spent in user time sy - Time spent in kernel time id - Time spent idle wa - Time spent waiting for IO Exercise Look at your memory usage with vmstat. Quiz Questions Click the right arrow to view the answers What tool is used to view memory utilization? vmstat","title":"Memory Monitoring"},{"location":"process-utilization/memory-monitoring/#memory-monitoring","text":"In addition to CPU monitoring and I/O monitoring you can monitor your memory usage with vmstat mo:~$ vmstat procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu----- r b swpd free buff cache si so bi bo in cs us sy id wa st 1 0 0 396528 38816 384036 0 0 4 2 38 79 0 0 99 0 0 The fields are as follows: procs r - Number of processes for run time b - Number of processes in uninterruptible sleep memory swpd - Amount of virtual memory used free - Amount of free memory buff - Amount of memory used as buffers cache - Amount of memory used as cache swap si - Amount of memory swapped in from disk so - Amount of memory swapped out to disk io bi - Amount of blocks received in from a block device bo - Amount of blocks sent out to a block device system in - Number of interrupts per second cs - Number of context switches per second cpu us - Time spent in user time sy - Time spent in kernel time id - Time spent idle wa - Time spent waiting for IO","title":"Memory Monitoring"},{"location":"process-utilization/memory-monitoring/#exercise","text":"Look at your memory usage with vmstat.","title":"Exercise"},{"location":"process-utilization/memory-monitoring/#quiz-questions","text":"Click the right arrow to view the answers What tool is used to view memory utilization? vmstat","title":"Quiz Questions"},{"location":"process-utilization/process-threads/","text":"Process Threads You may have heard of the terms single-threaded and multi-threaded processes. Threads are very similar to processes, in that they are used to execute the same program, they are often referred to as lightweight processes. If a process has one thread it is single-threaded and if a process has more than one thread it is multi-threaded. However, all processes have at least one thread. Processes operate with their own isolated system resources, however threads can share these resources among each other easily, making it easier for them to communicate among each other and at times it is more efficient to have a multi-threaded application than a multi-process application. Basically, let's say you open up LibreOffice Writer and Chrome, each is it's own separate process. Now you go inside Writer and start editing text, when you edit the text it gets automatically saved. These two parallel \"lightweight processes\" of saving and editing are threads. To view process threads, you can use: mo:~$ ps m PID TTY STAT TIME COMMAND 2207 pts/2 - 0:01 bash - - Ss 0:01 - 5252 pts/2 - 0:00 ps m - - R+ 0:00 - The processes are denoted with each PID and underneath the processes are their threads (denoted by a --). So you can see that the processes above are both single-threaded. Exercise Run the ps m command and see what processes you have running are multi-threaded. Quiz Questions Click the right arrow to view the answers True or false, all processes start out single-threaded. True","title":"Process Threads"},{"location":"process-utilization/process-threads/#process-threads","text":"You may have heard of the terms single-threaded and multi-threaded processes. Threads are very similar to processes, in that they are used to execute the same program, they are often referred to as lightweight processes. If a process has one thread it is single-threaded and if a process has more than one thread it is multi-threaded. However, all processes have at least one thread. Processes operate with their own isolated system resources, however threads can share these resources among each other easily, making it easier for them to communicate among each other and at times it is more efficient to have a multi-threaded application than a multi-process application. Basically, let's say you open up LibreOffice Writer and Chrome, each is it's own separate process. Now you go inside Writer and start editing text, when you edit the text it gets automatically saved. These two parallel \"lightweight processes\" of saving and editing are threads. To view process threads, you can use: mo:~$ ps m PID TTY STAT TIME COMMAND 2207 pts/2 - 0:01 bash - - Ss 0:01 - 5252 pts/2 - 0:00 ps m - - R+ 0:00 - The processes are denoted with each PID and underneath the processes are their threads (denoted by a --). So you can see that the processes above are both single-threaded.","title":"Process Threads"},{"location":"process-utilization/process-threads/#exercise","text":"Run the ps m command and see what processes you have running are multi-threaded.","title":"Exercise"},{"location":"process-utilization/process-threads/#quiz-questions","text":"Click the right arrow to view the answers True or false, all processes start out single-threaded. True","title":"Quiz Questions"},{"location":"process-utilization/tracking-processes-lsof/","text":"lsof and fuser Let's say you plugged in a USB drive and starting working on some files, once you were done, you go and unmount the USB device and you're getting an error \"Device or Resource Busy\". How would you find out which files in the USB drive are still in use? There are actually two tools you can use for this: lsof Remember files aren't just text files, images, etc, they are everything on the system, disks, pipes, network sockets, devices, etc. To see what is in use by a process, you can use the lsof command (short for \"list open files\") this will show you a list of all the open files and their associated process. mo:~$ lsof . COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME lxsession 1491 mo cwd DIR 8,6 4096 131 . update-no 1796 mo cwd DIR 8,6 4096 131 . nm-applet 1804 mo cwd DIR 8,6 4096 131 . indicator 1809 mo cwd DIR 8,6 4096 131 . xterm 2205 mo cwd DIR 8,6 4096 131 . bash 2207 mo cwd DIR 8,6 4096 131 . lsof 5914 mo cwd DIR 8,6 4096 131 . lsof 5915 mo cwd DIR 8,6 4096 131 . Now I can see what processes are currently holding the device/file open. In our USB example, you can also kill these processes so we can unmount this pesky drive. fuser Another way to track a process is the fuser command (short for \"file user\"), this will show you information about the process that is using the file or the file user. mo:~$ fuser -v . USER PID ACCESS COMMAND /home/mo: mo 1491 ..c.. lxsession mo 1796 ..c.. update-notifier mo 1804 ..c.. nm-applet mo 1809 ..c.. indicator-power mo 2205 ..c.. xterm mo 2207 ..c.. bash We can see which processes are currently using our /home/mo directory. The lsof and fuser tools are very similar, familiarize yourself with these tools and try using them next time you need to track a file or process down. Exercise Read the manpages for lsof and fuser, there is a lot of information that we didn't cover that allows you to have greater flexibility with these tools. Quiz Questions Click the right arrow to view the answers What command is used to list open files and their process information? lsof","title":"Tracking Processes lsof"},{"location":"process-utilization/tracking-processes-lsof/#lsof-and-fuser","text":"Let's say you plugged in a USB drive and starting working on some files, once you were done, you go and unmount the USB device and you're getting an error \"Device or Resource Busy\". How would you find out which files in the USB drive are still in use? There are actually two tools you can use for this: lsof Remember files aren't just text files, images, etc, they are everything on the system, disks, pipes, network sockets, devices, etc. To see what is in use by a process, you can use the lsof command (short for \"list open files\") this will show you a list of all the open files and their associated process. mo:~$ lsof . COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME lxsession 1491 mo cwd DIR 8,6 4096 131 . update-no 1796 mo cwd DIR 8,6 4096 131 . nm-applet 1804 mo cwd DIR 8,6 4096 131 . indicator 1809 mo cwd DIR 8,6 4096 131 . xterm 2205 mo cwd DIR 8,6 4096 131 . bash 2207 mo cwd DIR 8,6 4096 131 . lsof 5914 mo cwd DIR 8,6 4096 131 . lsof 5915 mo cwd DIR 8,6 4096 131 . Now I can see what processes are currently holding the device/file open. In our USB example, you can also kill these processes so we can unmount this pesky drive. fuser Another way to track a process is the fuser command (short for \"file user\"), this will show you information about the process that is using the file or the file user. mo:~$ fuser -v . USER PID ACCESS COMMAND /home/mo: mo 1491 ..c.. lxsession mo 1796 ..c.. update-notifier mo 1804 ..c.. nm-applet mo 1809 ..c.. indicator-power mo 2205 ..c.. xterm mo 2207 ..c.. bash We can see which processes are currently using our /home/mo directory. The lsof and fuser tools are very similar, familiarize yourself with these tools and try using them next time you need to track a file or process down.","title":"lsof and fuser"},{"location":"process-utilization/tracking-processes-lsof/#exercise","text":"Read the manpages for lsof and fuser, there is a lot of information that we didn't cover that allows you to have greater flexibility with these tools.","title":"Exercise"},{"location":"process-utilization/tracking-processes-lsof/#quiz-questions","text":"Click the right arrow to view the answers What command is used to list open files and their process information? lsof","title":"Quiz Questions"},{"location":"process-utilization/tracking-processes-top/","text":"Tracking processes: top In this course, we'll go over how to read and analyze the resource utilization on your system, this lesson shows some great tools to use when you need to track what a process is doing. top We've discussed top before, but we're going to dig into the specifics of what it's actually displaying. Remember top is the tool we used to get a real time view of the system utilization by our processes: top - 18:06:26 up 6 days, 4:07, 2 users, load average: 0.92, 0.62, 0.59 Tasks: 389 total, 1 running, 387 sleeping, 0 stopped, 1 zombie %Cpu(s): 1.8 us, 0.4 sy, 0.0 ni, 97.6 id, 0.1 wa, 0.0 hi, 0.0 si, 0.0 st KiB Mem: 32870888 total, 27467976 used, 5402912 free, 518808 buffers KiB Swap: 33480700 total, 39892 used, 33440808 free. 19454152 cached Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 6675 mo 20 0 1731472 520960 30876 S 8.3 1.6 160:24.79 chrome 6926 mo 20 0 935888 163456 25576 S 4.3 0.5 5:28.13 chrome Let's go over what this output means, you don't have to memorize this, but come back to this when you need a reference. 1st line: This is the same information you would see if you ran the uptime command (more to come) The fields are from left to right: Current time How long the system has been running How many users are currently logged on System load average (more to come) 2nd line: Tasks that are running, sleeping, stopped and zombied 3rd line: Cpu information us: user CPU time - Percentage of CPU time spent running users\u2019 processes that aren\u2019t niced. sy: system CPU time - Percentage of CPU time spent running the kernel and kernel processes ni: nice CPU time - Percentage of CPU time spent running niced processes id: CPU idle time - Percentage of CPU time that is spent idle wa: I/O wait - Percentage of CPU time that is spent waiting for I/O. If this value is low, the problem probably isn\u2019t disk or network I/O hi: hardware interrupts - Percentage of CPU time spent serving hardware interrupts si: software interrupts - Percentage of CPU time spent serving software interrupts st: steal time - If you are running virtual machines, this is the percentage of CPU time that was stolen from you for other tasks 4th and 5th line: Memory Usage and Swap Usage Processes List that are Currently in Use PID: Id of the process USER: user that is the owner of the process PR: Priority of process NI: The nice value VIRT: Virtual memory used by the process RES: Physical memory used from the process SHR: Shared memory of the process S: Indicates the status of the process: S=sleep, R=running, Z=zombie,D=uninterruptible,T=stopped %CPU - this is the percent of CPU used by this process %MEM - percentage of RAM used by this process TIME+ - total time of activity of this process COMMAND - name of the process You can also specify a process ID if you just want to track certain processes: $ top -p 1 Exercise Play around with the top command and see what processes are using the most resources. Quiz Questions Click the right arrow to view the answers What command displays the same output as the first line in top? uptime","title":"Tracking Processes top"},{"location":"process-utilization/tracking-processes-top/#tracking-processes-top","text":"In this course, we'll go over how to read and analyze the resource utilization on your system, this lesson shows some great tools to use when you need to track what a process is doing. top We've discussed top before, but we're going to dig into the specifics of what it's actually displaying. Remember top is the tool we used to get a real time view of the system utilization by our processes: top - 18:06:26 up 6 days, 4:07, 2 users, load average: 0.92, 0.62, 0.59 Tasks: 389 total, 1 running, 387 sleeping, 0 stopped, 1 zombie %Cpu(s): 1.8 us, 0.4 sy, 0.0 ni, 97.6 id, 0.1 wa, 0.0 hi, 0.0 si, 0.0 st KiB Mem: 32870888 total, 27467976 used, 5402912 free, 518808 buffers KiB Swap: 33480700 total, 39892 used, 33440808 free. 19454152 cached Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 6675 mo 20 0 1731472 520960 30876 S 8.3 1.6 160:24.79 chrome 6926 mo 20 0 935888 163456 25576 S 4.3 0.5 5:28.13 chrome Let's go over what this output means, you don't have to memorize this, but come back to this when you need a reference. 1st line: This is the same information you would see if you ran the uptime command (more to come) The fields are from left to right: Current time How long the system has been running How many users are currently logged on System load average (more to come) 2nd line: Tasks that are running, sleeping, stopped and zombied 3rd line: Cpu information us: user CPU time - Percentage of CPU time spent running users\u2019 processes that aren\u2019t niced. sy: system CPU time - Percentage of CPU time spent running the kernel and kernel processes ni: nice CPU time - Percentage of CPU time spent running niced processes id: CPU idle time - Percentage of CPU time that is spent idle wa: I/O wait - Percentage of CPU time that is spent waiting for I/O. If this value is low, the problem probably isn\u2019t disk or network I/O hi: hardware interrupts - Percentage of CPU time spent serving hardware interrupts si: software interrupts - Percentage of CPU time spent serving software interrupts st: steal time - If you are running virtual machines, this is the percentage of CPU time that was stolen from you for other tasks 4th and 5th line: Memory Usage and Swap Usage Processes List that are Currently in Use PID: Id of the process USER: user that is the owner of the process PR: Priority of process NI: The nice value VIRT: Virtual memory used by the process RES: Physical memory used from the process SHR: Shared memory of the process S: Indicates the status of the process: S=sleep, R=running, Z=zombie,D=uninterruptible,T=stopped %CPU - this is the percent of CPU used by this process %MEM - percentage of RAM used by this process TIME+ - total time of activity of this process COMMAND - name of the process You can also specify a process ID if you just want to track certain processes: $ top -p 1","title":"Tracking processes: top"},{"location":"process-utilization/tracking-processes-top/#exercise","text":"Play around with the top command and see what processes are using the most resources.","title":"Exercise"},{"location":"process-utilization/tracking-processes-top/#quiz-questions","text":"Click the right arrow to view the answers What command displays the same output as the first line in top? uptime","title":"Quiz Questions"},{"location":"processes/controlling-terminal/","text":"Controlling Terminal We discussed how there is a TTY field in the ps output. The TTY is the terminal that executed the command. There are two types of terminals, regular terminal devices and pseudoterminal devices . A regular terminal device is a native terminal device that you can type into and send output to your system, this sounds like the terminal application you've been launching to get to your shell, but it's not. We're gonna segue so you can see this action, go ahead and type Ctrl-Alt-F1 to get into TTY1 (the first virtual console), you'll notice how you don't have anything except the terminal, no graphics, etc. This is considered a regular terminal device, you can exit this with Ctrl-Alt-F7. A pseudoterminal is what you've been used to working in, they emulate terminals with the shell terminal window and are denoted by PTS . If you look at ps again, you'll see your shell process under pts/*. Ok, now circling back to the controlling terminal, processes are usually bound to a controlling terminal. For example, if you were running a program on your shell window such as find and you closed the window, your process would also go with it. There are processes such as daemon processes, which are special processes that are essentially keeping the system running. They often start at system boot and usually get terminated when the system is shutdown. They run in the background and since we don't want these special processes to get terminated they are not bound to a controlling terminal. In the ps output, the TTY is listed as a ? meaning it does not have a controlling terminal. Exercise Look at your ps output and list all the unique TTY values. Quiz Questions Click the right arrow to view the answers What value is given for a process that does not have a controlling terminal? ?","title":"Controlling Terminal"},{"location":"processes/controlling-terminal/#controlling-terminal","text":"We discussed how there is a TTY field in the ps output. The TTY is the terminal that executed the command. There are two types of terminals, regular terminal devices and pseudoterminal devices . A regular terminal device is a native terminal device that you can type into and send output to your system, this sounds like the terminal application you've been launching to get to your shell, but it's not. We're gonna segue so you can see this action, go ahead and type Ctrl-Alt-F1 to get into TTY1 (the first virtual console), you'll notice how you don't have anything except the terminal, no graphics, etc. This is considered a regular terminal device, you can exit this with Ctrl-Alt-F7. A pseudoterminal is what you've been used to working in, they emulate terminals with the shell terminal window and are denoted by PTS . If you look at ps again, you'll see your shell process under pts/*. Ok, now circling back to the controlling terminal, processes are usually bound to a controlling terminal. For example, if you were running a program on your shell window such as find and you closed the window, your process would also go with it. There are processes such as daemon processes, which are special processes that are essentially keeping the system running. They often start at system boot and usually get terminated when the system is shutdown. They run in the background and since we don't want these special processes to get terminated they are not bound to a controlling terminal. In the ps output, the TTY is listed as a ? meaning it does not have a controlling terminal.","title":"Controlling Terminal"},{"location":"processes/controlling-terminal/#exercise","text":"Look at your ps output and list all the unique TTY values.","title":"Exercise"},{"location":"processes/controlling-terminal/#quiz-questions","text":"Click the right arrow to view the answers What value is given for a process that does not have a controlling terminal? ?","title":"Quiz Questions"},{"location":"processes/job-control/","text":"Job Control Let's say you're working on a single terminal window and you're running a command that is taking forever. You can't interact with the shell until it is complete, however we want to keep working on our machines, so we need that shell open. Fortunately we can control how our processes run with jobs: Sending a job to the background Appending an ampersand (&) to the command will run it in the background so you can still use your shell. Let's see an example: $ sleep 1000 & $ sleep 1001 & $ sleep 1002 & View all background jobs Now you can view the jobs you just sent to the background. $ jobs [1] Running sleep 1000 & [2]- Running sleep 1001 & [3]+ Running sleep 1002 & This will show you the job id in the first column, then the status and the command that was run. The + next to the job ID means that it is the most recent background job that started. The job with the - is the second most recent command. Sending a job to the background on existing job If you already ran a job and want to send it to the background, you don't have to terminate it and start over again. First suspend the job with Ctrl-Z, then run the bg command to send it to the background. mo ~ $ sleep 1003 ^Z [4]+ Stopped sleep 1003 mo ~ $ bg [4]+ sleep 1003 & mo ~ $ jobs [1] Running sleep 1000 & [2] Running sleep 1001 & [3]- Running sleep 1002 & [4]+ Running sleep 1003 & Moving a job from the background to the foreground To move a job out of the background just specify the job ID you want. If you run fg without any options, it will bring back the most recent background job (the job with the + sign next to it) $ fg %1 Kill background jobs Similar to moving jobs out of the background, you can use the same form to kill the processes by using their Job ID. kill %1 Exercise Move some jobs between the background and the foreground Quiz Questions Click the right arrow to view the answers What command is used to list background jobs? jobs","title":"Job Control"},{"location":"processes/job-control/#job-control","text":"Let's say you're working on a single terminal window and you're running a command that is taking forever. You can't interact with the shell until it is complete, however we want to keep working on our machines, so we need that shell open. Fortunately we can control how our processes run with jobs: Sending a job to the background Appending an ampersand (&) to the command will run it in the background so you can still use your shell. Let's see an example: $ sleep 1000 & $ sleep 1001 & $ sleep 1002 & View all background jobs Now you can view the jobs you just sent to the background. $ jobs [1] Running sleep 1000 & [2]- Running sleep 1001 & [3]+ Running sleep 1002 & This will show you the job id in the first column, then the status and the command that was run. The + next to the job ID means that it is the most recent background job that started. The job with the - is the second most recent command. Sending a job to the background on existing job If you already ran a job and want to send it to the background, you don't have to terminate it and start over again. First suspend the job with Ctrl-Z, then run the bg command to send it to the background. mo ~ $ sleep 1003 ^Z [4]+ Stopped sleep 1003 mo ~ $ bg [4]+ sleep 1003 & mo ~ $ jobs [1] Running sleep 1000 & [2] Running sleep 1001 & [3]- Running sleep 1002 & [4]+ Running sleep 1003 & Moving a job from the background to the foreground To move a job out of the background just specify the job ID you want. If you run fg without any options, it will bring back the most recent background job (the job with the + sign next to it) $ fg %1 Kill background jobs Similar to moving jobs out of the background, you can use the same form to kill the processes by using their Job ID. kill %1","title":"Job Control"},{"location":"processes/job-control/#exercise","text":"Move some jobs between the background and the foreground","title":"Exercise"},{"location":"processes/job-control/#quiz-questions","text":"Click the right arrow to view the answers What command is used to list background jobs? jobs","title":"Quiz Questions"},{"location":"processes/killing-processes/","text":"Kill (Terminate) You can send signals that terminate processes, such a command is aptly named the kill command. $ kill 12445 The 12445 is the PID of the process you want to kill. By default it sends a TERM signal. The SIGTERM signal is sent to a process to request its termination by allowing it to cleanly release its resources and saving its state. You can also specify a signal with the kill command: $ kill -9 12445 This will run the SIGKILL signal and kill the process. Differences between SIGHUP, SIGINT, SIGTERM, SIGKILL, SIGSTOP? These signals all sound reasonably similar, but they do have their differences. SIGHUP - Hangup, sent to a process when the controlling terminal is closed. For example, if you closed a terminal window that had a process running in it, you would get a SIGHUP signal. So basically you've been hung up on SIGINT - Is an interrupt signal, so you can use Ctrl-C and the system will try to gracefully kill the process SIGTERM - Kill the process, but allow it to do some cleanup first SIGKILL - Kill the process, kill it with fire, doesn't do any cleanup SIGSTOP - Stop/suspend a process Exercise Kill some processes using different signals. Quiz Questions Click the right arrow to view the answers What is the signal name for the default kill command? SIGTERM","title":"Killing processes"},{"location":"processes/killing-processes/#kill-terminate","text":"You can send signals that terminate processes, such a command is aptly named the kill command. $ kill 12445 The 12445 is the PID of the process you want to kill. By default it sends a TERM signal. The SIGTERM signal is sent to a process to request its termination by allowing it to cleanly release its resources and saving its state. You can also specify a signal with the kill command: $ kill -9 12445 This will run the SIGKILL signal and kill the process. Differences between SIGHUP, SIGINT, SIGTERM, SIGKILL, SIGSTOP? These signals all sound reasonably similar, but they do have their differences. SIGHUP - Hangup, sent to a process when the controlling terminal is closed. For example, if you closed a terminal window that had a process running in it, you would get a SIGHUP signal. So basically you've been hung up on SIGINT - Is an interrupt signal, so you can use Ctrl-C and the system will try to gracefully kill the process SIGTERM - Kill the process, but allow it to do some cleanup first SIGKILL - Kill the process, kill it with fire, doesn't do any cleanup SIGSTOP - Stop/suspend a process","title":"Kill (Terminate)"},{"location":"processes/killing-processes/#exercise","text":"Kill some processes using different signals.","title":"Exercise"},{"location":"processes/killing-processes/#quiz-questions","text":"Click the right arrow to view the answers What is the signal name for the default kill command? SIGTERM","title":"Quiz Questions"},{"location":"processes/proc-filesystem/","text":"/proc filesystem Remember everything in Linux is a file, even processes. Process information is stored in a special filesystem known as the /proc filesystem. $ ls /proc You should see multiple values in here, there are sub-directories for every PID. If you looked at a PID in the ps output, you would be able to find it in the /proc directory. Go ahead and enter one of the processes and look at that file: $ cat /proc/12345/status You should see process state information and well as more detailed information. The /proc directory is how the kernel is views the system, so there is a lot more information here than what you would see in ps. Quiz Questions Click the right arrow to view the answers What filesystem stores process information? /proc","title":"Proc Filesystem"},{"location":"processes/proc-filesystem/#proc-filesystem","text":"Remember everything in Linux is a file, even processes. Process information is stored in a special filesystem known as the /proc filesystem. $ ls /proc You should see multiple values in here, there are sub-directories for every PID. If you looked at a PID in the ps output, you would be able to find it in the /proc directory. Go ahead and enter one of the processes and look at that file: $ cat /proc/12345/status You should see process state information and well as more detailed information. The /proc directory is how the kernel is views the system, so there is a lot more information here than what you would see in ps.","title":"/proc filesystem"},{"location":"processes/proc-filesystem/#quiz-questions","text":"Click the right arrow to view the answers What filesystem stores process information? /proc","title":"Quiz Questions"},{"location":"processes/process-creation/","text":"Process Creation Again this lesson and the next are purely information to let you see what's under the hood, feel free to circle back to this once you've worked with processes a bit more. When a new process is created, an existing process basically clones itself using something called the fork system call (system calls will be discussed very far into the future). The fork system call creates a mostly identical child process, this child process takes on a new process ID (PID) and the original process becomes its parent process and has something called a parent process ID PPID . Afterwards, the child process can either continue to use the same program its parent was using before or more often use the execve system call to launch up a new program. This system call destroys the memory management that the kernel put into place for that process and sets up new ones for the new program. We can see this in action: $ ps l The l option gives us a \"long format\" or even more detailed view of our running processes. You'll see a column labelled PPID , this is the parent ID. Now look at your terminal, you'll see a process running that is your shell, so on my system I have a process running bash. Now remember when you ran the ps l command, you were running it from the process that was running bash. Now you'll see that the PID of the bash shell is the PPID of the ps l command. So if every process has to have a parent and they are just forks of each other, there must be a mother of all processes right? You are correct, when the system boots up, the kernels creates a process called init , it has a PID of 1. The init process can't be terminated unless the system shuts down. It runs with root privileges and runs many processes that keep the system running. We will take a closer look at init in the system bootup course, for now just know it is the process that spawns all other processes. Exercise Take a look at your running processes, can you see what other processes have parents? Quiz Questions Click the right arrow to view the answers What system call creates a new process? fork","title":"Process Creation"},{"location":"processes/process-creation/#process-creation","text":"Again this lesson and the next are purely information to let you see what's under the hood, feel free to circle back to this once you've worked with processes a bit more. When a new process is created, an existing process basically clones itself using something called the fork system call (system calls will be discussed very far into the future). The fork system call creates a mostly identical child process, this child process takes on a new process ID (PID) and the original process becomes its parent process and has something called a parent process ID PPID . Afterwards, the child process can either continue to use the same program its parent was using before or more often use the execve system call to launch up a new program. This system call destroys the memory management that the kernel put into place for that process and sets up new ones for the new program. We can see this in action: $ ps l The l option gives us a \"long format\" or even more detailed view of our running processes. You'll see a column labelled PPID , this is the parent ID. Now look at your terminal, you'll see a process running that is your shell, so on my system I have a process running bash. Now remember when you ran the ps l command, you were running it from the process that was running bash. Now you'll see that the PID of the bash shell is the PPID of the ps l command. So if every process has to have a parent and they are just forks of each other, there must be a mother of all processes right? You are correct, when the system boots up, the kernels creates a process called init , it has a PID of 1. The init process can't be terminated unless the system shuts down. It runs with root privileges and runs many processes that keep the system running. We will take a closer look at init in the system bootup course, for now just know it is the process that spawns all other processes.","title":"Process Creation"},{"location":"processes/process-creation/#exercise","text":"Take a look at your running processes, can you see what other processes have parents?","title":"Exercise"},{"location":"processes/process-creation/#quiz-questions","text":"Click the right arrow to view the answers What system call creates a new process? fork","title":"Quiz Questions"},{"location":"processes/process-details/","text":"Process Details Before we get into more practical applications of processes, we have to first understand what they are and how they work. This part can get confusing since we are diving into the nitty gritty, so feel free to come back to this lesson if you don't want to learn about it now. A process like we said before is a running program on the system, more precisely it's the system allocating memory, CPU, I/O to make the program run. A process is an instance of a running program, go ahead and open 3 terminal windows, in two windows, run the cat command without passing any options (the cat process will stay open as a process because it expects stdin). Now in the third window run: ps aux | grep cat . You'll see that there are two processes for cat, even though they are calling the same program. The kernel is in charge of processes, when we run a program the kernel loads up the code of the program in memory, determines and allocates resources and then keeps tabs on each process, it knows: The status of the process The resources the process is using and receives The process owner Signal handling (more on that later) And basically everything else All processes are trying to get a taste of that sweet resource pie, it's the kernel's job to make sure that processes get the right amount of resources depending on process demands. When a process ends, the resources it used are now freed up for other processes. Quiz Questions Click the right arrow to view the answers What manages and controls processes? kernel","title":"Process Details"},{"location":"processes/process-details/#process-details","text":"Before we get into more practical applications of processes, we have to first understand what they are and how they work. This part can get confusing since we are diving into the nitty gritty, so feel free to come back to this lesson if you don't want to learn about it now. A process like we said before is a running program on the system, more precisely it's the system allocating memory, CPU, I/O to make the program run. A process is an instance of a running program, go ahead and open 3 terminal windows, in two windows, run the cat command without passing any options (the cat process will stay open as a process because it expects stdin). Now in the third window run: ps aux | grep cat . You'll see that there are two processes for cat, even though they are calling the same program. The kernel is in charge of processes, when we run a program the kernel loads up the code of the program in memory, determines and allocates resources and then keeps tabs on each process, it knows: The status of the process The resources the process is using and receives The process owner Signal handling (more on that later) And basically everything else All processes are trying to get a taste of that sweet resource pie, it's the kernel's job to make sure that processes get the right amount of resources depending on process demands. When a process ends, the resources it used are now freed up for other processes.","title":"Process Details"},{"location":"processes/process-details/#quiz-questions","text":"Click the right arrow to view the answers What manages and controls processes? kernel","title":"Quiz Questions"},{"location":"processes/process-niceness/","text":"Niceness When you run multiple things on your computer, like perhaps Chrome, Microsoft Word or Photoshop at the same time, it may seem like these processes are running at the same time, but that isn't quite true. Processes use the CPU for a small amount of time called a time slice. Then they pause for milliseconds and another process gets a little time slice. By default, process scheduling happens in this round-robin fashion. Every process gets enough time slices until it's finished processing. The kernel handles all of these switching of processes and it does a pretty good job at it most of the time. Processes aren't able to decide when and how long they get CPU time, if all processes behaved normally they would each (roughly) get an equal amount of CPU time. However, there is a way to influence the kernel's process scheduling algorithm with a nice value. Niceness is a pretty weird name, but what it means is that processes have a number to determine their priority for the CPU. A high number means the process is nice and has a lower priority for the CPU and a low or negative number means the process is not very nice and it wants to get as much of the CPU as possible. $ top You can see a column for NI right now, that is the niceness level of a process. To change the niceness level you can use the nice and renice commands: $ nice -n 5 apt upgrade The nice command is used to set priority for a new process. The renice command is used to set priority on an existing process. $ renice 10 -p 3245 Exercise What processes aren't very nice and why? Quiz Questions Click the right arrow to view the answers If I want a process to get more CPU priority, do I use a lower or higher nice number? lower","title":"Process Niceness"},{"location":"processes/process-niceness/#niceness","text":"When you run multiple things on your computer, like perhaps Chrome, Microsoft Word or Photoshop at the same time, it may seem like these processes are running at the same time, but that isn't quite true. Processes use the CPU for a small amount of time called a time slice. Then they pause for milliseconds and another process gets a little time slice. By default, process scheduling happens in this round-robin fashion. Every process gets enough time slices until it's finished processing. The kernel handles all of these switching of processes and it does a pretty good job at it most of the time. Processes aren't able to decide when and how long they get CPU time, if all processes behaved normally they would each (roughly) get an equal amount of CPU time. However, there is a way to influence the kernel's process scheduling algorithm with a nice value. Niceness is a pretty weird name, but what it means is that processes have a number to determine their priority for the CPU. A high number means the process is nice and has a lower priority for the CPU and a low or negative number means the process is not very nice and it wants to get as much of the CPU as possible. $ top You can see a column for NI right now, that is the niceness level of a process. To change the niceness level you can use the nice and renice commands: $ nice -n 5 apt upgrade The nice command is used to set priority for a new process. The renice command is used to set priority on an existing process. $ renice 10 -p 3245","title":"Niceness"},{"location":"processes/process-niceness/#exercise","text":"What processes aren't very nice and why?","title":"Exercise"},{"location":"processes/process-niceness/#quiz-questions","text":"Click the right arrow to view the answers If I want a process to get more CPU priority, do I use a lower or higher nice number? lower","title":"Quiz Questions"},{"location":"processes/process-signals/","text":"Signals A signal is a notification to a process that something has happened. Why we have signals They are software interrupts and they have lots of uses: A user can type one of the special terminal characters (Ctrl-C) or (Ctrl-Z) to kill, interrupt or suspend processes Hardware issues can occur and the kernel wants to notify the process Software issues can occur and the kernel wants to notify the process They are basically ways processes can communicate Signal process When a signal is generated by some event, it's then delivered to a process, it's considered in a pending state until it's delivered. When the process is ran, the signal will be delivered. However, processes have signal masks and they can set signal delivery to be blocked if specified. When a signal is delivered, a process can do a multitude of things: Ignore the signal \"Catch\" the signal and perform a specific handler routine Process can be terminated, as opposed to the normal exit system call Block the signal, depending on the signal mask Common signals Each signal is defined by integers with symbolic names that are in the form of SIGxxx. Some of the most common signals are: SIGHUP or HUP or 1: Hangup SIGINT or INT or 2: Interrupt SIGKILL or KILL or 9: Kill SIGSEGV or SEGV or 11: Segmentation fault SIGTERM or TERM or 15: Software termination SIGSTOP or STOP: Stop Numbers can vary with signals so they are usually referred by their names. Some signals are unblockable, one example is the SIGKILL signal. The KILL signal destroys the process. Quiz Questions Click the right arrow to view the answers What signal is unblockable? SIGKILL","title":"Process Signals"},{"location":"processes/process-signals/#signals","text":"A signal is a notification to a process that something has happened. Why we have signals They are software interrupts and they have lots of uses: A user can type one of the special terminal characters (Ctrl-C) or (Ctrl-Z) to kill, interrupt or suspend processes Hardware issues can occur and the kernel wants to notify the process Software issues can occur and the kernel wants to notify the process They are basically ways processes can communicate Signal process When a signal is generated by some event, it's then delivered to a process, it's considered in a pending state until it's delivered. When the process is ran, the signal will be delivered. However, processes have signal masks and they can set signal delivery to be blocked if specified. When a signal is delivered, a process can do a multitude of things: Ignore the signal \"Catch\" the signal and perform a specific handler routine Process can be terminated, as opposed to the normal exit system call Block the signal, depending on the signal mask Common signals Each signal is defined by integers with symbolic names that are in the form of SIGxxx. Some of the most common signals are: SIGHUP or HUP or 1: Hangup SIGINT or INT or 2: Interrupt SIGKILL or KILL or 9: Kill SIGSEGV or SEGV or 11: Segmentation fault SIGTERM or TERM or 15: Software termination SIGSTOP or STOP: Stop Numbers can vary with signals so they are usually referred by their names. Some signals are unblockable, one example is the SIGKILL signal. The KILL signal destroys the process.","title":"Signals"},{"location":"processes/process-signals/#quiz-questions","text":"Click the right arrow to view the answers What signal is unblockable? SIGKILL","title":"Quiz Questions"},{"location":"processes/process-states/","text":"Process States Let's take a look at the ps aux command again: $ ps aux In the STAT column, you'll see lots of values. A linux process can be in a number of different states. The most common state codes you'll see are described below: R: running or runnable, it is just waiting for the CPU to process it S: Interruptible sleep, waiting for an event to complete, such as input from the terminal D: Uninterruptible sleep, processes that cannot be killed or interrupted with a signal, usually to make them go away you have to reboot or fix the issue Z: Zombie, we discussed in a previous lesson that zombies are terminated processes that are waiting to have their statuses collected T: Stopped, a process that has been suspended/stopped Exercise Take a look at the running processes on your system and check out their process states. Quiz Questions Click the right arrow to view the answers What STAT code is used to represent an uninterruptible sleep? D","title":"Process States"},{"location":"processes/process-states/#process-states","text":"Let's take a look at the ps aux command again: $ ps aux In the STAT column, you'll see lots of values. A linux process can be in a number of different states. The most common state codes you'll see are described below: R: running or runnable, it is just waiting for the CPU to process it S: Interruptible sleep, waiting for an event to complete, such as input from the terminal D: Uninterruptible sleep, processes that cannot be killed or interrupted with a signal, usually to make them go away you have to reboot or fix the issue Z: Zombie, we discussed in a previous lesson that zombies are terminated processes that are waiting to have their statuses collected T: Stopped, a process that has been suspended/stopped","title":"Process States"},{"location":"processes/process-states/#exercise","text":"Take a look at the running processes on your system and check out their process states.","title":"Exercise"},{"location":"processes/process-states/#quiz-questions","text":"Click the right arrow to view the answers What STAT code is used to represent an uninterruptible sleep? D","title":"Quiz Questions"},{"location":"processes/process-termination/","text":"Process Termination Now that we know what goes on when a process gets created, what is happening when we don't need it anymore? Be forewarned, sometimes Linux can get a little dark... A process can exit using the _exit system call, this will free up the resources that process was using for reallocation. So when a process is ready to terminate, it lets the kernel know why it's terminating with something called a termination status. Most commonly a status of 0 means that the process succeeded. However, that's not enough to completely terminate a process. The parent process has to acknowledge the termination of the child process by using the wait system call and what this does is it checks the termination status of the child process. I know it's gruesome to think about, but the wait call is a necessity, after all what parent wouldn't want to know how their child died? There is another way to terminate a process and that involves using signals, which we will discuss soon. Orphan Processes When a parent process dies before a child process, the kernel knows that it's not going to get a wait call, so instead it makes these processes \"orphans\" and puts them under the care of init (remember mother of all processes). Init will eventually perform the wait system call for these orphans so they can die. Zombie Processes What happens when a child terminates and the parent process hasn't called wait yet? We still want to be able to see how a child process terminated, so even though the child process finished, the kernel turns the child process into a zombie process. The resources the child process used are still freed up for other processes, however there is still an entry in the process table for this zombie. Zombie processes also cannot be killed, since they are technically \"dead\", so you can't use signals to kill them. Eventually if the parent process calls the wait system call, the zombie will disappear, this is known as \"reaping\". If the parent doesn't perform a wait call, init will adopt the zombie and automatically perform wait and remove the zombie. It can be a bad thing to have too many zombie processes, since they take up space on the process table, if it fills up it will prevent other processes from running. Quiz Questions Click the right arrow to view the answers What is the most common termination status for a process succeeding? 0","title":"Process Termination"},{"location":"processes/process-termination/#process-termination","text":"Now that we know what goes on when a process gets created, what is happening when we don't need it anymore? Be forewarned, sometimes Linux can get a little dark... A process can exit using the _exit system call, this will free up the resources that process was using for reallocation. So when a process is ready to terminate, it lets the kernel know why it's terminating with something called a termination status. Most commonly a status of 0 means that the process succeeded. However, that's not enough to completely terminate a process. The parent process has to acknowledge the termination of the child process by using the wait system call and what this does is it checks the termination status of the child process. I know it's gruesome to think about, but the wait call is a necessity, after all what parent wouldn't want to know how their child died? There is another way to terminate a process and that involves using signals, which we will discuss soon. Orphan Processes When a parent process dies before a child process, the kernel knows that it's not going to get a wait call, so instead it makes these processes \"orphans\" and puts them under the care of init (remember mother of all processes). Init will eventually perform the wait system call for these orphans so they can die. Zombie Processes What happens when a child terminates and the parent process hasn't called wait yet? We still want to be able to see how a child process terminated, so even though the child process finished, the kernel turns the child process into a zombie process. The resources the child process used are still freed up for other processes, however there is still an entry in the process table for this zombie. Zombie processes also cannot be killed, since they are technically \"dead\", so you can't use signals to kill them. Eventually if the parent process calls the wait system call, the zombie will disappear, this is known as \"reaping\". If the parent doesn't perform a wait call, init will adopt the zombie and automatically perform wait and remove the zombie. It can be a bad thing to have too many zombie processes, since they take up space on the process table, if it fills up it will prevent other processes from running.","title":"Process Termination"},{"location":"processes/process-termination/#quiz-questions","text":"Click the right arrow to view the answers What is the most common termination status for a process succeeding? 0","title":"Quiz Questions"},{"location":"processes/ps-command/","text":"ps (Processes) Processes are the programs that are running on your machine. They are managed by the kernel and each process has an ID associated with it called the process ID (PID). This PID is assigned in the order that processes are created. Go ahead and run the ps command to see a list of running processes: $ ps PID TTY STAT TIME CMD 41230 pts/4 Ss 00:00:00 bash 51224 pts/4 R+ 00:00:00 ps This shows you a quick snapshot of the current processes: PID: Process ID TTY: Controlling terminal associated with the process (we'll go in detail about this later) STAT: Process status code TIME: Total CPU usage time CMD: Name of executable/command If you look at the man page for ps you'll see that there are lots of command options you can pass, they will vary depending on what options you want to use - BSD, GNU or Unix. In my opinion the BSD style is more popular to use, so we're gonna go with that. If you are curious the difference between the styles is the amount of dashes you use and the flags. $ ps aux The a displays all processes running, including the ones being ran by other users. The u shows more details about the processes. And finally the x lists all processes that don't have a TTY associated with it, these programs will show a ? in the TTY field, they are most common in daemon processes that launch as part of the system startup. You'll notice you're seeing a lot more fields now, no need to memorize them all, in a later course on advanced processes, we'll go over some of these again: USER: The effective user (the one whose access we are using) PID: Process ID %CPU: CPU time used divided by the time the process has been running %MEM: Ratio of the process's resident set size to the physical memory on the machine VSZ: Virtual memory usage of the entire process RSS: Resident set size, the non-swapped physical memory that a task has used TTY: Controlling terminal associated with the process STAT: Process status code START: Start time of the process TIME: Total CPU usage time COMMAND: Name of executable/command The ps command can get a little messy to look at, for now the fields we will look at the most are PID, STAT and COMMAND. Another very useful command is the top command, top gives you real time information about the processes running on your system instead of a snapshot. By default you'll get a refresh every 10 seconds. Top is an extremely useful tool to see what processes are taking up a lot of your resources. $ top Exercise Use the ps command with different flags and see how the output changes. Quiz Questions Click the right arrow to view the answers What ps flag is used to view detailed information about processes? u","title":"Ps command"},{"location":"processes/ps-command/#ps-processes","text":"Processes are the programs that are running on your machine. They are managed by the kernel and each process has an ID associated with it called the process ID (PID). This PID is assigned in the order that processes are created. Go ahead and run the ps command to see a list of running processes: $ ps PID TTY STAT TIME CMD 41230 pts/4 Ss 00:00:00 bash 51224 pts/4 R+ 00:00:00 ps This shows you a quick snapshot of the current processes: PID: Process ID TTY: Controlling terminal associated with the process (we'll go in detail about this later) STAT: Process status code TIME: Total CPU usage time CMD: Name of executable/command If you look at the man page for ps you'll see that there are lots of command options you can pass, they will vary depending on what options you want to use - BSD, GNU or Unix. In my opinion the BSD style is more popular to use, so we're gonna go with that. If you are curious the difference between the styles is the amount of dashes you use and the flags. $ ps aux The a displays all processes running, including the ones being ran by other users. The u shows more details about the processes. And finally the x lists all processes that don't have a TTY associated with it, these programs will show a ? in the TTY field, they are most common in daemon processes that launch as part of the system startup. You'll notice you're seeing a lot more fields now, no need to memorize them all, in a later course on advanced processes, we'll go over some of these again: USER: The effective user (the one whose access we are using) PID: Process ID %CPU: CPU time used divided by the time the process has been running %MEM: Ratio of the process's resident set size to the physical memory on the machine VSZ: Virtual memory usage of the entire process RSS: Resident set size, the non-swapped physical memory that a task has used TTY: Controlling terminal associated with the process STAT: Process status code START: Start time of the process TIME: Total CPU usage time COMMAND: Name of executable/command The ps command can get a little messy to look at, for now the fields we will look at the most are PID, STAT and COMMAND. Another very useful command is the top command, top gives you real time information about the processes running on your system instead of a snapshot. By default you'll get a refresh every 10 seconds. Top is an extremely useful tool to see what processes are taking up a lot of your resources. $ top","title":"ps (Processes)"},{"location":"processes/ps-command/#exercise","text":"Use the ps command with different flags and see how the output changes.","title":"Exercise"},{"location":"processes/ps-command/#quiz-questions","text":"Click the right arrow to view the answers What ps flag is used to view detailed information about processes? u","title":"Quiz Questions"},{"location":"routing/arp/","text":"ARP (Address Resolution Protocol) The ARP is used when you have a layer 3 packet and you want to encapsulate it inside a frame and send that frame to a MAC address. We don't initially know the MAC address and we need a protocol which can find the MAC address for a given IP address For example if you communicate with AWS, AWS will be the destination of the IP packets but we will forward via our home router which is the default gateway and so we will need the MAC address of that default gateway to send the frame to containing the packet. This is where ARP comes in ARP will give you the MAC address for a given IP address Example of ARP: 2 laptops: Laptop A (133.33.3.7) wants to send data to Laptop B (133.33.3.10). THey are both on the same network since the IPs have same subnet masks Laptop A takes the data and passes it to layer 3 which creates packet. The packet has its IP address as the source and laptop B as the destination IP Now we need a way of being able to create a frame to put that packet in for a transmission. We need the MAC address of laptop B This is what ARP does for us. It\u2019s a process which runs between layer 2 and layer 3. Because both IPs have same subnet mask and it knows they are on the same local network, this is a direct connection. Routers aren\u2019t required here. We don\u2019t use routers for this type of comms ARP broadcasts on layer 2. It sends an ARP frame to all Fs as a MAC address and it asks who has the IP address 133.33.3.10. Laptop B is also running ARP. The ARP software sees this broadcast and it responds by saying im that IP address and here is my MAC address Now Laptop A has the destination MAC address of laptop B, it can use it to build a frame, encapsulate the packet in this frame and once frame is ready, it can be given to layer 1 and sent across the physical network. Layer 1 receives the physical raw bit stream and hands it off to layer 2 of the laptop. Layer 2 software of the laptop B reviews the dest MAC address and knows it meant for it. So it strips off the frame and sends the packet to its layer 3 software. Layer 3 sees the packet and sees it is the intended destination and it de-encapsulates the data and hands it to the game. Quiz Questions Click the right arrow to view the answers 1. What is the primary function of ARP in a network? ARP (Address Resolution Protocol) is used to map an IP address to its corresponding MAC address. 2. How does ARP handle the communication when a device wants to communicate with another device on the same local network? ARP broadcasts a request to the local network to find the MAC address associated with the destination IP address. The device with the matching IP address responds with its MAC address. 3. What is the role of ARP when dealing with Layer 3 packets? ARP (Address Resolution Protocol) is used to find the MAC address corresponding to a given IP address, allowing a Layer 3 packet to be encapsulated inside a frame for transmission. 4. In the context of ARP, what happens when a device needs to communicate with a destination within the same local network? ARP broadcasts a request within the local network to find out the MAC address associated with the destination IP address. The device holding that IP address responds with its MAC address, enabling direct communication. 5. Describe the process of ARP in the scenario where Laptop A (IP: 133.33.3.7) wants to send data to Laptop B (IP: 133.33.3.10) on the same network. Laptop A, using ARP, broadcasts a request to find the MAC address of Laptop B. Laptop B, recognizing its IP in the request, responds with its MAC address. Laptop A then encapsulates the packet in a frame with Laptop B's MAC address and sends it over the network. Laptop B receives the frame, recognizes the MAC address, processes the frame, and sends the packet to its Layer 3 for further handling.","title":"ARP"},{"location":"routing/arp/#arp-address-resolution-protocol","text":"The ARP is used when you have a layer 3 packet and you want to encapsulate it inside a frame and send that frame to a MAC address. We don't initially know the MAC address and we need a protocol which can find the MAC address for a given IP address For example if you communicate with AWS, AWS will be the destination of the IP packets but we will forward via our home router which is the default gateway and so we will need the MAC address of that default gateway to send the frame to containing the packet. This is where ARP comes in ARP will give you the MAC address for a given IP address Example of ARP: 2 laptops: Laptop A (133.33.3.7) wants to send data to Laptop B (133.33.3.10). THey are both on the same network since the IPs have same subnet masks Laptop A takes the data and passes it to layer 3 which creates packet. The packet has its IP address as the source and laptop B as the destination IP Now we need a way of being able to create a frame to put that packet in for a transmission. We need the MAC address of laptop B This is what ARP does for us. It\u2019s a process which runs between layer 2 and layer 3. Because both IPs have same subnet mask and it knows they are on the same local network, this is a direct connection. Routers aren\u2019t required here. We don\u2019t use routers for this type of comms ARP broadcasts on layer 2. It sends an ARP frame to all Fs as a MAC address and it asks who has the IP address 133.33.3.10. Laptop B is also running ARP. The ARP software sees this broadcast and it responds by saying im that IP address and here is my MAC address Now Laptop A has the destination MAC address of laptop B, it can use it to build a frame, encapsulate the packet in this frame and once frame is ready, it can be given to layer 1 and sent across the physical network. Layer 1 receives the physical raw bit stream and hands it off to layer 2 of the laptop. Layer 2 software of the laptop B reviews the dest MAC address and knows it meant for it. So it strips off the frame and sends the packet to its layer 3 software. Layer 3 sees the packet and sees it is the intended destination and it de-encapsulates the data and hands it to the game.","title":"ARP (Address Resolution Protocol)"},{"location":"routing/arp/#quiz-questions","text":"Click the right arrow to view the answers 1. What is the primary function of ARP in a network? ARP (Address Resolution Protocol) is used to map an IP address to its corresponding MAC address. 2. How does ARP handle the communication when a device wants to communicate with another device on the same local network? ARP broadcasts a request to the local network to find the MAC address associated with the destination IP address. The device with the matching IP address responds with its MAC address. 3. What is the role of ARP when dealing with Layer 3 packets? ARP (Address Resolution Protocol) is used to find the MAC address corresponding to a given IP address, allowing a Layer 3 packet to be encapsulated inside a frame for transmission. 4. In the context of ARP, what happens when a device needs to communicate with a destination within the same local network? ARP broadcasts a request within the local network to find out the MAC address associated with the destination IP address. The device holding that IP address responds with its MAC address, enabling direct communication. 5. Describe the process of ARP in the scenario where Laptop A (IP: 133.33.3.7) wants to send data to Laptop B (IP: 133.33.3.10) on the same network. Laptop A, using ARP, broadcasts a request to find the MAC address of Laptop B. Laptop B, recognizing its IP in the request, responds with its MAC address. Laptop A then encapsulates the packet in a frame with Laptop B's MAC address and sends it over the network. Laptop B receives the frame, recognizes the MAC address, processes the frame, and sends the packet to its Layer 3 for further handling.","title":"Quiz Questions"},{"location":"routing/bgp/","text":"Border Gateway Protocol The last important protocol we'll discuss is BGP, BGP is basically how the Internet runs. It's used to collect and exchange routing information among autonomous systems. Think of an autonomous system as an Internet service provider, a company, university, any organization, etc. Without BGP, these systems would not know how to talk to each other, they would just be siloed off. Instead of routing inside these autonomous systems, BGP routes between them. Let's say you were on your home network and I'm working from Starbucks, I want to be able to communicate with you, so I send an email and the network packet travels through Starbuck's network, it bounces around there and goes through the routing tables in Starbuck's network until it finally reaches a point at the border of the Starbucks network and passes it to a Border Gateway router. This router contains the information for my packet to leave the Starbucks network and traverse other networks. Border Gateway Protocol aka BGP A routing protocol used to control how data flows from point A through points B and C and arrives at dest point D. A system made up of lots of self-managing networks known as Autonomous systems (AS). An AS could be a large network or a collection of routers Routers are controlled by one entity, a network in BGP. AS are black boxes which abstract away from the detail and only concern with network routing in and out of AS. Each AS is allocated a unique number by IANA which is known as ASN. Now ASN (Autonomous system numbers) are the way that GBP identifies different entities within the network. It\u2019s the way that BGP can distinguish between your network or your ASN and my network. BGP is designed to be reliable and distributed. It operates over TCP using port 179 (reliable) it includes error correction and flow control to ensure that all parties can communicate reliably. It isn\u2019t automatic however. You have to manually create a peering aka a BGP relationship between 2 different AS (peering is manually configured) once peered, 2 AS can communicate what they know about network topology, A given AS will learn about networks from any of the peering relationships that it has and anything it learns, it will communicate out to any of its other peers. Coz of the peering relationship structure, you rapidly build up a larger BGP network where each individual AS is exchaning network topology info and that\u2019s how the internet functions from a routing perspective. All of the major core networks are busy exchanging routing and topology info between each other. BPG is a path-vector protocol it exchanges the best path to a destination between peers.. the path is called the ASPATH. BGP doesn\u2019t take into account link speed or condition and only focuses on paths. For e.g. can we get from A to D using A, B, C and or is there a direct link between A & D. It\u2019s BGP\u2019s responsibility to build up this network topology map and allow exchange between different AS. There are terms like: iBGP = Internal BGP - routing within an AS eBGP = External BGP - routing between AS\u2019s (this type often used with AWS) Example of BGP: We have 3 cities in Australia with 3 different routes. Each one has a dfiferent ASN (one has ASN 200, ASN 201 and ASN 202). Each use a different router range (10.16.0.1/16, 10.17.0.1/16, 10.18.0.1/16) So each AS can have peering relationships configured so ASN 200, 201 and 202. So assume we have linked all 3. Each peer will exchange the best path that they have to a destination with each other. All 3 AS can talk to both the others and this has been configured automatically once the BGP peering relationships were set up between each of the AS. This is a ring network so there are 2 ways to get to every other network, clockwise and anti-clockwise. AS usually advertise the shortest route that they\u2019re aware of to any other AS that they have peering relationships with. At the end, there are indirect routes at the bottom of each route table have a longer AS path. These are non-preferred because it\u2019s not the shortest path to the destination. By default, BGP always uses the shorter path as the preferred one. There are cases where you want a router to use a different path. However, BGP doesn\u2019t take into account performance or condition because it\u2019s the shortest path will always be used but there is a technique if you want to do this this technique is called AS path prepending: which means you can configure a certain link/path to look worse than it actually is and this can be done by adding additional AS numbers to the path. You make it appear to be longer than it physically is. AS path prepending can be used to artificially make the satellite path look longer making the fibre path preferred. Remember BGP decides everything based on path length and so by artificially lengthening the path between a certain route, it means that another path will learn a new route which will be the shortest path. In, summary as BGP autonomous system advertises the shortest path to a destination that it\u2019s aware of to all other BGP routers that it\u2019s paired with. It might be aware of more paths but it only advertises the shortest one. It means that all BGP networks together to create a dynamic and ever-changing topology of all interconnected networks. It\u2019s how many large enterprise networks function. It\u2019s how the internet works and it\u2019s how routes are learned and communicated when using Direct Connect and dynamic VPNs with AWS. Another example of BGP: ISPs as Autonomous Systems: ISP-A (AS1) : A large internet service provider serving customers in North America. It has its own network infrastructure (routers, servers, cables, etc.) and an Autonomous System Number (ASN), say AS1. ISP-B (AS2) : Another major ISP, but it serves customers in Europe, with its own infrastructure and ASN, say AS2. Interconnection for Global Internet Access: Situation : A user with an internet subscription from ISP-A wants to access a website hosted in ISP-B's network. Role of BGP : Here's how BGP and ASes come into play: Routing Information Exchange : ISP-A and ISP-B use BGP to share information about what networks they can reach and the best routes to take. Path Selection : BGP algorithms in ISP-A's routers determine the best path to reach the website hosted in ISP-B's network. This decision is based on factors like the number of ASes the data must pass through (AS path), network policies, and traffic conditions. Data Transmission : Once the best path is chosen, data from the user's computer travels through ISP-A's network, reaches ISP-B's network via inter-AS connections (possibly through other intermediate ASes), and finally arrives at the server hosting the website. Response Back : The website server responds, and the data travels back through the selected route to the user's computer. Key Points in This Example: Autonomy : Each ISP, as an AS, independently manages its network and decides the best way to route traffic within and outside its network. Global Connectivity : Despite being separate entities, ISP-A and ISP-B can communicate and route traffic between each other efficiently, thanks to BGP. Dynamic Routing : BGP continuously updates the routing information. If a usual path becomes congested or unavailable, BGP can dynamically change the route to maintain connectivity. Quiz Questions Click the right arrow to view the answers What protocol basically makes the Internet work? BGP What is the primary role of BGP in the Internet's infrastructure? BGP (Border Gateway Protocol) is crucial for routing data across different autonomous systems on the Internet, such as ISPs, companies, and universities. Without BGP, these systems wouldn't be able to communicate with each other efficiently. How does BGP determine the best path for data transmission between autonomous systems? BGP is a path-vector protocol that determines the best path based on the ASPATH. It primarily focuses on the path length, without considering link speed or condition, and generally chooses the shortest available path. Describe the concept of 'AS path prepending' in BGP and its purpose. AS path prepending is a technique used to make a network path appear longer than it actually is by adding extra AS numbers to the path. This is used to influence route selection in BGP, often to de-prioritize certain paths over others for reasons like traffic management or reliability. Explain the difference between iBGP and eBGP. iBGP (Internal BGP) is used for routing within an autonomous system (AS), while eBGP (External BGP) is used for routing between different AS's. eBGP is often used in scenarios involving large networks like AWS. How do autonomous systems use BGP in the context of the Internet? Autonomous systems use BGP to advertise the shortest path to a destination they are aware of to all other BGP routers they are paired with. This collaborative effort creates a dynamic, ever-changing topology of interconnected networks, enabling efficient global Internet functionality.","title":"BGP Border Gateway Protocol"},{"location":"routing/bgp/#border-gateway-protocol","text":"The last important protocol we'll discuss is BGP, BGP is basically how the Internet runs. It's used to collect and exchange routing information among autonomous systems. Think of an autonomous system as an Internet service provider, a company, university, any organization, etc. Without BGP, these systems would not know how to talk to each other, they would just be siloed off. Instead of routing inside these autonomous systems, BGP routes between them. Let's say you were on your home network and I'm working from Starbucks, I want to be able to communicate with you, so I send an email and the network packet travels through Starbuck's network, it bounces around there and goes through the routing tables in Starbuck's network until it finally reaches a point at the border of the Starbucks network and passes it to a Border Gateway router. This router contains the information for my packet to leave the Starbucks network and traverse other networks.","title":"Border Gateway Protocol"},{"location":"routing/bgp/#border-gateway-protocol-aka-bgp","text":"A routing protocol used to control how data flows from point A through points B and C and arrives at dest point D. A system made up of lots of self-managing networks known as Autonomous systems (AS). An AS could be a large network or a collection of routers Routers are controlled by one entity, a network in BGP. AS are black boxes which abstract away from the detail and only concern with network routing in and out of AS. Each AS is allocated a unique number by IANA which is known as ASN. Now ASN (Autonomous system numbers) are the way that GBP identifies different entities within the network. It\u2019s the way that BGP can distinguish between your network or your ASN and my network. BGP is designed to be reliable and distributed. It operates over TCP using port 179 (reliable) it includes error correction and flow control to ensure that all parties can communicate reliably. It isn\u2019t automatic however. You have to manually create a peering aka a BGP relationship between 2 different AS (peering is manually configured) once peered, 2 AS can communicate what they know about network topology, A given AS will learn about networks from any of the peering relationships that it has and anything it learns, it will communicate out to any of its other peers. Coz of the peering relationship structure, you rapidly build up a larger BGP network where each individual AS is exchaning network topology info and that\u2019s how the internet functions from a routing perspective. All of the major core networks are busy exchanging routing and topology info between each other. BPG is a path-vector protocol it exchanges the best path to a destination between peers.. the path is called the ASPATH. BGP doesn\u2019t take into account link speed or condition and only focuses on paths. For e.g. can we get from A to D using A, B, C and or is there a direct link between A & D. It\u2019s BGP\u2019s responsibility to build up this network topology map and allow exchange between different AS. There are terms like: iBGP = Internal BGP - routing within an AS eBGP = External BGP - routing between AS\u2019s (this type often used with AWS) Example of BGP: We have 3 cities in Australia with 3 different routes. Each one has a dfiferent ASN (one has ASN 200, ASN 201 and ASN 202). Each use a different router range (10.16.0.1/16, 10.17.0.1/16, 10.18.0.1/16) So each AS can have peering relationships configured so ASN 200, 201 and 202. So assume we have linked all 3. Each peer will exchange the best path that they have to a destination with each other. All 3 AS can talk to both the others and this has been configured automatically once the BGP peering relationships were set up between each of the AS. This is a ring network so there are 2 ways to get to every other network, clockwise and anti-clockwise. AS usually advertise the shortest route that they\u2019re aware of to any other AS that they have peering relationships with. At the end, there are indirect routes at the bottom of each route table have a longer AS path. These are non-preferred because it\u2019s not the shortest path to the destination. By default, BGP always uses the shorter path as the preferred one. There are cases where you want a router to use a different path. However, BGP doesn\u2019t take into account performance or condition because it\u2019s the shortest path will always be used but there is a technique if you want to do this this technique is called AS path prepending: which means you can configure a certain link/path to look worse than it actually is and this can be done by adding additional AS numbers to the path. You make it appear to be longer than it physically is. AS path prepending can be used to artificially make the satellite path look longer making the fibre path preferred. Remember BGP decides everything based on path length and so by artificially lengthening the path between a certain route, it means that another path will learn a new route which will be the shortest path. In, summary as BGP autonomous system advertises the shortest path to a destination that it\u2019s aware of to all other BGP routers that it\u2019s paired with. It might be aware of more paths but it only advertises the shortest one. It means that all BGP networks together to create a dynamic and ever-changing topology of all interconnected networks. It\u2019s how many large enterprise networks function. It\u2019s how the internet works and it\u2019s how routes are learned and communicated when using Direct Connect and dynamic VPNs with AWS. Another example of BGP:","title":"Border Gateway Protocol aka BGP"},{"location":"routing/bgp/#isps-as-autonomous-systems","text":"ISP-A (AS1) : A large internet service provider serving customers in North America. It has its own network infrastructure (routers, servers, cables, etc.) and an Autonomous System Number (ASN), say AS1. ISP-B (AS2) : Another major ISP, but it serves customers in Europe, with its own infrastructure and ASN, say AS2.","title":"ISPs as Autonomous Systems:"},{"location":"routing/bgp/#interconnection-for-global-internet-access","text":"Situation : A user with an internet subscription from ISP-A wants to access a website hosted in ISP-B's network. Role of BGP : Here's how BGP and ASes come into play: Routing Information Exchange : ISP-A and ISP-B use BGP to share information about what networks they can reach and the best routes to take. Path Selection : BGP algorithms in ISP-A's routers determine the best path to reach the website hosted in ISP-B's network. This decision is based on factors like the number of ASes the data must pass through (AS path), network policies, and traffic conditions. Data Transmission : Once the best path is chosen, data from the user's computer travels through ISP-A's network, reaches ISP-B's network via inter-AS connections (possibly through other intermediate ASes), and finally arrives at the server hosting the website. Response Back : The website server responds, and the data travels back through the selected route to the user's computer.","title":"Interconnection for Global Internet Access:"},{"location":"routing/bgp/#key-points-in-this-example","text":"Autonomy : Each ISP, as an AS, independently manages its network and decides the best way to route traffic within and outside its network. Global Connectivity : Despite being separate entities, ISP-A and ISP-B can communicate and route traffic between each other efficiently, thanks to BGP. Dynamic Routing : BGP continuously updates the routing information. If a usual path becomes congested or unavailable, BGP can dynamically change the route to maintain connectivity.","title":"Key Points in This Example:"},{"location":"routing/bgp/#quiz-questions","text":"Click the right arrow to view the answers What protocol basically makes the Internet work? BGP What is the primary role of BGP in the Internet's infrastructure? BGP (Border Gateway Protocol) is crucial for routing data across different autonomous systems on the Internet, such as ISPs, companies, and universities. Without BGP, these systems wouldn't be able to communicate with each other efficiently. How does BGP determine the best path for data transmission between autonomous systems? BGP is a path-vector protocol that determines the best path based on the ASPATH. It primarily focuses on the path length, without considering link speed or condition, and generally chooses the shortest available path. Describe the concept of 'AS path prepending' in BGP and its purpose. AS path prepending is a technique used to make a network path appear longer than it actually is by adding extra AS numbers to the path. This is used to influence route selection in BGP, often to de-prioritize certain paths over others for reasons like traffic management or reliability. Explain the difference between iBGP and eBGP. iBGP (Internal BGP) is used for routing within an autonomous system (AS), while eBGP (External BGP) is used for routing between different AS's. eBGP is often used in scenarios involving large networks like AWS. How do autonomous systems use BGP in the context of the Internet? Autonomous systems use BGP to advertise the shortest path to a destination they are aware of to all other BGP routers they are paired with. This collaborative effort creates a dynamic, ever-changing topology of interconnected networks, enabling efficient global Internet functionality.","title":"Quiz Questions"},{"location":"routing/distance-vector-protocols/","text":"Distance Vector Protocols Distance vector protocols determine the path of other networks using the hop count a packet takes across the network. If network A was 3 hops away and network B was next to network A, then we assume it must be 4 hops away. In distance vector protocols, the next route would be the one with the least amount of hops. Distance vector protocols are great for small networks, when networks start to scale it takes longer for the routers to converge because it periodically sends the entire routing table out to every router. Another downside to distance vector protocols is efficiency, it chooses routes that are closer in hops, but it may not always choose the most efficient route. One of the common distance vector protocols is RIP (Routing Information Protocol), it broadcasts the routing table to every router in the network every 30 seconds. For a large network, this can take some serious juice to pull off, because of that RIP limits it's hop count to 15. Quiz Questions Click the right arrow to view the answers True or false, distance protocols use the route with the least amount of bandwidth? false","title":"Distance Vector Protocols"},{"location":"routing/distance-vector-protocols/#distance-vector-protocols","text":"Distance vector protocols determine the path of other networks using the hop count a packet takes across the network. If network A was 3 hops away and network B was next to network A, then we assume it must be 4 hops away. In distance vector protocols, the next route would be the one with the least amount of hops. Distance vector protocols are great for small networks, when networks start to scale it takes longer for the routers to converge because it periodically sends the entire routing table out to every router. Another downside to distance vector protocols is efficiency, it chooses routes that are closer in hops, but it may not always choose the most efficient route. One of the common distance vector protocols is RIP (Routing Information Protocol), it broadcasts the routing table to every router in the network every 30 seconds. For a large network, this can take some serious juice to pull off, because of that RIP limits it's hop count to 15.","title":"Distance Vector Protocols"},{"location":"routing/distance-vector-protocols/#quiz-questions","text":"Click the right arrow to view the answers True or false, distance protocols use the route with the least amount of bandwidth? false","title":"Quiz Questions"},{"location":"routing/link-state-protocols/","text":"Link State Protocols Link state protocols are great for large scale networks, they are more complex than distance vector protocols, however a large upside is their ability to converge quickly, this is because instead of periodically sending out the whole routing table, they only send updates to neighboring routes. They use a different algorithm to calculate the shortest path first and construct their network topology in the form of a graph to show which routers are connected to other routers. One of the common link state protocols is OSPF (Open Shortest Path First), it only updates the routing tables if there was a network change. It doesn't have a hop limit. Quiz Questions Click the right arrow to view the answers What is one of the most common link state protocols? OSPF","title":"Link State Protocols"},{"location":"routing/link-state-protocols/#link-state-protocols","text":"Link state protocols are great for large scale networks, they are more complex than distance vector protocols, however a large upside is their ability to converge quickly, this is because instead of periodically sending out the whole routing table, they only send updates to neighboring routes. They use a different algorithm to calculate the shortest path first and construct their network topology in the form of a graph to show which routers are connected to other routers. One of the common link state protocols is OSPF (Open Shortest Path First), it only updates the routing tables if there was a network change. It doesn't have a hop limit.","title":"Link State Protocols"},{"location":"routing/link-state-protocols/#quiz-questions","text":"Click the right arrow to view the answers What is one of the most common link state protocols? OSPF","title":"Quiz Questions"},{"location":"routing/nat/","text":"Network Address Translation (NAT) NAT is designed to overcome IPv4 shortages. IPv4 are either publically routable or they fail within the private address space. Publically routable addresses are assigned by a central agency and regional agencies which assign them to ISPs. And ISPs allocate them to businses or consumer needs An IPv4 publicly routable addresses have to be unique in order to function correctly. Private IPv4 addresses such as those in 10.0.0.0 range can be used in multiple places but can\u2019t be routed over the internet. And so to give internet access to private devices, we need to use Network Address Translation. on top of this, NAT provides extra security benefits. There are multiple types of NAT and all of them translate private IPv4 addresses to public ones so that packets can flow over the public internet and then translate back in reverse. so that internet based hosts can communicate back with these private services. That\u2019s a high level overview of a NAT but each type of NAT handles the process differently. Static NAT Static NAT: 1 private to 1 fixed public address (internet gateway). In affect, giving that private IP address access to the public internet in both directions. This is how an internet gateway within AWS works. Static NAT is what you would use when certain specific private IP addresses need access to the internet using a public IP and where these IPs need to be consistent. Dynamic NAT Similar to static NAT but there is no static allocation. Instead you have a pool of public IP addresses to use, and these are allocated as needed. So when private Ip addresses attempt to use the internet for something, This method of NAT is generally used when you have a large number of private IP addresses and want them all to have internet access via public IPs, but when you have less public IPs than private IPs and you want to be efficient in how they\u2019re used. Port Address Translation (PAT) Many private IPs translated to 1 public IP (NAT GW) This is likely what your home internet router does. You might have many devices like phones, laptops etc - and all of these will use PAT, aka overloading to use a single public IP. This method as the name suggest uses ports to identify devices. This is the actually the method that the NAT GW or NAT instances use within AWS. NAT as a process only makes sense for IPv4.. not IPv6. Since IPv6 has so many addresses, we don\u2019t need a form of private addressing. and as such as we don\u2019t need translation. With IPv6 generally, you don\u2019t need any form of NAT. Summary of NAT A static NAT is similar to how the Internet Gateway in AWS works. 1 to 1 static network address translation With dynamic NAT , multiple private IPs can share a single public IP as long as there is no overlap. As long as the devices, use the allocations at different times. With dynamic NAT, because the shared public pool of IPs are used, it\u2019s possible to run out of public IPs to allocate. This type of NAT is used when you have less public IPs than private ones, but when all of the private IPs at some time need public access, which is bidirectional. PAT (Port Address Translation) : is what allows a large number of private IPs to share one public IP It\u2019s how the AWS NAT GW functions. It has a many to 1 mapping architecture. Many private IPv4 addresses are mapped onto one public IPv4 address. Multiple devices are given unique public ports within the public address provided by the nat gateway. So laptop A (which has a private address) can have a public address of 52.95.36.67 with source port 1337 and laptop B can have the same public address here but with source port 1338 to communicate with the internet. So the NAT devices is creating a NAT table to store these ports. which has: Private IP, Private Port & Public IP (of the NAT GW) & Public port (which is unique) It\u2019s how your home router works and how NAT GW within AWS works Why PAT you can\u2019t initiate traffic to these private devices: because without an entry in the NAT table, the NAT device won\u2019t know to which device traffic should be translated and forwarded to. Quiz Questions Click the right arrow to view the answers What is the primary purpose of Network Address Translation (NAT) in IPv4 networks? NAT is designed to conserve IPv4 addresses by translating private IPv4 addresses into public ones for internet connectivity, and vice versa. This is crucial because IPv4 addresses are limited and need to be unique globally to function correctly. NAT also adds a layer of security by keeping internal network addresses private. Describe the difference between Static NAT and Dynamic NAT. Static NAT maps one private IP address to one fixed public IP address, providing consistent public access for specific private IPs. Dynamic NAT, on the other hand, involves a pool of public IP addresses allocated as needed. It's used when there are more private IP addresses than public ones, and efficient usage of public IPs is desired. Explain Port Address Translation (PAT) and its typical use case in home networks and AWS. PAT, also known as overloading, allows many private IP addresses to share a single public IP address. It uses unique port numbers to distinguish between different private IPs. This method is commonly used in home routers and AWS's NAT Gateways, enabling multiple devices to access the internet through one public IP. However, PAT does not allow initiating traffic to private devices without an entry in the NAT table. Why is NAT not typically required in IPv6 networks? IPv6 addresses are plentiful, eliminating the need for private addressing and, consequently, the need for address translation that NAT provides in IPv4 networks. IPv6's large address space makes every device capable of having a unique public IP address.","title":"NAT"},{"location":"routing/nat/#network-address-translation-nat","text":"NAT is designed to overcome IPv4 shortages. IPv4 are either publically routable or they fail within the private address space. Publically routable addresses are assigned by a central agency and regional agencies which assign them to ISPs. And ISPs allocate them to businses or consumer needs An IPv4 publicly routable addresses have to be unique in order to function correctly. Private IPv4 addresses such as those in 10.0.0.0 range can be used in multiple places but can\u2019t be routed over the internet. And so to give internet access to private devices, we need to use Network Address Translation. on top of this, NAT provides extra security benefits. There are multiple types of NAT and all of them translate private IPv4 addresses to public ones so that packets can flow over the public internet and then translate back in reverse. so that internet based hosts can communicate back with these private services. That\u2019s a high level overview of a NAT but each type of NAT handles the process differently.","title":"Network Address Translation (NAT)"},{"location":"routing/nat/#static-nat","text":"Static NAT: 1 private to 1 fixed public address (internet gateway). In affect, giving that private IP address access to the public internet in both directions. This is how an internet gateway within AWS works. Static NAT is what you would use when certain specific private IP addresses need access to the internet using a public IP and where these IPs need to be consistent.","title":"Static NAT"},{"location":"routing/nat/#dynamic-nat","text":"Similar to static NAT but there is no static allocation. Instead you have a pool of public IP addresses to use, and these are allocated as needed. So when private Ip addresses attempt to use the internet for something, This method of NAT is generally used when you have a large number of private IP addresses and want them all to have internet access via public IPs, but when you have less public IPs than private IPs and you want to be efficient in how they\u2019re used.","title":"Dynamic NAT"},{"location":"routing/nat/#port-address-translation-pat","text":"Many private IPs translated to 1 public IP (NAT GW) This is likely what your home internet router does. You might have many devices like phones, laptops etc - and all of these will use PAT, aka overloading to use a single public IP. This method as the name suggest uses ports to identify devices. This is the actually the method that the NAT GW or NAT instances use within AWS. NAT as a process only makes sense for IPv4.. not IPv6. Since IPv6 has so many addresses, we don\u2019t need a form of private addressing. and as such as we don\u2019t need translation. With IPv6 generally, you don\u2019t need any form of NAT.","title":"Port Address Translation (PAT)"},{"location":"routing/nat/#summary-of-nat","text":"A static NAT is similar to how the Internet Gateway in AWS works. 1 to 1 static network address translation With dynamic NAT , multiple private IPs can share a single public IP as long as there is no overlap. As long as the devices, use the allocations at different times. With dynamic NAT, because the shared public pool of IPs are used, it\u2019s possible to run out of public IPs to allocate. This type of NAT is used when you have less public IPs than private ones, but when all of the private IPs at some time need public access, which is bidirectional. PAT (Port Address Translation) : is what allows a large number of private IPs to share one public IP It\u2019s how the AWS NAT GW functions. It has a many to 1 mapping architecture. Many private IPv4 addresses are mapped onto one public IPv4 address. Multiple devices are given unique public ports within the public address provided by the nat gateway. So laptop A (which has a private address) can have a public address of 52.95.36.67 with source port 1337 and laptop B can have the same public address here but with source port 1338 to communicate with the internet. So the NAT devices is creating a NAT table to store these ports. which has: Private IP, Private Port & Public IP (of the NAT GW) & Public port (which is unique) It\u2019s how your home router works and how NAT GW within AWS works Why PAT you can\u2019t initiate traffic to these private devices: because without an entry in the NAT table, the NAT device won\u2019t know to which device traffic should be translated and forwarded to.","title":"Summary of NAT"},{"location":"routing/nat/#quiz-questions","text":"Click the right arrow to view the answers What is the primary purpose of Network Address Translation (NAT) in IPv4 networks? NAT is designed to conserve IPv4 addresses by translating private IPv4 addresses into public ones for internet connectivity, and vice versa. This is crucial because IPv4 addresses are limited and need to be unique globally to function correctly. NAT also adds a layer of security by keeping internal network addresses private. Describe the difference between Static NAT and Dynamic NAT. Static NAT maps one private IP address to one fixed public IP address, providing consistent public access for specific private IPs. Dynamic NAT, on the other hand, involves a pool of public IP addresses allocated as needed. It's used when there are more private IP addresses than public ones, and efficient usage of public IPs is desired. Explain Port Address Translation (PAT) and its typical use case in home networks and AWS. PAT, also known as overloading, allows many private IP addresses to share a single public IP address. It uses unique port numbers to distinguish between different private IPs. This method is commonly used in home routers and AWS's NAT Gateways, enabling multiple devices to access the internet through one public IP. However, PAT does not allow initiating traffic to private devices without an entry in the NAT table. Why is NAT not typically required in IPv6 networks? IPv6 addresses are plentiful, eliminating the need for private addressing and, consequently, the need for address translation that NAT provides in IPv4 networks. IPv6's large address space makes every device capable of having a unique public IP address.","title":"Quiz Questions"},{"location":"routing/path-of-a-packet/","text":"Path of a Packet Let's look at how a packet travels within it's local network First the local machine will compare the destination IP address to see if it's in the same subnet by looking at its subnet mask. When packets are sent they need to have a source MAC address, destination MAC address, source IP address and destination IP address, at this point we do not know the destination MAC address. To get to the destination host, we use ARP to broadcast a request on the local network to find the MAC address of the destination host. Now the packet can be successfully sent! Let's see how a packet travels outside it's network First the local machine will compare the destination IP address, since it's outside of our network, it does not see the MAC address of the destination host. And we can't use ARP because the ARP request is a broadcast to locally connected hosts. So our packet now looks at the routing table, it doesn't know the address of the destination IP, so it sends it out to the default gateway (another router). So now our packet contains our source IP, destination IP and source MAC, however we don't have a destination MAC. Remember MAC addresses are only reached through the same network. So what does it do? It sends an ARP request to get the MAC address of the default gateway. The router looks at the packet and confirms the destination MAC address, but it's not the final destination IP address, so it keeps looking at the routing table to forward the packet to another IP address that can help the packet move along to its destination. Everytime the packet moves, it strips the old source and destination MAC address and updates the packet with the new source and destination MAC addresses. Once the packet gets forwarded to the same network, we use ARP to find the final destination MAC address During this process, our packet doesn't change the source or destination IP address. Quiz Questions Click the right arrow to view the answers How do we find the MAC address of an IP address? ARP","title":"Path of a packet"},{"location":"routing/path-of-a-packet/#path-of-a-packet","text":"Let's look at how a packet travels within it's local network First the local machine will compare the destination IP address to see if it's in the same subnet by looking at its subnet mask. When packets are sent they need to have a source MAC address, destination MAC address, source IP address and destination IP address, at this point we do not know the destination MAC address. To get to the destination host, we use ARP to broadcast a request on the local network to find the MAC address of the destination host. Now the packet can be successfully sent! Let's see how a packet travels outside it's network First the local machine will compare the destination IP address, since it's outside of our network, it does not see the MAC address of the destination host. And we can't use ARP because the ARP request is a broadcast to locally connected hosts. So our packet now looks at the routing table, it doesn't know the address of the destination IP, so it sends it out to the default gateway (another router). So now our packet contains our source IP, destination IP and source MAC, however we don't have a destination MAC. Remember MAC addresses are only reached through the same network. So what does it do? It sends an ARP request to get the MAC address of the default gateway. The router looks at the packet and confirms the destination MAC address, but it's not the final destination IP address, so it keeps looking at the routing table to forward the packet to another IP address that can help the packet move along to its destination. Everytime the packet moves, it strips the old source and destination MAC address and updates the packet with the new source and destination MAC addresses. Once the packet gets forwarded to the same network, we use ARP to find the final destination MAC address During this process, our packet doesn't change the source or destination IP address.","title":"Path of a Packet"},{"location":"routing/path-of-a-packet/#quiz-questions","text":"Click the right arrow to view the answers How do we find the MAC address of an IP address? ARP","title":"Quiz Questions"},{"location":"routing/routing-protocols/","text":"Routing Protocols It would be a pain to have to manually configure routes on a routing table for every device on your network, so instead we use what are known as routing protocols. Routing protocols are used to help our system adapt to network changes, it learns of different routes, builds them in the routing table and then routes our packets through that way. There are two primary routing protocol types, distance vector protocols and link state protocols. Convergence Before we talk about the protocols, we should go over a term using in routing known as convergence. When using routing protocols, routers communicate with other routers to collect and exchange information about the network. When they agree on how a network should look, every routing table maps out the complete topology of the network, thus \"converging\". When something occurs in the network topology, the convergence will temporarily break until all routers are aware of this change. Quiz Questions Click the right arrow to view the answers What is the term used when all routing tables know the network topology? convergence","title":"Routing Protocols"},{"location":"routing/routing-protocols/#routing-protocols","text":"It would be a pain to have to manually configure routes on a routing table for every device on your network, so instead we use what are known as routing protocols. Routing protocols are used to help our system adapt to network changes, it learns of different routes, builds them in the routing table and then routes our packets through that way. There are two primary routing protocol types, distance vector protocols and link state protocols. Convergence Before we talk about the protocols, we should go over a term using in routing known as convergence. When using routing protocols, routers communicate with other routers to collect and exchange information about the network. When they agree on how a network should look, every routing table maps out the complete topology of the network, thus \"converging\". When something occurs in the network topology, the convergence will temporarily break until all routers are aware of this change.","title":"Routing Protocols"},{"location":"routing/routing-protocols/#quiz-questions","text":"Click the right arrow to view the answers What is the term used when all routing tables know the network topology? convergence","title":"Quiz Questions"},{"location":"routing/routing-table/","text":"Routing Table Look at your machine's routing table: mo:~$ sudo route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 192.168.224.2 0.0.0.0 UG 0 0 0 eth0 192.168.224.0 0.0.0.0 255.255.255.0 U 1 0 0 eth0 Destination In the first field, we have a destination IP address of 192.168.224.0, this says that any packet that tries to go to this network, goes out through my Ethernet cable (eth0). If I was 192.168.224.5 and wanted to get to 192.168.224.7, I would just use the network interface eth0 directly. Notice that we have addresses of 0.0.0.0 this means that no address is specified or it's unknown. So if for example, I wanted to send a packet to IP address 151.123.43.6, our routing table doesn't know where that goes, so it denotes it as 0.0.0.0 and therefore routes our packet to the Gateway. Gateway If we are sending a packet that is not on the same network, it will be sent to this Gateway address. Which is aptly named as being a Gateway to another network. Genmask This is the subnet mask, used to figure out what IP addresses match what destination. Flags UG - Network is Up and is a Gateway U - Network is Up Iface This is the interface that our packet will be going out of, eth0 usually stands for the first Ethernet device on your system. Exercise Look at your routing table and see where your packets can go. Quiz Questions Click the right arrow to view the answers Where are packets routed to if our routing table doesn't know? Gateway","title":"Routing Table"},{"location":"routing/routing-table/#routing-table","text":"Look at your machine's routing table: mo:~$ sudo route -n Kernel IP routing table Destination Gateway Genmask Flags Metric Ref Use Iface 0.0.0.0 192.168.224.2 0.0.0.0 UG 0 0 0 eth0 192.168.224.0 0.0.0.0 255.255.255.0 U 1 0 0 eth0 Destination In the first field, we have a destination IP address of 192.168.224.0, this says that any packet that tries to go to this network, goes out through my Ethernet cable (eth0). If I was 192.168.224.5 and wanted to get to 192.168.224.7, I would just use the network interface eth0 directly. Notice that we have addresses of 0.0.0.0 this means that no address is specified or it's unknown. So if for example, I wanted to send a packet to IP address 151.123.43.6, our routing table doesn't know where that goes, so it denotes it as 0.0.0.0 and therefore routes our packet to the Gateway. Gateway If we are sending a packet that is not on the same network, it will be sent to this Gateway address. Which is aptly named as being a Gateway to another network. Genmask This is the subnet mask, used to figure out what IP addresses match what destination. Flags UG - Network is Up and is a Gateway U - Network is Up Iface This is the interface that our packet will be going out of, eth0 usually stands for the first Ethernet device on your system.","title":"Routing Table"},{"location":"routing/routing-table/#exercise","text":"Look at your routing table and see where your packets can go.","title":"Exercise"},{"location":"routing/routing-table/#quiz-questions","text":"Click the right arrow to view the answers Where are packets routed to if our routing table doesn't know? Gateway","title":"Quiz Questions"},{"location":"routing/what-is-a-router/","text":"What is a router? We've used this term router before, hopefully you know what one is, since you probably have one in your home. A router enables machines on a network to communicate with each other as well as other networks. On a typical router, you will have LAN ports, that allow your machines to connect to the same local area network and you will also have an Internet uplink port that connects you to the Internet, sometimes you'll see this port being labelled as WAN, because it is essentially connecting you to a wider network. When we do any sort of networking activity, it has to go through the router. The router decides where our network packets go and which ones come in. It routes our packets between multiple networks to get from it's source host to it's destination host. How does a router work? Think about routing the same way as mail delivery, we have an address we want to send a letter to, when we send it off to the post office, they get the letter and see, oh this is going to California, I'll put it on the truck going to California (I honestly have no idea how the postal system works). The letter then gets sent to San Francisco, inside San Francisco there are different zip codes, and then in those zip codes there are smaller address codes, until finally someone is able to deliver your letter to the address you wanted. On the other hand, if you already lived in San Francisco and in the same zipcode, the mail deliverer will probably know exactly where the letter has to go to without handing it off to anyone else. When we route packets, they use similar address \"routes\", such as to get to network A, send these packets to network B. When we don't have a route set for that, we have a default route that our packets will use. These routes are set on a routing table that our system uses to navigate us across networks. Hops As packets move across networks, they travel in hops, a hop is how we roughly measure the distance that the packet must travel to get from the source to the destination. Let's say to I have two routers connecting host A to host B, so therefore we say there are two hops between host A and host B. Each hop is a intermediate device like the routers that we must pass through. Understanding the basic difference between Switching, Routing & Flooding? Packet SWITCHING is basically receiving, processing and forwarding data to the destination device. ROUTING is a process of creating the routing table, so that we can do SWITCHING better. Before routing, FLOODING was used. If a router don't know which way to send a packet than every incoming packet is sent through every outgoing link except the one it arrived on. Quiz Questions Click the right arrow to view the answers How do packets measure distance? hops","title":"What is a router"},{"location":"routing/what-is-a-router/#what-is-a-router","text":"We've used this term router before, hopefully you know what one is, since you probably have one in your home. A router enables machines on a network to communicate with each other as well as other networks. On a typical router, you will have LAN ports, that allow your machines to connect to the same local area network and you will also have an Internet uplink port that connects you to the Internet, sometimes you'll see this port being labelled as WAN, because it is essentially connecting you to a wider network. When we do any sort of networking activity, it has to go through the router. The router decides where our network packets go and which ones come in. It routes our packets between multiple networks to get from it's source host to it's destination host. How does a router work? Think about routing the same way as mail delivery, we have an address we want to send a letter to, when we send it off to the post office, they get the letter and see, oh this is going to California, I'll put it on the truck going to California (I honestly have no idea how the postal system works). The letter then gets sent to San Francisco, inside San Francisco there are different zip codes, and then in those zip codes there are smaller address codes, until finally someone is able to deliver your letter to the address you wanted. On the other hand, if you already lived in San Francisco and in the same zipcode, the mail deliverer will probably know exactly where the letter has to go to without handing it off to anyone else. When we route packets, they use similar address \"routes\", such as to get to network A, send these packets to network B. When we don't have a route set for that, we have a default route that our packets will use. These routes are set on a routing table that our system uses to navigate us across networks. Hops As packets move across networks, they travel in hops, a hop is how we roughly measure the distance that the packet must travel to get from the source to the destination. Let's say to I have two routers connecting host A to host B, so therefore we say there are two hops between host A and host B. Each hop is a intermediate device like the routers that we must pass through. Understanding the basic difference between Switching, Routing & Flooding? Packet SWITCHING is basically receiving, processing and forwarding data to the destination device. ROUTING is a process of creating the routing table, so that we can do SWITCHING better. Before routing, FLOODING was used. If a router don't know which way to send a packet than every incoming packet is sent through every outgoing link except the one it arrived on.","title":"What is a router?"},{"location":"routing/what-is-a-router/#quiz-questions","text":"Click the right arrow to view the answers How do packets measure distance? hops","title":"Quiz Questions"},{"location":"subnetting/cidr/","text":"CIDR CIDR (classless inter-domain routing) is used to represent a subnet mask in a more compact way. You may see subnets notated in CIDR notation, where a subnet such as the 10.42.3.0/255.255.255.0 is written as 10.42.3.0/24 which just means it includes both the subnet prefix and the subnet mask. Remember an IP address consists of 4 bytes or 32 bits, CIDR indicates the amount of bits used as the network prefix. So 123.12.24.0/23 means that the first 23 bits are used. Well what does that mean? How many hosts is that? A simple trick is to subtract the total of bits an IP address can have (32) from the CIDR address (23), so that leaves 9 bits, 2^9 = 512, but we have to remove 2 addresses (subnet address and broadcast address) so we have 510 usable hosts. Quiz Questions Click the right arrow to view the answers Add questions later Add answer here","title":"CIDR"},{"location":"subnetting/cidr/#cidr","text":"CIDR (classless inter-domain routing) is used to represent a subnet mask in a more compact way. You may see subnets notated in CIDR notation, where a subnet such as the 10.42.3.0/255.255.255.0 is written as 10.42.3.0/24 which just means it includes both the subnet prefix and the subnet mask. Remember an IP address consists of 4 bytes or 32 bits, CIDR indicates the amount of bits used as the network prefix. So 123.12.24.0/23 means that the first 23 bits are used. Well what does that mean? How many hosts is that? A simple trick is to subtract the total of bits an IP address can have (32) from the CIDR address (23), so that leaves 9 bits, 2^9 = 512, but we have to remove 2 addresses (subnet address and broadcast address) so we have 510 usable hosts.","title":"CIDR"},{"location":"subnetting/cidr/#quiz-questions","text":"Click the right arrow to view the answers Add questions later Add answer here","title":"Quiz Questions"},{"location":"subnetting/ipv4/","text":"IPv4 So we know that network hosts have a unique address they can be found at. These addresses are known as IP addresses. An IPv4 address looks something like this: 204.23.124.23 This address actually contains two parts, the network portion that tells us know network it's on and the host portion that tells us which host on that network it is. For this course we will mostly be discussing IPv4 addresses, which are what you commonly will see when referring to IP addresses. An IP address is separated into octets by the periods. So there are 4 octets in an IPv4 address. If you know a bit of computer science, an octet is 8 bits and 8 bits actually equal 1 byte, so we also refer to an IPv4 address as having 4 bytes. We use bits frequently when dealing with subnets and IP addresses. You can view your IP address with the ifconfig -a command: mo:~$ ifconfig -a eth0 Link encap:Ethernet HWaddr 1d:3a:32:24:4d:ce inet addr:192.168.1.129 Bcast:192.168.1.255 Mask:255.255.255.0 inet6 addr: fd60::21c:29ff:fe63:5cdc/64 Scope:Link As you can see my IPv4 address is: 192.168.1.129 Packet structure of IPv4 vs IPv6 IPv4 Every packet has a source and destination IP address Protocol field (which is layer 4) like ICMP, TCP, UDP If you're storing TCP data inside a packet, this value will be 6 If you're storing UDP data inside a packet, this value will be 17 If you're storing ICMP data inside a packet, this value will be 1 Bulk of the field within a packet is taken up by the data. A field called TTL Exercise Find your IP address with ifconfig. Quiz Questions Click the right arrow to view the answers How many bytes are in an IPv4 address? 4","title":"IPv4"},{"location":"subnetting/ipv4/#ipv4","text":"So we know that network hosts have a unique address they can be found at. These addresses are known as IP addresses. An IPv4 address looks something like this: 204.23.124.23 This address actually contains two parts, the network portion that tells us know network it's on and the host portion that tells us which host on that network it is. For this course we will mostly be discussing IPv4 addresses, which are what you commonly will see when referring to IP addresses. An IP address is separated into octets by the periods. So there are 4 octets in an IPv4 address. If you know a bit of computer science, an octet is 8 bits and 8 bits actually equal 1 byte, so we also refer to an IPv4 address as having 4 bytes. We use bits frequently when dealing with subnets and IP addresses. You can view your IP address with the ifconfig -a command: mo:~$ ifconfig -a eth0 Link encap:Ethernet HWaddr 1d:3a:32:24:4d:ce inet addr:192.168.1.129 Bcast:192.168.1.255 Mask:255.255.255.0 inet6 addr: fd60::21c:29ff:fe63:5cdc/64 Scope:Link As you can see my IPv4 address is: 192.168.1.129","title":"IPv4"},{"location":"subnetting/ipv4/#packet-structure-of-ipv4-vs-ipv6","text":"","title":"Packet structure of IPv4 vs IPv6"},{"location":"subnetting/ipv4/#ipv4_1","text":"Every packet has a source and destination IP address Protocol field (which is layer 4) like ICMP, TCP, UDP If you're storing TCP data inside a packet, this value will be 6 If you're storing UDP data inside a packet, this value will be 17 If you're storing ICMP data inside a packet, this value will be 1 Bulk of the field within a packet is taken up by the data. A field called TTL","title":"IPv4"},{"location":"subnetting/ipv4/#exercise","text":"Find your IP address with ifconfig.","title":"Exercise"},{"location":"subnetting/ipv4/#quiz-questions","text":"Click the right arrow to view the answers How many bytes are in an IPv4 address? 4","title":"Quiz Questions"},{"location":"subnetting/ipv6/","text":"IPv6 We've heard the term IPv6 here and there, but what is it? Every device that connects to the Internet gets it's own IP address, well that happens to be a finite number that we are soon approaching in this digital age. IPv6 was created to allow us to connect more hosts to the Internet, it comes with more IP improvements however, it's adoption is quite slow. It isn't meant to replace IPv4, they are meant to complement each other. The two IP protocols are very similar and if you know IPv4 you'll understand IPv6, the major difference is the way the address is written. Here is what a typical IPv6 address looks like: 2dde:1235:1256:3:200:f8ed:fe23:59cf Packet structure of IPv6 Source & IP (Bigger & therefore, larger addresses) Data Hop limit (like TTL) Exercise Check ifconfig to see if you have an IPv6 address listed. Quiz Questions Click the right arrow to view the answers What IP address is used to help increase the number of hosts that can connect to the Internet? IPv6 How many bytes are in an IPv6 address? 16","title":"IPv6"},{"location":"subnetting/ipv6/#ipv6","text":"We've heard the term IPv6 here and there, but what is it? Every device that connects to the Internet gets it's own IP address, well that happens to be a finite number that we are soon approaching in this digital age. IPv6 was created to allow us to connect more hosts to the Internet, it comes with more IP improvements however, it's adoption is quite slow. It isn't meant to replace IPv4, they are meant to complement each other. The two IP protocols are very similar and if you know IPv4 you'll understand IPv6, the major difference is the way the address is written. Here is what a typical IPv6 address looks like: 2dde:1235:1256:3:200:f8ed:fe23:59cf","title":"IPv6"},{"location":"subnetting/ipv6/#packet-structure-of-ipv6","text":"Source & IP (Bigger & therefore, larger addresses) Data Hop limit (like TTL)","title":"Packet structure of IPv6"},{"location":"subnetting/ipv6/#exercise","text":"Check ifconfig to see if you have an IPv6 address listed.","title":"Exercise"},{"location":"subnetting/ipv6/#quiz-questions","text":"Click the right arrow to view the answers What IP address is used to help increase the number of hosts that can connect to the Internet? IPv6 How many bytes are in an IPv6 address? 16","title":"Quiz Questions"},{"location":"subnetting/nat/","text":"NAT We've brought up NAT (network address translation) before but didn't touch upon it, when we are working on our network, does that mean that the Internet can see our IP address? Not quite. NAT makes a device like our router act as an intermediary between the Internet and private network. So only a single, unique IP address is required to represent an entire group of computers. Think of NAT is like a receptionist in a large office, if someone wants to contact you, they only know the number to the whole office, the receptionist would then have to look for your extension number and forward the call to you. How does it work? A simple case would look like this: Patty wants to connect to www.google.com, so her machine sends this request through the router The router takes that request and opens its own connection to google.com, then it sends Patty's request once it makes a connection The router is the intermediary between Patty and www.google.com. Google doesn't know about Patty instead all it can see is the router. NAT and packet routing in general can get pretty ugly, but we won't dive into the specifics. Quiz Questions Click the right arrow to view the answers What is used to represent a single private address to the Internet? NAT","title":"NAT"},{"location":"subnetting/nat/#nat","text":"We've brought up NAT (network address translation) before but didn't touch upon it, when we are working on our network, does that mean that the Internet can see our IP address? Not quite. NAT makes a device like our router act as an intermediary between the Internet and private network. So only a single, unique IP address is required to represent an entire group of computers. Think of NAT is like a receptionist in a large office, if someone wants to contact you, they only know the number to the whole office, the receptionist would then have to look for your extension number and forward the call to you. How does it work? A simple case would look like this: Patty wants to connect to www.google.com, so her machine sends this request through the router The router takes that request and opens its own connection to google.com, then it sends Patty's request once it makes a connection The router is the intermediary between Patty and www.google.com. Google doesn't know about Patty instead all it can see is the router. NAT and packet routing in general can get pretty ugly, but we won't dive into the specifics.","title":"NAT"},{"location":"subnetting/nat/#quiz-questions","text":"Click the right arrow to view the answers What is used to represent a single private address to the Internet? NAT","title":"Quiz Questions"},{"location":"subnetting/subnet-math/","text":"Subnet Math Ok, we know that subnet masks are important to figure out how many hosts we can have on our subnet. So how many hosts would that be? Let's say I have an IP address of 192.168.1.0 and a subnet mask of 255.255.255.0 , now let's line up these numbers in binary form. For now use an online calculator to convert these values from decimal to binary. 192.168.1.165 = 11000000.10101000.00000001.10100101 255.255.255.0 = 11111111.11111111.11111111.00000000 The IP address is masked by our subnet mask, when you see a 1, it is masked and we pretend like we don't see it. So the only possible hosts we can have are from the 00000000 region. Remember 11111111 in binary form equals 255, we also account 0 as a host number, so there are 256 possible options. However, it may look like we have 256 possible options, but we actually subtract 2 hosts because we have to account for the broadcast address and the subnet address, leaving us with 254 possible hosts on our subnet. So we know that we can have hosts with IP addresses ranging from 192.168.1.1 - 192.168.1.254. Quiz Questions Click the right arrow to view the answers What is the binary equivalent of 255? 11111111","title":"Subnet Math"},{"location":"subnetting/subnet-math/#subnet-math","text":"Ok, we know that subnet masks are important to figure out how many hosts we can have on our subnet. So how many hosts would that be? Let's say I have an IP address of 192.168.1.0 and a subnet mask of 255.255.255.0 , now let's line up these numbers in binary form. For now use an online calculator to convert these values from decimal to binary. 192.168.1.165 = 11000000.10101000.00000001.10100101 255.255.255.0 = 11111111.11111111.11111111.00000000 The IP address is masked by our subnet mask, when you see a 1, it is masked and we pretend like we don't see it. So the only possible hosts we can have are from the 00000000 region. Remember 11111111 in binary form equals 255, we also account 0 as a host number, so there are 256 possible options. However, it may look like we have 256 possible options, but we actually subtract 2 hosts because we have to account for the broadcast address and the subnet address, leaving us with 254 possible hosts on our subnet. So we know that we can have hosts with IP addresses ranging from 192.168.1.1 - 192.168.1.254.","title":"Subnet Math"},{"location":"subnetting/subnet-math/#quiz-questions","text":"Click the right arrow to view the answers What is the binary equivalent of 255? 11111111","title":"Quiz Questions"},{"location":"subnetting/subnets/","text":"Subnets How can I tell if I'm on the same network as Patty? Well we can just look at the subnet short for subnetwork. A subnet is a group of hosts with IP addresses that are similar in a certain way. These hosts usually are in a proximate location from each other and you can easily send data to and from hosts on the same subnet. Think about it as sending mail in the same zip code, it's a lot easier than sending mail to a different state. For example, all hosts with an IP address that starts with 123.45.67 would be on the same subnet. My host has an IP of 123.45.67.8 and Patty's has an IP of 123.45.67.9. The common numbers are my network prefix and the 8 and 9 are our hosts, therefore my network is the same as Patty's. A subnet is divided into a network prefix, such as 123.45.67.0 and a subnet mask. Subnet Masks Subnet masks determine what part of your IP address is the network portion and what part is the host portion. A typical subnet mask can look something like this: 255.255.255.0 The 255 portion is actually our mask. To make this a little easier to understand, remember how we refer to each octet as 8 bits? In computer science a bit is denoted by a 0 or a 1 in binary form. When binary numbers are used, 1 means on and 0 means off. So what does 8 0's or 1's equal? Punch into Google \"binary to decimal calculator\" and convert 11111111 into a decimal form. What do you get? 255! So an octet ranges from 0 to 255. So if we had a subnet mask of 255.255.255.0, and an IP address of 192.168.1.0, how many hosts are on that subnet? We'll find out the answer to that in our subnet math lesson. Also when we talk about our subnet, we commonly denote it by the network prefix followed by the subnet mask: 123.234.0.0/255.255.0.0 Why? Why on earth do we make subnets? Subnetting is used to segment networks and control the flow of traffic within that network. So a host on one subnet can\u2019t interact with another host on a different subnet. But wait a minute, what if I want to connect to other hosts like yahoo.com? Then you need to connect subnets together. To connect subnets you just need to find the hosts that are connected to more than one subnet. For example, if my host at 192.168.1.129 is connected to a local network of 192.168.1.129/24 it can reach any hosts on that network. To reach hosts on the rest of the Internet, it needs to communicate through the router. Traditionally, on most networks with a subnet mask of 255.255.255.0, the router is usually at address 1 of the subnet, so 192.168.1.1. Now that router will have a port that connects it to another subnet (more in the Routing course). Certain IP addresses (private networks) are not visible to the internet, and we have things like NAT in place (more on this later). Exercise Use ifconfig to view your subnet mask. Quiz Questions Click the right arrow to view the answers True or false, a subnet consists of a subnet mask and network prefix. True","title":"Subnets"},{"location":"subnetting/subnets/#subnets","text":"How can I tell if I'm on the same network as Patty? Well we can just look at the subnet short for subnetwork. A subnet is a group of hosts with IP addresses that are similar in a certain way. These hosts usually are in a proximate location from each other and you can easily send data to and from hosts on the same subnet. Think about it as sending mail in the same zip code, it's a lot easier than sending mail to a different state. For example, all hosts with an IP address that starts with 123.45.67 would be on the same subnet. My host has an IP of 123.45.67.8 and Patty's has an IP of 123.45.67.9. The common numbers are my network prefix and the 8 and 9 are our hosts, therefore my network is the same as Patty's. A subnet is divided into a network prefix, such as 123.45.67.0 and a subnet mask. Subnet Masks Subnet masks determine what part of your IP address is the network portion and what part is the host portion. A typical subnet mask can look something like this: 255.255.255.0 The 255 portion is actually our mask. To make this a little easier to understand, remember how we refer to each octet as 8 bits? In computer science a bit is denoted by a 0 or a 1 in binary form. When binary numbers are used, 1 means on and 0 means off. So what does 8 0's or 1's equal? Punch into Google \"binary to decimal calculator\" and convert 11111111 into a decimal form. What do you get? 255! So an octet ranges from 0 to 255. So if we had a subnet mask of 255.255.255.0, and an IP address of 192.168.1.0, how many hosts are on that subnet? We'll find out the answer to that in our subnet math lesson. Also when we talk about our subnet, we commonly denote it by the network prefix followed by the subnet mask: 123.234.0.0/255.255.0.0 Why? Why on earth do we make subnets? Subnetting is used to segment networks and control the flow of traffic within that network. So a host on one subnet can\u2019t interact with another host on a different subnet. But wait a minute, what if I want to connect to other hosts like yahoo.com? Then you need to connect subnets together. To connect subnets you just need to find the hosts that are connected to more than one subnet. For example, if my host at 192.168.1.129 is connected to a local network of 192.168.1.129/24 it can reach any hosts on that network. To reach hosts on the rest of the Internet, it needs to communicate through the router. Traditionally, on most networks with a subnet mask of 255.255.255.0, the router is usually at address 1 of the subnet, so 192.168.1.1. Now that router will have a port that connects it to another subnet (more in the Routing course). Certain IP addresses (private networks) are not visible to the internet, and we have things like NAT in place (more on this later).","title":"Subnets"},{"location":"subnetting/subnets/#exercise","text":"Use ifconfig to view your subnet mask.","title":"Exercise"},{"location":"subnetting/subnets/#quiz-questions","text":"Click the right arrow to view the answers True or false, a subnet consists of a subnet mask and network prefix. True","title":"Quiz Questions"},{"location":"subnetting/subnetting-cheats/","text":"Subnetting Cheats I hate to have to add this section, in the real world you would most likely never have to do subnet math by hand, however if you were getting interviewed on this, you'll have to know how to convert to and from binary form for subnetting. Luckily there are some arithmetic cheats you can memorize. First memorize your base-2 calculations, just do it: 2^1 = 2 2^2 = 4 2^3 = 8 2^4 = 16 2^5 = 32 2^6 = 64 2^7 = 128 2^8 = 256 2^9 = 512 2^10 = 1024 2^11 = 2048 2^12 = 4096 Decimal to Binary Chart 1 1 1 1 1 1 1 1 128 64 32 16 8 4 2 1 There are lots of reasons why the following chart looks the way it does, if you're curious how it works there are lots of resources online. Ok, got these memorized? Let's do a quick decimal to binary conversion: Convert 192.168.23.43 to Binary Remember: 128 / 64 / 32 / 16 / 8 / 4 / 2 / 1 Let's walk through converting the first octet to binary and you'll understand how the rest works. Can you subtract 192 - 128? Yes, so the first bit is 1 192 - 128 = 64, the next number in the chart is 64, can you subtract 64 - 64? Yes, so the second bit is 1 We've run out of numbers to subtract from, so our binary form of 192 is 11000000 Convert Binary 11000000 to Decimal For binary to decimal conversion you add up the numbers that have a 1, so: 128 + 64 + 0 + 0 + 0 + 0 + 0 + 0 = 192! Exercise Look at your IP address and subnet mask and see how many hosts you can have on your subnet. Quiz Questions Click the right arrow to view the answers What is the binary conversion of 123? 1111011","title":"Subnetting Cheats"},{"location":"subnetting/subnetting-cheats/#subnetting-cheats","text":"I hate to have to add this section, in the real world you would most likely never have to do subnet math by hand, however if you were getting interviewed on this, you'll have to know how to convert to and from binary form for subnetting. Luckily there are some arithmetic cheats you can memorize. First memorize your base-2 calculations, just do it: 2^1 = 2 2^2 = 4 2^3 = 8 2^4 = 16 2^5 = 32 2^6 = 64 2^7 = 128 2^8 = 256 2^9 = 512 2^10 = 1024 2^11 = 2048 2^12 = 4096 Decimal to Binary Chart 1 1 1 1 1 1 1 1 128 64 32 16 8 4 2 1 There are lots of reasons why the following chart looks the way it does, if you're curious how it works there are lots of resources online. Ok, got these memorized? Let's do a quick decimal to binary conversion: Convert 192.168.23.43 to Binary Remember: 128 / 64 / 32 / 16 / 8 / 4 / 2 / 1 Let's walk through converting the first octet to binary and you'll understand how the rest works. Can you subtract 192 - 128? Yes, so the first bit is 1 192 - 128 = 64, the next number in the chart is 64, can you subtract 64 - 64? Yes, so the second bit is 1 We've run out of numbers to subtract from, so our binary form of 192 is 11000000 Convert Binary 11000000 to Decimal For binary to decimal conversion you add up the numbers that have a 1, so: 128 + 64 + 0 + 0 + 0 + 0 + 0 + 0 = 192!","title":"Subnetting Cheats"},{"location":"subnetting/subnetting-cheats/#exercise","text":"Look at your IP address and subnet mask and see how many hosts you can have on your subnet.","title":"Exercise"},{"location":"subnetting/subnetting-cheats/#quiz-questions","text":"Click the right arrow to view the answers What is the binary conversion of 123? 1111011","title":"Quiz Questions"},{"location":"text-manipulation/cut-command/","text":"cut We're gonna learn a couple of useful commands that you can use to process text. Before we get started, let's create a file that we'll be working with. Copy and paste the following command, once you do that add a TAB in between lazy and dog (hold down Ctrl-v + TAB). $ echo 'The quick brown; fox jumps over the lazy dog' > sample.txt First command we'll be learning about is the cut command. It extracts portions of text from a file. To extract contents by a list of characters: $ cut -c 5 sample.txt This outputs the 5th character in each line of the file. In this case it is \"q\", note that the space also counts as a character. To extract the contents by a field, we'll need to do a little modification: $ cut -f 2 sample.txt The -f or field flag cuts text based off of fields, by default it uses TABs as delimiters, so everything separated by a TAB is considered a field. You should see \"dog\" as your output. You can combine the field flag with the delimiter flag to extract the contents by a custom delimiter: $ cut -f 1 -d \";\" sample.txt This will change the TAB delimiter to a \";\" delimiter and since we are cutting the first field, the result should be \"The quick brown\". Exercise What does the following command do? Why? $ cut -c 5-10 sample.txt $ cut -c 5- sample.txt $ cut -c -5 sample.txt Quiz Questions Click the right arrow to view the answers What command would you use to get the first character of every line in a file? cut -c 1","title":"Cut"},{"location":"text-manipulation/cut-command/#cut","text":"We're gonna learn a couple of useful commands that you can use to process text. Before we get started, let's create a file that we'll be working with. Copy and paste the following command, once you do that add a TAB in between lazy and dog (hold down Ctrl-v + TAB). $ echo 'The quick brown; fox jumps over the lazy dog' > sample.txt First command we'll be learning about is the cut command. It extracts portions of text from a file. To extract contents by a list of characters: $ cut -c 5 sample.txt This outputs the 5th character in each line of the file. In this case it is \"q\", note that the space also counts as a character. To extract the contents by a field, we'll need to do a little modification: $ cut -f 2 sample.txt The -f or field flag cuts text based off of fields, by default it uses TABs as delimiters, so everything separated by a TAB is considered a field. You should see \"dog\" as your output. You can combine the field flag with the delimiter flag to extract the contents by a custom delimiter: $ cut -f 1 -d \";\" sample.txt This will change the TAB delimiter to a \";\" delimiter and since we are cutting the first field, the result should be \"The quick brown\".","title":"cut"},{"location":"text-manipulation/cut-command/#exercise","text":"What does the following command do? Why? $ cut -c 5-10 sample.txt $ cut -c 5- sample.txt $ cut -c -5 sample.txt","title":"Exercise"},{"location":"text-manipulation/cut-command/#quiz-questions","text":"Click the right arrow to view the answers What command would you use to get the first character of every line in a file? cut -c 1","title":"Quiz Questions"},{"location":"text-manipulation/env-environment/","text":"env (environment) Run the following command: $ echo $HOME You should see the path to your home directory, mine looks like /home/mo. What about this command? $ echo $USER You should see your username! Where is this information coming from? It's coming from your environment variables. You can view these by typing $ env This outputs a whole lot of information about the environment variables you currently have set. These variables contain useful information that the shell and other processes can use. Here is a short example: PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/bin PWD=/home/user USER=mo One particularly important variable is the PATH Variable. You can access these variables by sticking a $ infront of the variable name like so: $ echo $PATH /usr/local/sbin:/usr/local/bin:/usr/sbin:/bin This returns a list of paths separated by a colon that your system searches when it runs a command. Let's say you manually download and install a package from the internet and put it in to a non standard directory and want to run that command, you type $ coolcommand and the prompt says command not found. Well that's silly you are looking at the binary in a folder and know it exists. What is happening is that $PATH variable doesn't check that directory for this binary so it's throwing an error. Let's say you had tons of binaries you wanted to run out of that directory, you can just modify the PATH variable to include that directory in your PATH environment variable. Exercise What does the following output? Why? $ echo $HOME Quiz Questions Click the right arrow to view the answers How do you see your environment variables? env","title":"Env"},{"location":"text-manipulation/env-environment/#env-environment","text":"Run the following command: $ echo $HOME You should see the path to your home directory, mine looks like /home/mo. What about this command? $ echo $USER You should see your username! Where is this information coming from? It's coming from your environment variables. You can view these by typing $ env This outputs a whole lot of information about the environment variables you currently have set. These variables contain useful information that the shell and other processes can use. Here is a short example: PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/bin PWD=/home/user USER=mo One particularly important variable is the PATH Variable. You can access these variables by sticking a $ infront of the variable name like so: $ echo $PATH /usr/local/sbin:/usr/local/bin:/usr/sbin:/bin This returns a list of paths separated by a colon that your system searches when it runs a command. Let's say you manually download and install a package from the internet and put it in to a non standard directory and want to run that command, you type $ coolcommand and the prompt says command not found. Well that's silly you are looking at the binary in a folder and know it exists. What is happening is that $PATH variable doesn't check that directory for this binary so it's throwing an error. Let's say you had tons of binaries you wanted to run out of that directory, you can just modify the PATH variable to include that directory in your PATH environment variable.","title":"env (environment)"},{"location":"text-manipulation/env-environment/#exercise","text":"What does the following output? Why? $ echo $HOME","title":"Exercise"},{"location":"text-manipulation/env-environment/#quiz-questions","text":"Click the right arrow to view the answers How do you see your environment variables? env","title":"Quiz Questions"},{"location":"text-manipulation/expand-command/","text":"expand and unexpand In our lesson on the cut command, we had our sample.txt file that contained a tab. Normally TABs would usually show a noticeable difference but some text files don't show that well enough. Having TABs in a text file may not be the desired spacing you want. To change your TABs to spaces, use the expand command. $ expand sample.txt The command above will print output with each TAB converted into a group of spaces. To save this output in a file, use output redirection like below. $ expand sample.txt > result.txt Opposite to expand, we can convert back each group of spaces to a TAB with the unexpand command: $ unexpand -a result.txt Exercise What happens if you just type expand with no file input? Quiz Questions Click the right arrow to view the answers What command is used to convert TABs to spaces? expand","title":"Expand"},{"location":"text-manipulation/expand-command/#expand-and-unexpand","text":"In our lesson on the cut command, we had our sample.txt file that contained a tab. Normally TABs would usually show a noticeable difference but some text files don't show that well enough. Having TABs in a text file may not be the desired spacing you want. To change your TABs to spaces, use the expand command. $ expand sample.txt The command above will print output with each TAB converted into a group of spaces. To save this output in a file, use output redirection like below. $ expand sample.txt > result.txt Opposite to expand, we can convert back each group of spaces to a TAB with the unexpand command: $ unexpand -a result.txt","title":"expand and unexpand"},{"location":"text-manipulation/expand-command/#exercise","text":"What happens if you just type expand with no file input?","title":"Exercise"},{"location":"text-manipulation/expand-command/#quiz-questions","text":"Click the right arrow to view the answers What command is used to convert TABs to spaces? expand","title":"Quiz Questions"},{"location":"text-manipulation/grep-command/","text":"grep The grep command is quite possibly the most common text processing command you will use. It allows you to search files for characters that match a certain pattern. What if you wanted to know if a file existed in a certain directory or if you wanted to see if a string was found in a file? You certainly wouldn't dig through every line of text, you would use grep! Let's use our sample.txt file as an example: $ grep fox sample.txt You should see that grep found fox in the sample.txt file. You can also grep patterns that are case insensitive with the -i flag: $ grep -i somepattern somefile To get even more flexible with grep you can combine it with other commands with |. $ env | grep -i User As you can see grep is pretty versatile. You can even use regular expressions in your pattern: $ ls /somedir | grep '.txt$' Should return all files ending with .txt in somedir. Exercise You may have heard of egrep or fgrep, these are deprecated grep calls and have since been replaced by grep -E and grep -F. Read the grep manpage to learn more. Quiz Questions Click the right arrow to view the answers What command do you use to find a certain pattern? grep","title":"Grep"},{"location":"text-manipulation/grep-command/#grep","text":"The grep command is quite possibly the most common text processing command you will use. It allows you to search files for characters that match a certain pattern. What if you wanted to know if a file existed in a certain directory or if you wanted to see if a string was found in a file? You certainly wouldn't dig through every line of text, you would use grep! Let's use our sample.txt file as an example: $ grep fox sample.txt You should see that grep found fox in the sample.txt file. You can also grep patterns that are case insensitive with the -i flag: $ grep -i somepattern somefile To get even more flexible with grep you can combine it with other commands with |. $ env | grep -i User As you can see grep is pretty versatile. You can even use regular expressions in your pattern: $ ls /somedir | grep '.txt$' Should return all files ending with .txt in somedir.","title":"grep"},{"location":"text-manipulation/grep-command/#exercise","text":"You may have heard of egrep or fgrep, these are deprecated grep calls and have since been replaced by grep -E and grep -F. Read the grep manpage to learn more.","title":"Exercise"},{"location":"text-manipulation/grep-command/#quiz-questions","text":"Click the right arrow to view the answers What command do you use to find a certain pattern? grep","title":"Quiz Questions"},{"location":"text-manipulation/head-command/","text":"head Let's say we have a very long file, in fact we have many to choose from, go ahead and cat /var/log/syslog. You should see pages upon pages of text. What if I just wanted to see the first couple of lines in this text file? Well we can do that with the head command, by default the head command will show you the first 10 lines in a file. $ head /var/log/syslog You can also modify the line count to whatever you choose, let's say I wanted to see the first 15 lines instead. $ head -n 15 /var/log/syslog The -n flag stands for number of lines. Exercise What does the following command do and why? $ head -c 15 /var/log/syslog Quiz Questions Click the right arrow to view the answers What flag would you use to change the number of lines you want to view for the head command? -n","title":"Head"},{"location":"text-manipulation/head-command/#head","text":"Let's say we have a very long file, in fact we have many to choose from, go ahead and cat /var/log/syslog. You should see pages upon pages of text. What if I just wanted to see the first couple of lines in this text file? Well we can do that with the head command, by default the head command will show you the first 10 lines in a file. $ head /var/log/syslog You can also modify the line count to whatever you choose, let's say I wanted to see the first 15 lines instead. $ head -n 15 /var/log/syslog The -n flag stands for number of lines.","title":"head"},{"location":"text-manipulation/head-command/#exercise","text":"What does the following command do and why? $ head -c 15 /var/log/syslog","title":"Exercise"},{"location":"text-manipulation/head-command/#quiz-questions","text":"Click the right arrow to view the answers What flag would you use to change the number of lines you want to view for the head command? -n","title":"Quiz Questions"},{"location":"text-manipulation/join-split-command/","text":"join and split The join command allows you to join multiple files together by a common field: Let's say I had two files that I wanted to join together: file1.txt 1 John 2 Jane 3 Mary file2.txt 1 Doe 2 Doe 3 Sue $ join file1.txt file2.txt 1 John Doe 2 Jane Doe 3 Mary Sue See how it joined together my files? They are joined together by the first field by default and the fields have to be identical, if they are not you can sort them, so in this case the files are joined via 1, 2, 3. How would we join the following files? file1.txt John 1 Jane 2 Mary 3 file2.txt 1 Doe 2 Doe 3 Sue To join this file you need to specify which fields you are joining, in this case we want field 2 on file1.txt and field 1 on file2.txt, so the command would look like this: $ join -1 2 -2 1 file1.txt file2.txt 1 John Doe 2 Jane Doe 3 Mary Sue -1 refers to file1.txt and -2 refers to file2.txt. Pretty neat. You can also split a file up into different files with the split command: $ split somefile This will split it into different files, by default it will split them once they reach a 1000 line limit. The files are named x** by default. Exercise Join two files with different number of lines in each file, what happens? Quiz Questions Click the right arrow to view the answers What command would you use to join files named foo bar tar? join foo bar tar","title":"join and split"},{"location":"text-manipulation/join-split-command/#join-and-split","text":"The join command allows you to join multiple files together by a common field: Let's say I had two files that I wanted to join together: file1.txt 1 John 2 Jane 3 Mary file2.txt 1 Doe 2 Doe 3 Sue $ join file1.txt file2.txt 1 John Doe 2 Jane Doe 3 Mary Sue See how it joined together my files? They are joined together by the first field by default and the fields have to be identical, if they are not you can sort them, so in this case the files are joined via 1, 2, 3. How would we join the following files? file1.txt John 1 Jane 2 Mary 3 file2.txt 1 Doe 2 Doe 3 Sue To join this file you need to specify which fields you are joining, in this case we want field 2 on file1.txt and field 1 on file2.txt, so the command would look like this: $ join -1 2 -2 1 file1.txt file2.txt 1 John Doe 2 Jane Doe 3 Mary Sue -1 refers to file1.txt and -2 refers to file2.txt. Pretty neat. You can also split a file up into different files with the split command: $ split somefile This will split it into different files, by default it will split them once they reach a 1000 line limit. The files are named x** by default.","title":"join and split"},{"location":"text-manipulation/join-split-command/#exercise","text":"Join two files with different number of lines in each file, what happens?","title":"Exercise"},{"location":"text-manipulation/join-split-command/#quiz-questions","text":"Click the right arrow to view the answers What command would you use to join files named foo bar tar? join foo bar tar","title":"Quiz Questions"},{"location":"text-manipulation/nl-wc-command/","text":"wc and nl The wc (word count) command shows the total count of words in a file. $ wc /etc/passwd 96 265 5925 /etc/passwd It display the number of lines, number of words and number of bytes, respectively. To just see just the count of a certain field, use the -l, -w, or -c respectively. $ wc -l /etc/passwd 96 Another command you can use to check the count of lines on a file is the nl (number lines) command. file1.txt i like turtles $ nl file1.txt 1. i 2. like 3. turtles Exercise How would you get the total count of lines by using the nl file without searching through the entire output? Hint: Use some of the other commands you learned in this course. Quiz Questions Click the right arrow to view the answers What command would you use to get the total number of words in a file and just the words? wc -w","title":"wc and nl"},{"location":"text-manipulation/nl-wc-command/#wc-and-nl","text":"The wc (word count) command shows the total count of words in a file. $ wc /etc/passwd 96 265 5925 /etc/passwd It display the number of lines, number of words and number of bytes, respectively. To just see just the count of a certain field, use the -l, -w, or -c respectively. $ wc -l /etc/passwd 96 Another command you can use to check the count of lines on a file is the nl (number lines) command. file1.txt i like turtles $ nl file1.txt 1. i 2. like 3. turtles","title":"wc and nl"},{"location":"text-manipulation/nl-wc-command/#exercise","text":"How would you get the total count of lines by using the nl file without searching through the entire output? Hint: Use some of the other commands you learned in this course.","title":"Exercise"},{"location":"text-manipulation/nl-wc-command/#quiz-questions","text":"Click the right arrow to view the answers What command would you use to get the total number of words in a file and just the words? wc -w","title":"Quiz Questions"},{"location":"text-manipulation/paste-command/","text":"paste The paste command is similar to the cat command, it merges lines together in a file. Let's create a new file with the following contents: sample2.txt The quick brown fox Let's combine all these lines into one line: $ paste -s sample2.txt The default delimiter for paste is TAB, so now there is one line with TABs separating each word. Let's change this delimiter (-d) to something a little more readable: $ paste -d ' ' -s sample2.txt Now everything should be on one line delimited by spaces. Exercise Try to paste multiple files together, what happens? Quiz Questions Click the right arrow to view the answers What flag do you use with paste to make everything go on one line? -s","title":"paste"},{"location":"text-manipulation/paste-command/#paste","text":"The paste command is similar to the cat command, it merges lines together in a file. Let's create a new file with the following contents: sample2.txt The quick brown fox Let's combine all these lines into one line: $ paste -s sample2.txt The default delimiter for paste is TAB, so now there is one line with TABs separating each word. Let's change this delimiter (-d) to something a little more readable: $ paste -d ' ' -s sample2.txt Now everything should be on one line delimited by spaces.","title":"paste"},{"location":"text-manipulation/paste-command/#exercise","text":"Try to paste multiple files together, what happens?","title":"Exercise"},{"location":"text-manipulation/paste-command/#quiz-questions","text":"Click the right arrow to view the answers What flag do you use with paste to make everything go on one line? -s","title":"Quiz Questions"},{"location":"text-manipulation/pipe-tee-redirect/","text":"pipe and tee Let's get into some plumbing now, not really but kinda. Let's try a command: $ ls -la /etc You should see a very long list of items, it's a little hard to read actually. Instead of redirecting this output to a file, wouldn't it be nice if we could just see the output in another command like less? Well we can! $ ls -la /etc | less The pipe operator |, represented by a vertical bar, allows us to get the stdout of a command and make that the stdin to another process. In this case, we took the stdout of ls -la /etc and then piped it to the less command. The pipe command is extremely useful and we will continue to use it for all eternity. Well what if I wanted to write the output of my command to two different streams? That's possible with the tee command: $ ls | tee peanuts.txt You should see the output of ls on your screen and if you open up the peanuts.txt file you should see the same information! Exercise Try the following commands: $ ls | tee peanuts.txt banan.txt Quiz Questions Click the right arrow to view the answers What key represents the pipe operator? \"|\"","title":"Pipe/Tee"},{"location":"text-manipulation/pipe-tee-redirect/#pipe-and-tee","text":"Let's get into some plumbing now, not really but kinda. Let's try a command: $ ls -la /etc You should see a very long list of items, it's a little hard to read actually. Instead of redirecting this output to a file, wouldn't it be nice if we could just see the output in another command like less? Well we can! $ ls -la /etc | less The pipe operator |, represented by a vertical bar, allows us to get the stdout of a command and make that the stdin to another process. In this case, we took the stdout of ls -la /etc and then piped it to the less command. The pipe command is extremely useful and we will continue to use it for all eternity. Well what if I wanted to write the output of my command to two different streams? That's possible with the tee command: $ ls | tee peanuts.txt You should see the output of ls on your screen and if you open up the peanuts.txt file you should see the same information!","title":"pipe and tee"},{"location":"text-manipulation/pipe-tee-redirect/#exercise","text":"Try the following commands: $ ls | tee peanuts.txt banan.txt","title":"Exercise"},{"location":"text-manipulation/pipe-tee-redirect/#quiz-questions","text":"Click the right arrow to view the answers What key represents the pipe operator? \"|\"","title":"Quiz Questions"},{"location":"text-manipulation/sort-command/","text":"sort The sort command is useful for sorting lines. file1.txt dog cow cat elephant bird $ sort file1.txt bird cat cow dog elephant You can also do a reverse sort: $ sort -r file1.txt elephant dog cow cat bird And also sort via numerical value: $ sort -n file1.txt bird cat cow elephant dog Exercise The real power of sort comes with its ability to be combined with other commands, try the following command and see what happens? $ ls /etc | sort -rn Quiz Question Quiz Answer Quiz Questions Click the right arrow to view the answers What flag do you use to do a reverse sort? -r","title":"Sort"},{"location":"text-manipulation/sort-command/#sort","text":"The sort command is useful for sorting lines. file1.txt dog cow cat elephant bird $ sort file1.txt bird cat cow dog elephant You can also do a reverse sort: $ sort -r file1.txt elephant dog cow cat bird And also sort via numerical value: $ sort -n file1.txt bird cat cow elephant dog","title":"sort"},{"location":"text-manipulation/sort-command/#exercise","text":"The real power of sort comes with its ability to be combined with other commands, try the following command and see what happens? $ ls /etc | sort -rn","title":"Exercise"},{"location":"text-manipulation/sort-command/#quiz-question","text":"","title":"Quiz Question"},{"location":"text-manipulation/sort-command/#quiz-answer","text":"","title":"Quiz Answer"},{"location":"text-manipulation/sort-command/#quiz-questions","text":"Click the right arrow to view the answers What flag do you use to do a reverse sort? -r","title":"Quiz Questions"},{"location":"text-manipulation/stderr-standard-error-redirect/","text":"stderr (Standard Error) Let's try something a little different now, let's try to list the contents of a directory that doesn't exist on your system and redirect the output to the peanuts.txt file again. $ ls /fake/directory > peanuts.txt What you should see is: ls: cannot access /fake/directory: No such file or directory Now you're probably thinking, shouldn't that message have been sent to the file? There is actually another I/O stream in play here called standard error (stderr). By default, stderr sends its output to the screen as well, it's a completely different stream than stdout. So you'll need to redirect its output a different way. Unfortunately the redirector is not as nice as using < or > but it's pretty close. We will have to use file descriptors. A file descriptor is a non-negative number that is used to access a file or stream. We will go in depth about this later, but for now know that the file descriptor for stdin, stdout and stderr is 0, 1, and 2 respectively. So now if we want to redirect our stderr to the file we can do this: $ ls /fake/directory 2> peanuts.txt You should see just the stderr messages in peanuts.txt. Now what if I wanted to see both stderr and stdout in the peanuts.txt file? It's possible to do this with file descriptors as well: $ ls /fake/directory > peanuts.txt 2>&1 This sends the results of ls /fake/directory to the peanuts.txt file and then it redirects stderr to the stdout via 2>&1. The order of operations here matters, 2>&1 sends stderr to whatever stdout is pointing to. In this case stdout is pointing to a file, so 2>&1 also sends stderr to a file. So if you open up that peanuts.txt file you should see both stderr and stdout. In our case, the above command only outputs stderr. There is a shorter way to redirect both stdout and stderr to a file: $ ls /fake/directory &> peanuts.txt Now what if I don't want any of that cruft and want to get rid of stderr messages completely? Well you can also redirect output to a special file call /dev/null and it will discard any input. $ ls /fake/directory 2> /dev/null Exercise What is the following command doing? $ ls /fake/directory >> /dev/null 2>&1 Quiz Questions Click the right arrow to view the answers What is the redirector for stderr? 2>","title":"stderr (Standard Error)"},{"location":"text-manipulation/stderr-standard-error-redirect/#stderr-standard-error","text":"Let's try something a little different now, let's try to list the contents of a directory that doesn't exist on your system and redirect the output to the peanuts.txt file again. $ ls /fake/directory > peanuts.txt What you should see is: ls: cannot access /fake/directory: No such file or directory Now you're probably thinking, shouldn't that message have been sent to the file? There is actually another I/O stream in play here called standard error (stderr). By default, stderr sends its output to the screen as well, it's a completely different stream than stdout. So you'll need to redirect its output a different way. Unfortunately the redirector is not as nice as using < or > but it's pretty close. We will have to use file descriptors. A file descriptor is a non-negative number that is used to access a file or stream. We will go in depth about this later, but for now know that the file descriptor for stdin, stdout and stderr is 0, 1, and 2 respectively. So now if we want to redirect our stderr to the file we can do this: $ ls /fake/directory 2> peanuts.txt You should see just the stderr messages in peanuts.txt. Now what if I wanted to see both stderr and stdout in the peanuts.txt file? It's possible to do this with file descriptors as well: $ ls /fake/directory > peanuts.txt 2>&1 This sends the results of ls /fake/directory to the peanuts.txt file and then it redirects stderr to the stdout via 2>&1. The order of operations here matters, 2>&1 sends stderr to whatever stdout is pointing to. In this case stdout is pointing to a file, so 2>&1 also sends stderr to a file. So if you open up that peanuts.txt file you should see both stderr and stdout. In our case, the above command only outputs stderr. There is a shorter way to redirect both stdout and stderr to a file: $ ls /fake/directory &> peanuts.txt Now what if I don't want any of that cruft and want to get rid of stderr messages completely? Well you can also redirect output to a special file call /dev/null and it will discard any input. $ ls /fake/directory 2> /dev/null","title":"stderr (Standard Error)"},{"location":"text-manipulation/stderr-standard-error-redirect/#exercise","text":"What is the following command doing? $ ls /fake/directory >> /dev/null 2>&1","title":"Exercise"},{"location":"text-manipulation/stderr-standard-error-redirect/#quiz-questions","text":"Click the right arrow to view the answers What is the redirector for stderr? 2>","title":"Quiz Questions"},{"location":"text-manipulation/stdin-standard-in-redirect/","text":"stdin (Standard In) In our previous lesson we learned that we have different stdout streams we can use, such as a file or the screen. Well there are also different standard input (stdin) streams we can use as well. We know that we have stdin from devices like the keyboard, but we can use files, output from other processes and the terminal as well, let's see an example. Let's use the peanuts.txt file in the previous lesson for this example, remember it had the text Hello World in it. $ cat < peanuts.txt > banana.txt Just like we had > for stdout redirection, we can use < for stdin redirection. Normally in the cat command, you send a file to it and that file becomes the stdin, in this case, we redirected peanuts.txt to be our stdin. Then the output of cat peanuts.txt which would be Hello World gets redirected to another file called banana.txt. Exercise Try out a couple of commands: $ echo < peanuts.txt > banana.txt $ ls < peanuts.txt > banana.txt $ pwd < peanuts.txt > banana.txt Quiz Questions Click the right arrow to view the answers What redirector do you use to redirect stdin? <","title":"stdin (Standard In)"},{"location":"text-manipulation/stdin-standard-in-redirect/#stdin-standard-in","text":"In our previous lesson we learned that we have different stdout streams we can use, such as a file or the screen. Well there are also different standard input (stdin) streams we can use as well. We know that we have stdin from devices like the keyboard, but we can use files, output from other processes and the terminal as well, let's see an example. Let's use the peanuts.txt file in the previous lesson for this example, remember it had the text Hello World in it. $ cat < peanuts.txt > banana.txt Just like we had > for stdout redirection, we can use < for stdin redirection. Normally in the cat command, you send a file to it and that file becomes the stdin, in this case, we redirected peanuts.txt to be our stdin. Then the output of cat peanuts.txt which would be Hello World gets redirected to another file called banana.txt.","title":"stdin (Standard In)"},{"location":"text-manipulation/stdin-standard-in-redirect/#exercise","text":"Try out a couple of commands: $ echo < peanuts.txt > banana.txt $ ls < peanuts.txt > banana.txt $ pwd < peanuts.txt > banana.txt","title":"Exercise"},{"location":"text-manipulation/stdin-standard-in-redirect/#quiz-questions","text":"Click the right arrow to view the answers What redirector do you use to redirect stdin? <","title":"Quiz Questions"},{"location":"text-manipulation/stdout-standard-out-redirect/","text":"stdout (Standard Out) By now, we've become familiar with many commands and their output and that brings us to our next subject I/O (input/output) streams. Let's run the following command and we'll discuss how this works. $ echo Hello World > peanuts.txt What just happened? Well check the directory where you ran that command and lo and behold you should see a file called peanuts.txt, look inside that file and you should see the text Hello World. Lots of things just happened in one command so let's break it down. First let's break down the first part: $ echo Hello World We know this prints out Hello World to the screen, but how? Processes use I/O streams to receive input and return output. By default the echo command takes the input (standard input or stdin) from the keyboard and returns the output (standard output or stdout) to the screen. So that's why when you type echo Hello World in your shell, you get Hello World on the screen. However, I/O redirection allows us to change this default behavior giving us greater file flexibility. Let's proceed to the next part of the command: > The > is a redirection operator that allows us the change where standard output goes. It allows us to send the output of echo Hello World to a file instead of the screen. If the file does not already exist it will create it for us. However, if it does exist it will overwrite it (you can add a shell flag to prevent this depending on what shell you are using). And that's basically how stdout redirection works! Well let's say I didn't want to overwrite my peanuts.txt, luckily there is a redirection operator for that as well, >>: $ echo Hello World >> peanuts.txt This will append Hello World to the end of the peanuts.txt file, if the file doesn't already exist it will create it for us like it did with the > redirector! Exercise Try a couple of commands: $ ls -l /var/log > myoutput.txt $ echo Hello World > rm $ > somefile.txt Quiz Question Quiz Answer Quiz Questions Click the right arrow to view the answers What redirector do you use to append output to a file? >>","title":"stdout (Standard Out)"},{"location":"text-manipulation/stdout-standard-out-redirect/#stdout-standard-out","text":"By now, we've become familiar with many commands and their output and that brings us to our next subject I/O (input/output) streams. Let's run the following command and we'll discuss how this works. $ echo Hello World > peanuts.txt What just happened? Well check the directory where you ran that command and lo and behold you should see a file called peanuts.txt, look inside that file and you should see the text Hello World. Lots of things just happened in one command so let's break it down. First let's break down the first part: $ echo Hello World We know this prints out Hello World to the screen, but how? Processes use I/O streams to receive input and return output. By default the echo command takes the input (standard input or stdin) from the keyboard and returns the output (standard output or stdout) to the screen. So that's why when you type echo Hello World in your shell, you get Hello World on the screen. However, I/O redirection allows us to change this default behavior giving us greater file flexibility. Let's proceed to the next part of the command: > The > is a redirection operator that allows us the change where standard output goes. It allows us to send the output of echo Hello World to a file instead of the screen. If the file does not already exist it will create it for us. However, if it does exist it will overwrite it (you can add a shell flag to prevent this depending on what shell you are using). And that's basically how stdout redirection works! Well let's say I didn't want to overwrite my peanuts.txt, luckily there is a redirection operator for that as well, >>: $ echo Hello World >> peanuts.txt This will append Hello World to the end of the peanuts.txt file, if the file doesn't already exist it will create it for us like it did with the > redirector!","title":"stdout (Standard Out)"},{"location":"text-manipulation/stdout-standard-out-redirect/#exercise","text":"Try a couple of commands: $ ls -l /var/log > myoutput.txt $ echo Hello World > rm $ > somefile.txt","title":"Exercise"},{"location":"text-manipulation/stdout-standard-out-redirect/#quiz-question","text":"","title":"Quiz Question"},{"location":"text-manipulation/stdout-standard-out-redirect/#quiz-answer","text":"","title":"Quiz Answer"},{"location":"text-manipulation/stdout-standard-out-redirect/#quiz-questions","text":"Click the right arrow to view the answers What redirector do you use to append output to a file? >>","title":"Quiz Questions"},{"location":"text-manipulation/tail-command/","text":"tail Similar to the head command, the tail command lets you see the last 10 lines of a file by default. $ tail /var/log/syslog Along with head you can change the number of lines you want to see. $ tail -n 10 /var/log/syslog Another great option you can use is the -f (follow) flag, this will follow the file as it grows. Give it a try and see what happens. $ tail -f /var/log/syslog Your syslog file will be continually changing while you interact with your system and using tail -f you can see everything that is getting added to that file. Exercise Look at the man page of tail and read some of the other commands we didn't discuss. $ man tail Quiz Questions Click the right arrow to view the answers What is the flag used to follow a file in tail? -f","title":"Tail"},{"location":"text-manipulation/tail-command/#tail","text":"Similar to the head command, the tail command lets you see the last 10 lines of a file by default. $ tail /var/log/syslog Along with head you can change the number of lines you want to see. $ tail -n 10 /var/log/syslog Another great option you can use is the -f (follow) flag, this will follow the file as it grows. Give it a try and see what happens. $ tail -f /var/log/syslog Your syslog file will be continually changing while you interact with your system and using tail -f you can see everything that is getting added to that file.","title":"tail"},{"location":"text-manipulation/tail-command/#exercise","text":"Look at the man page of tail and read some of the other commands we didn't discuss. $ man tail","title":"Exercise"},{"location":"text-manipulation/tail-command/#quiz-questions","text":"Click the right arrow to view the answers What is the flag used to follow a file in tail? -f","title":"Quiz Questions"},{"location":"text-manipulation/tr-translate-command/","text":"tr (translate) The tr (translate) command allows you to translate a set of characters into another set of characters. Let's try an example of translating all lower case characters to uppercase characters. $ tr a-z A-Z hello HELLO As you can see we made the ranges of a-z into A-Z and all text we type that is lowercase gets uppercased. Exercise Try the following command what happens? $ tr -d ello hello Quiz Questions Click the right arrow to view the answers What command is used to translate characters? tr","title":"Translate (TR)"},{"location":"text-manipulation/tr-translate-command/#tr-translate","text":"The tr (translate) command allows you to translate a set of characters into another set of characters. Let's try an example of translating all lower case characters to uppercase characters. $ tr a-z A-Z hello HELLO As you can see we made the ranges of a-z into A-Z and all text we type that is lowercase gets uppercased.","title":"tr (translate)"},{"location":"text-manipulation/tr-translate-command/#exercise","text":"Try the following command what happens? $ tr -d ello hello","title":"Exercise"},{"location":"text-manipulation/tr-translate-command/#quiz-questions","text":"Click the right arrow to view the answers What command is used to translate characters? tr","title":"Quiz Questions"},{"location":"text-manipulation/uniq-unique-command/","text":"uniq (unique) The uniq (unique) command is another useful tool for parsing text. Let's say you had a file with lots of duplicates: reading.txt book book paper paper article article magazine And you wanted to remove the duplicates, well you can use the uniq command: $ uniq reading.txt book paper article magazine Let's get the count of how many occurrences of a line: $ uniq -c reading.txt 2 book 2 paper 2 article 1 magazine Let's just get unique values: $ uniq -u reading.txt magazine Let's just get duplicate values: $ uniq -d reading.txt book paper article Note : uniq does not detect duplicate lines unless they are adjacent. For eg: Let's say you had a file with duplicates which are not adjacent: reading.txt book paper book paper article magazine article $ uniq reading.txt reading.txt book paper book paper article magazine article The result returned by uniq will contain all the entries unlike the very first example. To overcome this limitation of uniq we can use sort in combination with uniq: $ sort reading.txt | uniq article book magazine paper Exercise What result would you get if you tried uniq -uc? Quiz Questions Click the right arrow to view the answers What command would you use to remove duplicates in a file? uniq","title":"uniq (unique)"},{"location":"text-manipulation/uniq-unique-command/#uniq-unique","text":"The uniq (unique) command is another useful tool for parsing text. Let's say you had a file with lots of duplicates: reading.txt book book paper paper article article magazine And you wanted to remove the duplicates, well you can use the uniq command: $ uniq reading.txt book paper article magazine Let's get the count of how many occurrences of a line: $ uniq -c reading.txt 2 book 2 paper 2 article 1 magazine Let's just get unique values: $ uniq -u reading.txt magazine Let's just get duplicate values: $ uniq -d reading.txt book paper article Note : uniq does not detect duplicate lines unless they are adjacent. For eg: Let's say you had a file with duplicates which are not adjacent: reading.txt book paper book paper article magazine article $ uniq reading.txt reading.txt book paper book paper article magazine article The result returned by uniq will contain all the entries unlike the very first example. To overcome this limitation of uniq we can use sort in combination with uniq: $ sort reading.txt | uniq article book magazine paper","title":"uniq (unique)"},{"location":"text-manipulation/uniq-unique-command/#exercise","text":"What result would you get if you tried uniq -uc?","title":"Exercise"},{"location":"text-manipulation/uniq-unique-command/#quiz-questions","text":"Click the right arrow to view the answers What command would you use to remove duplicates in a file? uniq","title":"Quiz Questions"},{"location":"user-management/etc-group-file/","text":"/etc/group Another file that is used in user management is the /etc/group file. This file allows for different groups with different permissions. $ cat /etc/group root:*:0:mo Very similar to the /etc/password field, the /etc/group fields are as follows: Group name Group password - there isn't a need to set a group password, using an elevated privilege like sudo is standard. A \"*\" will be put in place as the default value. Group ID (GID) List of users - you can manually specify users you want in a specific group Exercise Run the command groups . What do you see? Quiz Questions Click the right arrow to view the answers What is the GID of root? 0","title":"/etc/group"},{"location":"user-management/etc-group-file/#etcgroup","text":"Another file that is used in user management is the /etc/group file. This file allows for different groups with different permissions. $ cat /etc/group root:*:0:mo Very similar to the /etc/password field, the /etc/group fields are as follows: Group name Group password - there isn't a need to set a group password, using an elevated privilege like sudo is standard. A \"*\" will be put in place as the default value. Group ID (GID) List of users - you can manually specify users you want in a specific group","title":"/etc/group"},{"location":"user-management/etc-group-file/#exercise","text":"Run the command groups . What do you see?","title":"Exercise"},{"location":"user-management/etc-group-file/#quiz-questions","text":"Click the right arrow to view the answers What is the GID of root? 0","title":"Quiz Questions"},{"location":"user-management/etc-passwd-file/","text":"/etc/passwd Remember that usernames aren't really identifications for users. The system uses a user ID (UID) to identify a user. To find out what users are mapped to what ID, look at the /etc/passwd file. $ cat /etc/passwd This file shows you a list of users and detailed information about them. For example, the first line in this file most likely looks like this: root:x:0:0:root:/root:/bin/bash Each line displays user information for one user, most commonly you'll see the root user as the first line. There are many fields separated by colons that tell you additional information about the user, let's look at them all: Username User's password - the password is not really stored in this file, it's usually stored in the /etc/shadow file. We'll discuss more in the next lesson about /etc/shadow, but for now, know that it contains encrypted user passwords. You can see many different symbols that are in this field, if you see an \"x\" that means the password is stored in the /etc/shadow file, a \"*\" means the user doesn't have login access and if there is a blank field that means the user doesn't have a password. The user ID - as you can see root has the UID of 0 The group ID GECOS field - This is used to generally leave comments about the user or account such as their real name or phone number, it is comma delimited. User's home directory User's shell - you'll probably see a lot of user's defaulting to bash for their shell Normally in a user's setting page, you would expect you see just human users. However, you'll notice /etc/passwd contains other users. Remember that users are really only on the system to run processes with different permissions. Sometimes we want to run processes with pre-determined permissions. For example, the daemon user is used for daemon processes. Also should note that you can edit the /etc/passwd file by hand if you want to add users and modify information with the vipw tool, however things like these are best left to the tools we will discuss in a later lesson such as useradd and userdel. Exercise Look at your /etc/passwd file, take a look at some of the users and note the access they have. Quiz Questions Click the right arrow to view the answers If a user doesn't have login access how is that denoted in /etc/passwd? *","title":"/etc/passwd"},{"location":"user-management/etc-passwd-file/#etcpasswd","text":"Remember that usernames aren't really identifications for users. The system uses a user ID (UID) to identify a user. To find out what users are mapped to what ID, look at the /etc/passwd file. $ cat /etc/passwd This file shows you a list of users and detailed information about them. For example, the first line in this file most likely looks like this: root:x:0:0:root:/root:/bin/bash Each line displays user information for one user, most commonly you'll see the root user as the first line. There are many fields separated by colons that tell you additional information about the user, let's look at them all: Username User's password - the password is not really stored in this file, it's usually stored in the /etc/shadow file. We'll discuss more in the next lesson about /etc/shadow, but for now, know that it contains encrypted user passwords. You can see many different symbols that are in this field, if you see an \"x\" that means the password is stored in the /etc/shadow file, a \"*\" means the user doesn't have login access and if there is a blank field that means the user doesn't have a password. The user ID - as you can see root has the UID of 0 The group ID GECOS field - This is used to generally leave comments about the user or account such as their real name or phone number, it is comma delimited. User's home directory User's shell - you'll probably see a lot of user's defaulting to bash for their shell Normally in a user's setting page, you would expect you see just human users. However, you'll notice /etc/passwd contains other users. Remember that users are really only on the system to run processes with different permissions. Sometimes we want to run processes with pre-determined permissions. For example, the daemon user is used for daemon processes. Also should note that you can edit the /etc/passwd file by hand if you want to add users and modify information with the vipw tool, however things like these are best left to the tools we will discuss in a later lesson such as useradd and userdel.","title":"/etc/passwd"},{"location":"user-management/etc-passwd-file/#exercise","text":"Look at your /etc/passwd file, take a look at some of the users and note the access they have.","title":"Exercise"},{"location":"user-management/etc-passwd-file/#quiz-questions","text":"Click the right arrow to view the answers If a user doesn't have login access how is that denoted in /etc/passwd? *","title":"Quiz Questions"},{"location":"user-management/etc-shadow-file/","text":"/etc/shadow The /etc/shadow file is used to store information about user authentication. It requires superuser read permissions. $ sudo cat /etc/shadow root:MyEPTEa$6Nonsense:15000:0:99999:7::: You'll notice that it looks very similar to the contents of /etc/passwd, however in the password field you'll see an encrypted password. The fields are separated by colons as followed: Username Encrypted password Date of last password changed - expressed as the number of days since Jan 1, 1970. If there is a 0 that means the user should change their password the next time they login Minimum password age - Days that a user will have to wait before being able to change their password again Maximum password age - Maximum number of days before a user has to change their password Password warning period - Number of days before a password is going to expire Password inactivity period - Number of days after a password has expired to allow login with their password Account expiration date - date that user will not be able to login Reserved field for future use In most distributions today, user authentication doesn't rely on just the /etc/shadow file, there are other mechanisms in place such as PAM (Pluggable Authentication Modules) that replace authentication. Exercise Take a look at the /etc/shadow file Quiz Questions Click the right arrow to view the answers Add question Add asnwer here","title":"/etc/shadow"},{"location":"user-management/etc-shadow-file/#etcshadow","text":"The /etc/shadow file is used to store information about user authentication. It requires superuser read permissions. $ sudo cat /etc/shadow root:MyEPTEa$6Nonsense:15000:0:99999:7::: You'll notice that it looks very similar to the contents of /etc/passwd, however in the password field you'll see an encrypted password. The fields are separated by colons as followed: Username Encrypted password Date of last password changed - expressed as the number of days since Jan 1, 1970. If there is a 0 that means the user should change their password the next time they login Minimum password age - Days that a user will have to wait before being able to change their password again Maximum password age - Maximum number of days before a user has to change their password Password warning period - Number of days before a password is going to expire Password inactivity period - Number of days after a password has expired to allow login with their password Account expiration date - date that user will not be able to login Reserved field for future use In most distributions today, user authentication doesn't rely on just the /etc/shadow file, there are other mechanisms in place such as PAM (Pluggable Authentication Modules) that replace authentication.","title":"/etc/shadow"},{"location":"user-management/etc-shadow-file/#exercise","text":"Take a look at the /etc/shadow file","title":"Exercise"},{"location":"user-management/etc-shadow-file/#quiz-questions","text":"Click the right arrow to view the answers Add question Add asnwer here","title":"Quiz Questions"},{"location":"user-management/root-user/","text":"Root We've looked at one way to get superuser access using the sudo command. You can also run commands as the superuser with the su command. This command will \"substitute users\" and open a root shell if no username is specified. You can use this command to substitute to any user as long as you know the password. $ su There are some downsides to using this method: it's much easier to make a critical mistake running everything in root, you won't have records of the commands you use to change system configurations, etc. Basically, if you need to run commands as the superuser, just stick to sudo. Now that you know what commands to run as the superuser, the question is how do you know who has access to do that? The system doesn't let every single Joe Schmoe run commands as the superuser, so how does it know? There is a file called the /etc/sudoers file, this file lists users who can run sudo. You can edit this file with the visudo command. Exercise Open up the /etc/sudoers file and see what superuser permissions other users on the machine have. Quiz Questions Click the right arrow to view the answers What file shows the users who have access to sudo? /etc/sudoers","title":"Root User"},{"location":"user-management/root-user/#root","text":"We've looked at one way to get superuser access using the sudo command. You can also run commands as the superuser with the su command. This command will \"substitute users\" and open a root shell if no username is specified. You can use this command to substitute to any user as long as you know the password. $ su There are some downsides to using this method: it's much easier to make a critical mistake running everything in root, you won't have records of the commands you use to change system configurations, etc. Basically, if you need to run commands as the superuser, just stick to sudo. Now that you know what commands to run as the superuser, the question is how do you know who has access to do that? The system doesn't let every single Joe Schmoe run commands as the superuser, so how does it know? There is a file called the /etc/sudoers file, this file lists users who can run sudo. You can edit this file with the visudo command.","title":"Root"},{"location":"user-management/root-user/#exercise","text":"Open up the /etc/sudoers file and see what superuser permissions other users on the machine have.","title":"Exercise"},{"location":"user-management/root-user/#quiz-questions","text":"Click the right arrow to view the answers What file shows the users who have access to sudo? /etc/sudoers","title":"Quiz Questions"},{"location":"user-management/user-management-tools/","text":"User Management Tools Most enterprise environments are using management systems to manage users, accounts and passwords. However, on a single machine computer there are useful commands to run to manage users. Adding Users You can use the adduser or the useradd command. The adduser command contains more helpful features such as making a home directory and more. There are configuration files for adding new users that can be customized depending on what you want to allocate to a default user. $ sudo useradd bob You'll see that the above command creates an entry in /etc/passwd for bob, sets up default groups and adds an entry to the /etc/shadow file. Removing Users To remove a user, you can use the userdel command. $ sudo userdel bob This basically does its best to undo the file changes by useradd. Changing Passwords $ passwd bob This will allow you to change the password of yourself or another user (if you are root). Exercise Create a new user then change their password and login as the new user. Quiz Questions Click the right arrow to view the answers What command is used to change a password? passwd","title":"User Management Tools"},{"location":"user-management/user-management-tools/#user-management-tools","text":"Most enterprise environments are using management systems to manage users, accounts and passwords. However, on a single machine computer there are useful commands to run to manage users. Adding Users You can use the adduser or the useradd command. The adduser command contains more helpful features such as making a home directory and more. There are configuration files for adding new users that can be customized depending on what you want to allocate to a default user. $ sudo useradd bob You'll see that the above command creates an entry in /etc/passwd for bob, sets up default groups and adds an entry to the /etc/shadow file. Removing Users To remove a user, you can use the userdel command. $ sudo userdel bob This basically does its best to undo the file changes by useradd. Changing Passwords $ passwd bob This will allow you to change the password of yourself or another user (if you are root).","title":"User Management Tools"},{"location":"user-management/user-management-tools/#exercise","text":"Create a new user then change their password and login as the new user.","title":"Exercise"},{"location":"user-management/user-management-tools/#quiz-questions","text":"Click the right arrow to view the answers What command is used to change a password? passwd","title":"Quiz Questions"},{"location":"user-management/users-and-groups/","text":"Users and Groups In any traditional operating system, there are users and groups. They exist solely for access and permissions. When running a process, it will run as the owner of that process whether that is Jane or Bob. File access and ownership is also permission dependent. You wouldn't want Jane to see Bob's documents and vice versa. Each user has their own home directory where their user specific files get stored, this is usually located in /home/username, but can vary in different distributions. The system uses user ids (UID) to manage users, usernames are the friendly way to associate users with identification, but the system identifies users by their UID. The system also uses groups to manage permissions, groups are just sets of users with permission set by that group, they are identified by the system with their group ID (GID). In Linux, you'll have users in addition to the normal humans that use the system. Sometimes these users are system daemons that continuously run processes to keep the system functioning. One of the most important users is root or superuser, root is the most powerful user on the system, root can access any file and start and terminate any process. For that reason, it can be dangerous to operate as root all the time, you could potentially remove system critical files. Luckily, if root access is needed and a user has root access, they can run a command as root instead with the sudo command. The sudo command (superuser do) is used to run a command with root access, we'll go more in depth on how a user receives root access in a later lesson. Go ahead and try to view a protected file like /etc/shadow: $ cat /etc/shadow Notice how you get a permission denied error, look at the permissions with: $ ls -la /etc/shadow -rw-r----- 1 root shadow 1134 Dec 1 11:45 /etc/shadow We haven't gone through permissions yet, but what's happening here is that root is the owner of the file and you'll need root access or be part of the shadow group to read the contents. Now run the command with sudo: $ sudo cat /etc/shadow Now you'll be able to see the contents of the file! Quiz Questions Click the right arrow to view the answers What command do you use to run as root? sudo","title":"Users & Groups"},{"location":"user-management/users-and-groups/#users-and-groups","text":"In any traditional operating system, there are users and groups. They exist solely for access and permissions. When running a process, it will run as the owner of that process whether that is Jane or Bob. File access and ownership is also permission dependent. You wouldn't want Jane to see Bob's documents and vice versa. Each user has their own home directory where their user specific files get stored, this is usually located in /home/username, but can vary in different distributions. The system uses user ids (UID) to manage users, usernames are the friendly way to associate users with identification, but the system identifies users by their UID. The system also uses groups to manage permissions, groups are just sets of users with permission set by that group, they are identified by the system with their group ID (GID). In Linux, you'll have users in addition to the normal humans that use the system. Sometimes these users are system daemons that continuously run processes to keep the system functioning. One of the most important users is root or superuser, root is the most powerful user on the system, root can access any file and start and terminate any process. For that reason, it can be dangerous to operate as root all the time, you could potentially remove system critical files. Luckily, if root access is needed and a user has root access, they can run a command as root instead with the sudo command. The sudo command (superuser do) is used to run a command with root access, we'll go more in depth on how a user receives root access in a later lesson. Go ahead and try to view a protected file like /etc/shadow: $ cat /etc/shadow Notice how you get a permission denied error, look at the permissions with: $ ls -la /etc/shadow -rw-r----- 1 root shadow 1134 Dec 1 11:45 /etc/shadow We haven't gone through permissions yet, but what's happening here is that root is the owner of the file and you'll need root access or be part of the shadow group to read the contents. Now run the command with sudo: $ sudo cat /etc/shadow Now you'll be able to see the contents of the file!","title":"Users and Groups"},{"location":"user-management/users-and-groups/#quiz-questions","text":"Click the right arrow to view the answers What command do you use to run as root? sudo","title":"Quiz Questions"}]}